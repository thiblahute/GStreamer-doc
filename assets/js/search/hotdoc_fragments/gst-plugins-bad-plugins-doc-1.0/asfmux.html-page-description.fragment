fragment_downloaded_cb({"url": "gst-plugins-bad-plugins-doc-1.0/asfmux.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"asfmux\">\n<h1 id=\"asfmux1\">asfmux</h1><p>Muxes media into an ASF file/stream.</p>\n<p>Pad names are either video_xx or audio_xx, where 'xx' is the\nstream number of the stream that goes through that pad. Stream numbers\nare assigned sequentially, starting from 1.</p>\n<h2 id=\"example-launch-lines\">Example launch lines</h2>\n<p>(write everything in one line, without the backslash characters)</p>\n<pre><code>gst-launch-1.0 videotestsrc num-buffers=250 \\\n! \"video/x-raw,format=(string)I420,framerate=(fraction)25/1\" ! avenc_wmv2 \\\n! asfmux name=mux ! filesink location=test.asf \\\naudiotestsrc num-buffers=440 ! audioconvert \\\n! \"audio/x-raw,rate=44100\" ! avenc_wmav2 ! mux.\n</code></pre>\n<p>This creates an ASF file containing an WMV video stream\nwith a test picture and WMA audio stream of a test sound.</p>\n<h2 id=\"live-streaming\">Live streaming</h2>\n<p>asfmux and rtpasfpay are capable of generating a live asf stream.\nasfmux has to set its 'streamable' property to true, because in this\nmode it won't try to seek back to the start of the file to replace\nsome fields that couldn't be known at the file start. In this mode,\nit won't also send indexes at the end of the data packets (the actual\nmedia content)\nthe following pipelines are an example of this usage.\n(write everything in one line, without the backslash characters)\nServer (sender)</p>\n<pre><code>gst-launch-1.0 -ve videotestsrc ! avenc_wmv2 ! asfmux name=mux streamable=true \\\n! rtpasfpay ! udpsink host=127.0.0.1 port=3333 \\\naudiotestsrc ! avenc_wmav2 ! mux.\n</code></pre>\n<p>Client (receiver)</p>\n<pre><code>gst-launch-1.0 udpsrc port=3333 ! \"caps_from_rtpasfpay_at_sender\" \\\n! rtpasfdepay ! decodebin name=d ! queue \\\n! videoconvert ! autovideosink \\\nd. ! queue ! audioconvert ! autoaudiosink\n</code></pre>\n\n</div>\n\n\n"});