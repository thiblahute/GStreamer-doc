fragment_downloaded_cb({"url": "application-development/advanced/queryevents.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"queryevents.md\">\n<h1 id=\"position-tracking-and-seeking\">Position tracking and seeking</h1>\n<p>So far, we've looked at how to create a pipeline to do media processing\nand how to make it run. Most application developers will be interested\nin providing feedback to the user on media progress. Media players, for\nexample, will want to show a slider showing the progress in the song,\nand usually also a label indicating stream length. Transcoding\napplications will want to show a progress bar on how much percent of the\ntask is done. GStreamer has built-in support for doing all this using a\nconcept known as <em>querying</em>. Since seeking is very similar, it will be\ndiscussed here as well. Seeking is done using the concept of <em>events</em>.</p>\n<h2 id=\"querying-getting-the-position-or-length-of-a-stream\">Querying: getting the position or length of a stream</h2>\n<p>Querying is defined as requesting a specific stream property related to\nprogress tracking. This includes getting the length of a stream (if\navailable) or getting the current position. Those stream properties can\nbe retrieved in various formats such as time, audio samples, video\nframes or bytes. The function most commonly used for this is\n<code>gst_element_query ()</code>, although some convenience wrappers are provided\nas well (such as <code>gst_element_query_position ()</code> and\n<code>gst_element_query_duration ()</code>). You can generally query the pipeline\ndirectly, and it'll figure out the internal details for you, like which\nelement to query.</p>\n<p>Internally, queries will be sent to the sinks, and \u201cdispatched\u201d\nbackwards until one element can handle it; that result will be sent back\nto the function caller. Usually, that is the demuxer, although with live\nsources (from a webcam), it is the source itself.</p>\n<pre><code class=\"language-c\">\n#include &lt;gst/gst.h&gt;\n\n\n\n\nstatic gboolean\ncb_print_position (GstElement *pipeline)\n{\n  gint64 pos, len;\n\n  if (gst_element_query_position (pipeline, GST_FORMAT_TIME, &amp;pos)\n    &amp;&amp; gst_element_query_duration (pipeline, GST_FORMAT_TIME, &amp;len)) {\n    g_print (\"Time: %\" GST_TIME_FORMAT \" / %\" GST_TIME_FORMAT \"\\r\",\n         GST_TIME_ARGS (pos), GST_TIME_ARGS (len));\n  }\n\n  /* call me again */\n  return TRUE;\n}\n\ngint\nmain (gint   argc,\n      gchar *argv[])\n{\n  GstElement *pipeline;\n\n[..]\n\n  /* run pipeline */\n  g_timeout_add (200, (GSourceFunc) cb_print_position, pipeline);\n  g_main_loop_run (loop);\n\n[..]\n\n}\n\n</code></pre>\n<h2 id=\"events-seeking-and-more\">Events: seeking (and more)</h2>\n<p>Events work in a very similar way as queries. Dispatching, for example,\nworks exactly the same for events (and also has the same limitations),\nand they can similarly be sent to the toplevel pipeline and it will\nfigure out everything for you. Although there are more ways in which\napplications and elements can interact using events, we will only focus\non seeking here. This is done using the seek-event. A seek-event\ncontains a playback rate, a seek offset format (which is the unit of the\noffsets to follow, e.g. time, audio samples, video frames or bytes),\noptionally a set of seeking-related flags (e.g. whether internal buffers\nshould be flushed), a seek method (which indicates relative to what the\noffset was given), and seek offsets. The first offset (cur) is the new\nposition to seek to, while the second offset (stop) is optional and\nspecifies a position where streaming is supposed to stop. Usually it is\nfine to just specify GST_SEEK_TYPE_NONE and -1 as end_method and end\noffset. The behaviour of a seek is also wrapped in the <code>gst_element_seek ()</code>.</p>\n<pre><code class=\"language-c\">static void\nseek_to_time (GstElement *pipeline,\n          gint64      time_nanoseconds)\n{\n  if (!gst_element_seek (pipeline, 1.0, GST_FORMAT_TIME, GST_SEEK_FLAG_FLUSH,\n                         GST_SEEK_TYPE_SET, time_nanoseconds,\n                         GST_SEEK_TYPE_NONE, GST_CLOCK_TIME_NONE)) {\n    g_print (\"Seek failed!\\n\");\n  }\n}\n\n</code></pre>\n<p>Seeks with the GST_SEEK_FLAG_FLUSH should be done when the pipeline\nis in PAUSED or PLAYING state. The pipeline will automatically go to\npreroll state until the new data after the seek will cause the pipeline\nto preroll again. After the pipeline is prerolled, it will go back to\nthe state (PAUSED or PLAYING) it was in when the seek was executed. You\ncan wait (blocking) for the seek to complete with\n<code>gst_element_get_state()</code> or by waiting for the ASYNC_DONE message to\nappear on the bus.</p>\n<p>Seeks without the GST_SEEK_FLAG_FLUSH should only be done when the\npipeline is in the PLAYING state. Executing a non-flushing seek in the\nPAUSED state might deadlock because the pipeline streaming threads might\nbe blocked in the sinks.</p>\n<p>It is important to realise that seeks will not happen instantly in the\nsense that they are finished when the function <code>gst_element_seek ()</code>\nreturns. Depending on the specific elements involved, the actual seeking\nmight be done later in another thread (the streaming thread), and it\nmight take a short time until buffers from the new seek position will\nreach downstream elements such as sinks (if the seek was non-flushing\nthen it might take a bit longer).</p>\n<p>It is possible to do multiple seeks in short time-intervals, such as a\ndirect response to slider movement. After a seek, internally, the\npipeline will be paused (if it was playing), the position will be re-set\ninternally, the demuxers and decoders will decode from the new position\nonwards and this will continue until all sinks have data again. If it\nwas playing originally, it will be set to playing again, too. Since the\nnew position is immediately available in a video output, you will see\nthe new frame, even if your pipeline is not in the playing state.</p>\n\n</div>\n\n\n        "});