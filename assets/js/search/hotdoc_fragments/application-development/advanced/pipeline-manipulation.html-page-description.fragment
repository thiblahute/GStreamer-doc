fragment_downloaded_cb({"url": "application-development/advanced/pipeline-manipulation.html#page-description", "fragment": "This chapter will discuss how you can manipulate your pipeline in several ways from your application on. Parts of this chapter are very lowlevel so be assured that you ll need some programming knowledge and a good understanding of GStreamer before you start reading this. \nTopics that will be discussed here include how you can insert data into a pipeline from your application how to read data from a pipeline how to manipulate the pipeline s speed length starting point and how to listen to a pipeline s data processing. \nProbing is best envisioned as a pad listener. Technically a probe is nothing more than a callback that can be attached to a pad. You can attach a probe using gst_pad_add_probe Similarly one can use the gst_pad_remove_probe to remove the callback again. The probe notifies you of any activity that happens on the pad like buffers events and queries. You can define what kind of notifications you are interested in when you add the probe. \nThe probe can notify you of the following activity on pads \nA buffer is pushed or pulled. You want to specify the GST_PAD_PROBE_TYPE_BUFFER when registering the probe. Because the pad can be scheduled in different ways it is possible to also specify in what scheduling mode you are interested with the optional GST_PAD_PROBE_TYPE_PUSH and GST_PAD_PROBE_TYPE_PULL flags. \nYou can use this probe to inspect modify or drop the buffer. See Data probes. \nA bufferlist is pushed. Use the GST_PAD_PROBE_TYPE_BUFFER_LIST when registering the probe. \nAn event travels over a pad. Use the GST_PAD_PROBE_TYPE_EVENT_DOWNSTREAM and GST_PAD_PROBE_TYPE_EVENT_UPSTREAM flags to select downstream and upstream events. There is also a convenience GST_PAD_PROBE_TYPE_EVENT_BOTH to be notified of events going both upstream and downstream. By default flush events do not cause a notification. You need to explicitly enable GST_PAD_PROBE_TYPE_EVENT_FLUSH to receive callbacks from flushing events. Events are always only notified in push mode. \nYou can use this probe to inspect modify or drop the event. \nA query travels over a pad. Use the GST_PAD_PROBE_TYPE_QUERY_DOWNSTREAM and GST_PAD_PROBE_TYPE_QUERY_UPSTREAM flags to select downstream and upstream queries. The convenience GST_PAD_PROBE_TYPE_QUERY_BOTH can also be used to select both directions. Query probes will be notified twice once when the query travels upstream downstream and once when the query result is returned. You can select in what stage the callback will be called with the GST_PAD_PROBE_TYPE_PUSH and GST_PAD_PROBE_TYPE_PULL respectively when the query is performed and when the query result is returned. \nYou can use this probe to inspect or modify the query. You can also answer the query in the probe callback by placing the result value in the query and by returning GST_PAD_PROBE_DROP from the callback. \nIn addition to notifying you of dataflow you can also ask the probe to block the dataflow when the callback returns. This is called a blocking probe and is activated by specifying the GST_PAD_PROBE_TYPE_BLOCK flag. You can use this flag with the other flags to only block dataflow on selected activity. A pad becomes unblocked again if you remove the probe or when you return GST_PAD_PROBE_REMOVE from the callback. You can let only the currently blocked item pass by returning GST_PAD_PROBE_PASS from the callback it will block again on the next item. \nBlocking probes are used to temporarily block pads because they are unlinked or because you are going to unlink them. If the dataflow is not blocked the pipeline would go into an error state if data is pushed on an unlinked pad. We will se how to use blocking probes to partially preroll a pipeline. See also Play a region of a media file. \nBe notified when no activity is happening on a pad. You install this probe with the GST_PAD_PROBE_TYPE_IDLE flag. You can specify GST_PAD_PROBE_TYPE_PUSH and or GST_PAD_PROBE_TYPE_PULL to only be notified depending on the pad scheduling mode. The IDLE probe is also a blocking probe in that it will not let any data pass on the pad for as long as the IDLE probe is installed. \nYou can use idle probes to dynamically relink a pad. We will see how to use idle probes to replace an element in the pipeline. See also Dynamically changing the pipeline. \nData probes allow you to be notified when there is data passing on a pad. When adding the probe specify the GST_PAD_PROBE_TYPE_BUFFER and or GST_PAD_PROBE_TYPE_BUFFER_LIST. \nData probes run in pipeline streaming thread context so callbacks should try to not block and generally not do any weird stuff since this could have a negative impact on pipeline performance or in case of bugs cause deadlocks or crashes. More precisely one should usually not call any GUI related functions from within a probe callback nor try to change the state of the pipeline. An application may post custom messages on the pipeline s bus though to communicate with the main application thread and have it do things like stop the pipeline. \nIn any case most common buffer operations that elements can do in _chain functions can be done in probe callbacks as well. The example below gives a short impression on how to use them. \nCompare that output with the output of gst launch videotestsrc xvimagesink just so you know what you re looking for. \nStrictly speaking a pad probe callback is only allowed to modify the buffer content if the buffer is writable. Whether this is the case or not depends a lot on the pipeline and the elements involved. Often enough this is the case but sometimes it is not and if it is not then unexpected modification of the data or metadata can introduce bugs that are very hard to debug and track down. You can check if a buffer is writable with gst_buffer_is_writable Since you can pass back a different buffer than the one passed in it is a good idea to make the buffer writable in the callback function with gst_buffer_make_writable \nPad probes are suited best for looking at data as it passes through the pipeline. If you need to modify data you should better write your own GStreamer element. Base classes like GstAudioFilter GstVideoFilter or GstBaseTransform make this fairly easy. \nIf you just want to inspect buffers as they pass through the pipeline you don t even need to set up pad probes. You could also just insert an identity element into the pipeline and connect to its handoff signal. The identity element also provides a few useful debugging tools like the dump property or the last message property the latter is enabled by passing the v switch to gst launch and by setting the silent property on the identity to FALSE \nIn this example we will show you how to play back a region of a media file. The goal is to only play the part of a file from seconds to seconds and then EOS. \nIn a first step we will set a uridecodebin element to the PAUSED state and make sure that we block all the source pads that are created. When all the source pads are blocked we have data on all source pads and we say that the uridecodebin is prerolled. \nIn a prerolled pipeline we can ask for the duration of the media and we can also perform seeks. We are interested in performing a seek operation on the pipeline to select the range of media that we are interested in. \nAfter we configure the region we are interested in we can link the sink element unblock the source pads and set the pipeline to the playing state. You will see that exactly the requested region is played by the sink before it goes to EOS. \nWhat follows is an example application that loosly follows this algorithm. \nNote that we use a custom application message to signal the main thread that the uridecidebin is prerolled. The main thread will then issue a flushing seek to the requested region. The flush will temporarily unblock the pad and reblock them when new data arrives again. We detect this second block to remove the probes. Then we set the pipeline to PLAYING and it should play from to seconds then EOS and exit the application. \nMany people have expressed the wish to use their own sources to inject data into a pipeline. Some people have also expressed the wish to grab the output in a pipeline and take care of the actual output inside their application. While either of these methods are strongly discouraged GStreamer offers support for this. Beware You need to know what you are doing. Since you don t have any support from a base class you need to thoroughly understand state changes and synchronization. If it doesn t work there are a million ways to shoot yourself in the foot. It s always better to simply write a plugin and have the base class manage it. See the Plugin Writer s Guide for more information on this topic. Also see the next section which will explain how to embed plugins statically in your application. \nThere s two possible elements that you can use for the above mentioned purposes. Those are called appsrc an imaginary source and appsink an imaginary sink The same method applies to each of those elements. Here we will discuss how to use those elements to insert using appsrc or grab using appsink data from a pipeline and how to set negotiation. \nBoth appsrc and appsink provide sets of API. One API uses standard GObject action signals and properties. The same API is also available as a regular C api. The C api is more performant but requires you to link to the app library in order to use the elements. \nFirst we look at some examples for appsrc which lets you insert data into the pipeline from the application. Appsrc has some configuration options that define how it will operate. You should decide about the following configurations \nWill the appsrc operate in push or pull mode. The stream type property can be used to control this. stream type of random access will activate pull mode scheduling while the other stream types activate push mode. \nThe caps of the buffers that appsrc will push out. This needs to be configured with the caps property. The caps must be set to a fixed caps and will be used to negotiate a format downstream. \nIf the appsrc operates in live mode or not. This can be configured with the is live property. When operating in live mode it is important to configure the min latency and max latency in appsrc. The min latency should be set to the amount of time it takes between capturing a buffer and when it is pushed inside appsrc. In live mode you should timestamp the buffers with the pipeline running time when the first byte of the buffer was captured before feeding them to appsrc. You can let appsrc do the timestaping with the do timestamp property but then the min latency must be set to because it timestamps based on the running time when the buffer entered appsrc \nThe format of the SEGMENT event that appsrc will push. The format has implications for how the running time of the buffers will be calculated so you must be sure you understand this. For live sources you probably want to set the format property to GST_FORMAT_TIME. For non live source it depends on the media type that you are handling. If you plan to timestamp the buffers you should probably put a GST_FORMAT_TIME format otherwise GST_FORMAT_BYTES might be appropriate. \nIf appsrc operates in random access mode it is important to configure the size property of appsrc with the number of bytes in the stream. This will allow downstream elements to know the size of the media and alows them to seek to the end of the stream when needed. \nThe main way of handling data to appsrc is by using the function gst_app_src_push_buffer or by emiting the push buffer action signal. This will put the buffer onto a queue from which appsrc will read from in its streaming thread. It is important to note that data transport will not happen from the thread that performed the push buffer call. \nThe max bytes property controls how much data can be queued in appsrc before appsrc considers the queue full. A filled internal queue will always signal the enough data signal which signals the application that it should stop pushing data into appsrc. The block property will cause appsrc to block the push buffer method until free data becomes available again. \nWhen the internal queue is running out of data the need data signal is emitted which signals the application that it should start pushing more data into appsrc. \nIn addition to the need data and enough data signals appsrc can emit the seek data signal when the stream mode property is set to seekable or random access The signal argument will contain the new desired position in the stream expressed in the unit set with the format property. After receiving the seek data signal the application should push buffers from the new position. \nWhen the last byte is pushed into appsrc you must call gst_app_src_end_of_stream to make it send an EOS downstream. \nThese signals allow the application to operate appsrc in push and pull mode as will be explained next. \nWhen appsrc is configured in push mode stream type is stream or seekable the application repeatedly calls the push buffer method with a new buffer. Optionally the queue size in the appsrc can be controlled with the enough data and need data signals by respectively stopping starting the push buffer calls. The value of the min percent property defines how empty the internal appsrc queue needs to be before the need data signal will be fired. You can set this to some value to avoid completely draining the queue. \nWhen the stream type is set to seekable don t forget to implement a seek data callback. \nUse this model when implementing various network protocols or hardware devices. \nIn the pull model data is fed to appsrc from the need data signal handler. You should push exactly the amount of bytes requested in the need data signal. You are only allowed to push less bytes when you are at the end of the stream. \nUse this model for file access or other randomly accessable sources. \nThis example application will generate black white it switches every second video to an Xv window output by using appsrc as a source with caps to force a format. We use a colorspace conversion element to make sure that we feed the right format to your X server. We configure a video stream with a variable framerate and we set the timestamps on the outgoing buffers in such a way that we play frames per second. \nNote how we use the pull mode method of pushing new buffers into appsrc although appsrc is running in push mode. \nUnlike appsrc appsink is a little easier to use. It also supports a pull and push based model of getting data from the pipeline. \nThe normal way of retrieving samples from appsink is by using the gst_app_sink_pull_sample and gst_app_sink_pull_preroll methods or by using the pull sample and pull preroll signals. These methods block until a sample becomes available in the sink or when the sink is shut down or reaches EOS. \nAppsink will internally use a queue to collect buffers from the streaming thread. If the application is not pulling samples fast enough this queue will consume a lot of memory over time. The max buffers property can be used to limit the queue size. The drop property controls whether the streaming thread blocks or if older buffers are dropped when the maximum queue size is reached. Note that blocking the streaming thread can negatively affect real time performance and should be avoided. \nIf a blocking behaviour is not desirable setting the emit signals property to TRUE will make appsink emit the new sample and new preroll signals when a sample can be pulled without blocking. \nThe caps property on appsink can be used to control the formats that appsink can receive. This property can contain non fixed caps the format of the pulled samples can be obtained by getting the sample caps. \nIf one of the pull preroll or pull sample methods return NULL the appsink is stopped or in the EOS state. You can check for the EOS state with the eos property or with the gst_app_sink_is_eos method. \nThe eos signal can also be used to be informed when the EOS state is reached to avoid polling. \nConsider configuring the following properties in the appsink \nThe sync property if you want to have the sink base class synchronize the buffer against the pipeline clock before handing you the sample. \nEnable Quality of Service with the qos property. If you are dealing with raw video frames and let the base class sycnhronize on the clock it might be a good idea to also let the base class send QOS events upstream. \nThe caps property that contains the accepted caps. Upstream elements will try to convert the format so that it matches the configured caps on appsink. You must still check the GstSample to get the actual caps of the buffer. \nWhat follows is an example on how to capture a snapshot of a video stream using appsink. \nSometimes you ll want to set a specific format for example a video size and format or an audio bitsize and number of channels. You can do this by forcing a specific GstCaps on the pipeline which is possible by using filtered caps. You can set a filtered caps on a link by using the capsfilter element in between the two elements and specifying a GstCaps as caps property on this element. It will then only allow types matching that specified capability set for negotiation. See also Creating capabilities for filtering. \nIt is also possible to dynamically change the format in a pipeline while PLAYING. This can simply be done by changing the caps property on a capsfilter. The capsfilter will send a RECONFIGURE event upstream that will make the upstream element attempt to renegotiate a new format and allocator. This only works if the upstream element is not using fixed caps on the source pad. \nBelow is an example of how you can change the caps of a pipeline while in the PLAYING state \nNote how we use gst_bus_poll with a small timeout to get messages and also introduce a short sleep. \nIt is possible to set multiple caps for the capsfilter separated with a The capsfilter will try to renegotiate to the first possible format from the list. \nIn this section we talk about some techniques for dynamically modifying the pipeline. We are talking specifically about changing the pipeline while it is in the PLAYING state without interrupting the flow. \nThere are some important things to consider when building dynamic pipelines \nWhen removing elements from the pipeline make sure that there is no dataflow on unlinked pads because that will cause a fatal pipeline error. Always block source pads in push mode or sink pads in pull mode before unlinking pads. See also Changing elements in a pipeline. \nWhen adding elements to a pipeline make sure to put the element into the right state usually the same state as the parent before allowing dataflow the element. When an element is newly created it is in the NULL state and will return an error when it receives data. See also Changing elements in a pipeline. \nWhen adding elements to a pipeline GStreamer will by default set the clock and base time on the element to the current values of the pipeline. This means that the element will be able to construct the same pipeline running time as the other elements in the pipeline. This means that sinks will synchronize buffers like the other sinks in the pipeline and that sources produce buffers with a running time that matches the other sources. \nWhen unlinking elements from an upstream chain always make sure to flush any queued data in the element by sending an EOS event down the element sink pad s and by waiting that the EOS leaves the elements with an event probe \nIf you do not do this you will lose the data which is buffered by the unlinked element. This can result in a simple frame loss one or more video frames several milliseconds of audio However if you remove a muxer and in some cases an encoder or similar elements from the pipeline you risk getting a corrupted file which could not be played properly as some relevant metadata header seek index tables internal sync tags will not be stored or updated properly. \nSee also Changing elements in a pipeline. \nA live source will produce buffers with a running time of the current running time in the pipeline. \nA pipeline without a live source produces buffers with a running time starting from Likewise after a flushing seek those pipelines reset the running time back to \nThe running time can be changed with gst_pad_set_offset It is important to know the running time of the elements in the pipeline in order to maintain synchronization. \nAdding elements might change the state of the pipeline. Adding a non prerolled sink for example brings the pipeline back to the prerolling state. Removing a non prerolled sink for example might change the pipeline to PAUSED and PLAYING state. \nAdding a live source cancels the preroll stage and put the pipeline to the playing state. Adding a live source or other live elements might also change the latency of a pipeline. \nAdding or removing elements to the pipeline might change the clock selection of the pipeline. If the newly added element provides a clock it might be worth changing the clock in the pipeline to the new clock. If on the other hand the element that provides the clock for the pipeline is removed a new clock has to be selected. \nAdding and removing elements might cause upstream or downstream elements to renegotiate caps and or allocators. You don t really need to do anything from the application plugins largely adapt themself to the new pipeline topology in order to optimize their formats and allocation strategy. \nWhat is important is that when you add remove or change elements in the pipeline it is possible that the pipeline needs to negotiate a new format and this can fail. Usually you can fix this by inserting the right converter elements where needed. See also Changing elements in a pipeline. \nGStreamer offers support for doing about any dynamic pipeline modification but it requires you to know a bit of details before you can do this without causing pipeline errors. In the following sections we will demonstrate a couple of typical use cases. \nIn the next example we look at the following chain of elements \nWe want to change element2 by element4 while the pipeline is in the PLAYING state. Let s say that element2 is a visualization and that you want to switch the visualization in the pipeline. \nWe can t just unlink element2 s sinkpad from element1 s source pad because that would leave element1 s source pad unlinked and would cause a streaming error in the pipeline when data is pushed on the source pad. The technique is to block the dataflow from element1 s source pad before we change element2 by element4 and then resume dataflow as shown in the following steps \nBlock element1 s source pad with a blocking pad probe. When the pad is blocked the probe callback will be called. \nInside the block callback nothing is flowing between element1 and element2 and nothing will flow until unblocked. \nUnlink element1 and element2. \nMake sure data is flushed out of element2. Some elements might internally keep some data you need to make sure not to lose data by forcing it out of element2. You can do this by pushing EOS into element2 like this \nPut an event probe on element2 s source pad. \nSend EOS to element2 s sinkpad. This makes sure the all the data inside element2 is forced out. \nWait for the EOS event to appear on element2 s source pad. When the EOS is received drop it and remove the event probe. \nUnlink element2 and element3. You can now also remove element2 from the pipeline and set the state to NULL. \nAdd element4 to the pipeline if not already added. Link element4 and element3. Link element1 and element4. \nMake sure element4 is in the same state as the rest of the elements in the pipeline. It should be at least in the PAUSED state before it can receive buffers and events. \nUnblock element1 s source pad probe. This will let new data into element4 and continue streaming. \nThe above algorithm works when the source pad is blocked i.e. when there is dataflow in the pipeline. If there is no dataflow there is also no point in changing the element just yet so this algorithm can be used in the PAUSED state as well. \nLet show you how this works with an example. This example changes the video effect on a simple pipeline every second. \nNote how we added videoconvert elements before and after the effect. This is needed because some elements might operate in different colorspaces than other elements. By inserting the conversion elements you ensure that the right format can be negotiated at any time. \n"});