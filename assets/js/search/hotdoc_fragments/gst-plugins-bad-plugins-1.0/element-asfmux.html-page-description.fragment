fragment_downloaded_cb({"url": "gst-plugins-bad-plugins-1.0/element-asfmux.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"element-asfmux\">\n<h1 id=\"asfmux\">asfmux</h1><p>Muxes media into an ASF file/stream.</p>\n<p>Pad names are either video_xx or audio_xx, where 'xx' is the\nstream number of the stream that goes through that pad. Stream numbers\nare assigned sequentially, starting from 1.</p>\n<h2 id=\"example-launch-lines\">Example launch lines</h2>\n<p>(write everything in one line, without the backslash characters)</p>\n<pre><code class=\"language-[\"> gst-launch-1.0 videotestsrc num-buffers=250 \\\n ! \"video/x-raw,format=(string)I420,framerate=(fraction)25/1\" ! avenc_wmv2 \\\n ! asfmux name=mux ! filesink location=test.asf \\\n audiotestsrc num-buffers=440 ! audioconvert \\\n ! \"audio/x-raw,rate=44100\" ! avenc_wmav2 ! mux.\n ]| This creates an ASF file containing an WMV video stream\n with a test picture and WMA audio stream of a test sound.\n\n ## Live streaming\n asfmux and rtpasfpay are capable of generating a live asf stream.\n asfmux has to set its 'streamable' property to true, because in this\n mode it won't try to seek back to the start of the file to replace\n some fields that couldn't be known at the file start. In this mode,\n it won't also send indexes at the end of the data packets (the actual\n media content)\n the following pipelines are an example of this usage.\n (write everything in one line, without the backslash characters)\n Server (sender)\n |[\n gst-launch-1.0 -ve videotestsrc ! avenc_wmv2 ! asfmux name=mux streamable=true \\\n ! rtpasfpay ! udpsink host=127.0.0.1 port=3333 \\\n audiotestsrc ! avenc_wmav2 ! mux.\n</code></pre>\n<p>Client (receiver)</p>\n<pre><code class=\"language-[\"> gst-launch-1.0 udpsrc port=3333 ! \"caps_from_rtpasfpay_at_sender\" \\\n ! rtpasfdepay ! decodebin name=d ! queue \\\n ! videoconvert ! autovideosink \\\n d. ! queue ! audioconvert ! autoaudiosink\n</code></pre>\n\n</div>\n\n\n        "});