fragment_downloaded_cb({"url": "GStreamer-doc-1.0/design/latency.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"latency.md\">\n<h1 id=\"latency\">Latency</h1>\n<p>The latency is the time it takes for a sample captured at timestamp 0 to\nreach the sink. This time is measured against the pipeline's clock.\nFor pipelines where the only elements that synchronize against the clock\nare the sinks, the latency is always 0, since no other element is\ndelaying the buffer.</p>\n<p>For pipelines with live sources, a latency is introduced, mostly because\nof the way a live source works. Consider an audio source, it will start\ncapturing the first sample at time 0. If the source pushes buffers with\n44100 samples at a time at 44100Hz, it will have collected the buffer at\nsecond 1. Since the timestamp of the buffer is 0 and the time of the\nclock is now &gt;= 1 second, the sink will drop this buffer because it is\ntoo late. Without any latency compensation in the sink, all buffers will\nbe dropped.</p>\n<p>The situation becomes more complex in the presence of:</p>\n<ul>\n<li>\n<p>2 live sources connected to 2 live sinks with different latencies</p>\n<ul>\n<li>audio/video capture with synchronized live preview.</li>\n<li>added latencies due to effects (delays, resamplers\u2026)</li>\n</ul>\n</li>\n<li>\n<p>1 live source connected to 2 live sinks</p>\n<ul>\n<li>firewire DV</li>\n<li>RTP, with added latencies because of jitter buffers.</li>\n</ul>\n</li>\n<li>\n<p>mixed live source and non-live source scenarios.</p>\n<ul>\n<li>synchronized audio capture with non-live playback. (overdubs,..)</li>\n</ul>\n</li>\n<li>\n<p>clock slaving in the sinks due to the live sources providing their\nown clocks.</p>\n</li>\n</ul>\n<p>To perform the needed latency corrections in the above scenarios, we\nmust develop an algorithm to calculate a global latency for the\npipeline. This algorithm must be extensible, so that it can optimize the\nlatency at runtime. It must also be possible to disable or tune the\nalgorithm based on specific application needs (required minimal\nlatency).</p>\n<h2 id=\"pipelines-without-latency-compensation\">Pipelines without latency compensation</h2>\n<p>We show some examples to demonstrate the problem of latency in typical\ncapture pipelines.</p>\n<h3 id=\"example-1\">Example 1</h3>\n<p>An audio capture/playback pipeline.</p>\n<ul>\n<li>asrc: audio source, provides a clock</li>\n<li>asink audio sink, provides a clock</li>\n</ul>\n<pre><code>.--------------------------.\n| pipeline                 |\n| .------.      .-------.  |\n| | asrc |      | asink |  |\n| |     src -&gt; sink     |  |\n| '------'      '-------'  |\n'--------------------------'\n</code></pre>\n<ul>\n<li>\n<p><em>NULL\u2192READY</em>:</p>\n<ul>\n<li>asink: <em>NULL\u2192READY</em>: probes device, returns <code>SUCCESS</code></li>\n<li>asrc: <em>NULL\u2192READY</em>:  probes device, returns <code>SUCCESS</code></li>\n</ul>\n</li>\n<li>\n<p><em>READY\u2192PAUSED</em>:</p>\n<ul>\n<li>asink: <em>READY:\u2192PAUSED</em> open device, returns <code>ASYNC</code></li>\n<li>asrc: <em>READY\u2192PAUSED</em>:  open device, returns <code>NO_PREROLL</code></li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>\n<p>Since the source is a live source, it will only produce data in\nthe <code>PLAYING</code> state. To note this fact, it returns <code>NO_PREROLL</code>\nfrom the state change function.</p>\n</li>\n<li>\n<p>This sink returns <code>ASYNC</code> because it can only complete the state\nchange to <code>PAUSED</code> when it receives the first buffer.</p>\n</li>\n</ul>\n<p>At this point the pipeline is not processing data and the clock is not\nrunning. Unless a new action is performed on the pipeline, this situation will\nnever change.</p>\n<ul>\n<li>\n<p><em>PAUSED\u2192PLAYING</em>: asrc clock selected because it is the most upstream clock\nprovider. asink can only provide a clock when it received the first buffer and\nconfigured the device with the samplerate in the caps.</p>\n</li>\n<li>\n<p>sink: <em>PAUSED:\u2192PLAYING</em>, sets pending state to <code>PLAYING</code>, returns <code>ASYNC</code> because it\nis not prerolled. The sink will commit state to <code>PLAYING</code> when it prerolls.</p>\n</li>\n<li>\n<p>src: <em>PAUSED\u2192PLAYING</em>: starts pushing buffers.</p>\n</li>\n</ul>\n<ul>\n<li>\n<p>since the sink is still performing a state change from <code>READY\u2192PAUSED</code>, it remains ASYNC. The pending state will be set to\nPLAYING.</p>\n</li>\n<li>\n<p>The clock starts running as soon as all the elements have been\nset to PLAYING.</p>\n</li>\n<li>\n<p>the source is a live source with a latency. Since it is\nsynchronized with the clock, it will produce a buffer with\ntimestamp 0 and duration D after time D, ie. it will only be\nable to produce the last sample of the buffer (with timestamp D)\nat time D. This latency depends on the size of the buffer.</p>\n</li>\n<li>\n<p>the sink will receive the buffer with timestamp 0 at time &gt;= D.\nAt this point the buffer is too late already and might be\ndropped. This state of constantly dropping data will not change\nunless a constant latency correction is added to the incoming\nbuffer timestamps.</p>\n</li>\n</ul>\n<p>The problem is due to the fact that the sink is set to (pending) PLAYING\nwithout being prerolled, which only happens in live pipelines.</p>\n<h3 id=\"example-2\">Example 2</h3>\n<p>An audio/video capture/playback pipeline. We capture both audio and video and\nhave them played back synchronized again.</p>\n<ul>\n<li>asrc: audio source, provides a clock</li>\n<li>asink audio sink, provides a clock</li>\n<li>vsrc: video source</li>\n<li>vsink video sink</li>\n</ul>\n<pre><code>.--------------------------.\n| pipeline                 |\n| .------.      .-------.  |\n| | asrc |      | asink |  |\n| |     src -&gt; sink     |  |\n| '------'      '-------'  |\n| .------.      .-------.  |\n| | vsrc |      | vsink |  |\n| |     src -&gt; sink     |  |\n| '------'      '-------'  |\n'--------------------------'\n</code></pre>\n<p>The state changes happen in the same way as example 1. Both sinks end up with\npending state of <code>PLAYING</code> and a return value of ASYNC until they receive the\nfirst buffer.</p>\n<p>For audio and video to be played in sync, both sinks must compensate for the\nlatency of its source but must also use exactly the same latency correction.</p>\n<p>Suppose asrc has a latency of 20ms and vsrc a latency of 33ms, the total\nlatency in the pipeline has to be at least 33ms. This also means that the\npipeline must have at least a 33 - 20 = 13ms buffering on the audio stream or\nelse the audio src will underrun while the audiosink waits for the previous\nsample to play.</p>\n<h3 id=\"example-3\">Example 3</h3>\n<p>An example of the combination of a non-live (file) and a live source (vsrc)\nconnected to live sinks (vsink, sink).</p>\n<pre><code>.--------------------------.\n| pipeline                 |\n| .------.      .-------.  |\n| | file |      | sink  |  |\n| |     src -&gt; sink     |  |\n| '------'      '-------'  |\n| .------.      .-------.  |\n| | vsrc |      | vsink |  |\n| |     src -&gt; sink     |  |\n| '------'      '-------'  |\n'--------------------------'\n</code></pre>\n<p>The state changes happen in the same way as example 1. Except sink will be\nable to preroll (commit its state to PAUSED).</p>\n<p>In this case sink will have no latency but vsink will. The total latency\nshould be that of vsink.</p>\n<p>Note that because of the presence of a live source (vsrc), the pipeline can be\nset to playing before the sink is able to preroll. Without compensation for the\nlive source, this might lead to synchronisation problems because the latency\nshould be configured in the element before it can go to PLAYING.</p>\n<h3 id=\"example-4\">Example 4</h3>\n<p>An example of the combination of a non-live and a live source. The non-live\nsource is connected to a live sink and the live source to a non-live sink.</p>\n<pre><code>.--------------------------.\n| pipeline                 |\n| .------.      .-------.  |\n| | file |      | sink  |  |\n| |     src -&gt; sink     |  |\n| '------'      '-------'  |\n| .------.      .-------.  |\n| | vsrc |      | files |  |\n| |     src -&gt; sink     |  |\n| '------'      '-------'  |\n'--------------------------'\n</code></pre>\n<p>The state changes happen in the same way as example 3. Sink will be\nable to preroll (commit its state to PAUSED). files will not be able to\npreroll.</p>\n<p>sink will have no latency since it is not connected to a live source. files\ndoes not do synchronisation so it does not care about latency.</p>\n<p>The total latency in the pipeline is 0. The vsrc captures in sync with the\nplayback in sink.</p>\n<p>As in example 3, sink can only be set to <code>PLAYING</code> after it successfully\nprerolled.</p>\n<h2 id=\"state-changes\">State Changes</h2>\n<p>A sink is never set to <code>PLAYING</code> before it is prerolled. In order to do\nthis, the pipeline (at the <code>GstBin</code> level) keeps track of all elements\nthat require preroll (the ones that return ASYNC from the state change).\nThese elements posted an <code>ASYNC_START</code> message without a matching\n<code>ASYNC_DONE</code> one.</p>\n<p>The pipeline will not change the state of the elements that are still\ndoing an ASYNC state change.</p>\n<p>When an ASYNC element prerolls, it commits its state to PAUSED and posts\nan <code>ASYNC_DONE</code> message. The pipeline notices this <code>ASYNC_DONE</code> message\nand matches it with the <code>ASYNC_START</code> message it cached for the\ncorresponding element.</p>\n<p>When all <code>ASYNC_START</code> messages are matched with an <code>ASYNC_DONE</code> message,\nthe pipeline proceeds with setting the elements to the final state\nagain.</p>\n<p>The base time of the element was already set by the pipeline when it\nchanged the NO_PREROLL element to PLAYING. This operation has to be\nperformed in the separate async state change thread (like the one\ncurrently used for going from <code>PAUSED\u2192PLAYING</code> in a non-live pipeline).</p>\n<h2 id=\"query\">Query</h2>\n<p>The pipeline latency is queried with the LATENCY query.</p>\n<ul>\n<li>\n<p><strong><code>live</code></strong> <code>G_TYPE_BOOLEAN</code> (default FALSE): - if a live element is found upstream</p>\n</li>\n<li>\n<p><strong><code>min-latency</code></strong> <code>G_TYPE_UINT64</code> (default 0, must not be NONE): - the minimum\nlatency in the pipeline, meaning the minimum time downstream elements\nsynchronizing to the clock have to wait until they can be sure all data\nfor the current running time has been received.</p>\n</li>\n</ul>\n<p>Elements answering the latency query and introducing latency must\nset this to the maximum time for which they will delay data, while\nconsidering upstream's minimum latency. As such, from an element's\nperspective this is <em>not</em> its own minimum latency but its own\nmaximum latency.\nConsidering upstream's minimum latency generally means that the\nelement's own value is added to upstream's value, as this will give\nthe overall minimum latency of all elements from the source to the\ncurrent element:</p>\n<pre><code>min_latency = upstream_min_latency + own_min_latency\n</code></pre>\n<ul>\n<li><strong><code>max-latency</code></strong> <code>G_TYPE_UINT64</code> (default 0, NONE meaning infinity): - the\nmaximum latency in the pipeline, meaning the maximum time an element\nsynchronizing to the clock is allowed to wait for receiving all data for the\ncurrent running time. Waiting for a longer time will result in data loss,\nbuffer overruns and underruns and, in general, breaks synchronized data flow\nin the pipeline.</li>\n</ul>\n<p>Elements answering the latency query should set this to the maximum\ntime for which they can buffer upstream data without blocking or\ndropping further data. For an element, this value will generally be\nits own minimum latency, but might be bigger than that if it can\nbuffer more data. As such, queue elements can be used to increase\nthe maximum latency.</p>\n<p>The value set in the query should again consider upstream's maximum\nlatency:</p>\n<ul>\n<li>If the current element has blocking buffering, i.e. it does not drop data by\nitself when its internal buffer is full, it should just add its own maximum\nlatency (i.e. the size of its internal buffer) to upstream's value. If\nupstream's maximum latency, or the elements internal maximum latency was NONE\n(i.e. infinity), it will be set to infinity.</li>\n</ul>\n<pre><code>if (upstream_max_latency == NONE || own_max_latency == NONE)\n  max_latency = NONE;\nelse\n  max_latency = upstream_max_latency + own_max_latency\n</code></pre>\n<p>If the element has multiple sinkpads, the minimum upstream latency is\nthe maximum of all live upstream minimum latencies.</p>\n<p>If the current element has leaky buffering, i.e. it drops data by itself\nwhen its internal buffer is full, it should take the minimum of its own\nmaximum latency and upstream\u2019s. Examples for such elements are audio sinks\nand sources with an internal ringbuffer, leaky queues and in general live\nsources with a limited amount of internal buffers that can be used.</p>\n<pre><code>    max_latency = MIN (upstream_max_latency, own_max_latency)\n</code></pre>\n<blockquote>\n<p>Note: many GStreamer base classes allow subclasses to set a\nminimum and maximum latency and handle the query themselves. These\nbase classes assume non-leaky (i.e. blocking) buffering for the\nmaximum latency. The base class' default query handler needs to be\noverridden to correctly handle leaky buffering.</p>\n</blockquote>\n<p>If the element has multiple sinkpads, the maximum upstream latency is the\nminimum of all live upstream maximum latencies.</p>\n<h2 id=\"event\">Event</h2>\n<p>The latency in the pipeline is configured with the LATENCY event, which\ncontains the following fields:</p>\n<ul>\n<li><strong><code>latency</code></strong> <code>G_TYPE_UINT64</code>: the configured latency in the pipeline</li>\n</ul>\n<h2 id=\"latency-compensation\">Latency compensation</h2>\n<p>Latency calculation and compensation is performed before the pipeline\nproceeds to the <code>PLAYING</code> state.</p>\n<p>When the pipeline collected all <code>ASYNC_DONE</code> messages it can calculate\nthe global latency as follows:</p>\n<ul>\n<li>perform a latency query on all sinks</li>\n<li>sources set their minimum and maximum latency</li>\n<li>other elements add their own values as described above</li>\n<li>latency = MAX (all min latencies)</li>\n<li>if MIN (all max latencies) &lt; latency, we have an impossible\nsituation and we must generate an error indicating that this\npipeline cannot be played. This usually means that there is not\nenough buffering in some chain of the pipeline. A queue can be added\nto those chains.</li>\n</ul>\n<p>The sinks gather this information with a LATENCY query upstream.\nIntermediate elements pass the query upstream and add the amount of\nlatency they add to the result.</p>\n<pre><code>ex1: sink1: \\[20 - 20\\] sink2: \\[33 - 40\\]\n\n    MAX (20, 33) = 33\n    MIN (20, 40) = 20 &lt; 33 -&gt; impossible\n\nex2: sink1: \\[20 - 50\\] sink2: \\[33 - 40\\]\n\n    MAX (20, 33) = 33\n    MIN (50, 40) = 40 &gt;= 33 -&gt; latency = 33\n</code></pre>\n<p>The latency is set on the pipeline by sending a LATENCY event to the\nsinks in the pipeline. This event configures the total latency on the\nsinks. The sink forwards this LATENCY event upstream so that\nintermediate elements can configure themselves as well.</p>\n<p>After this step, the pipeline continues setting the pending state on its\nelements.</p>\n<p>A sink adds the latency value, received in the LATENCY event, to the\ntimes used for synchronizing against the clock. This will effectively\ndelay the rendering of the buffer with the required latency. Since this\ndelay is the same for all sinks, all sinks will render data relatively\nsynchronised.</p>\n<h2 id=\"flushing-a-playing-pipeline\">Flushing a playing pipeline</h2>\n<p>We can implement resynchronisation after an uncontrolled FLUSH in (part\nof) a pipeline in the same way. Indeed, when a flush is performed on a\nPLAYING live element, a new base time must be distributed to this\nelement.</p>\n<p>A flush in a pipeline can happen in the following cases:</p>\n<ul>\n<li>\n<p>flushing seek in the pipeline</p>\n</li>\n<li>\n<p>performed by the application on the pipeline</p>\n</li>\n<li>\n<p>performed by the application on an element</p>\n</li>\n<li>\n<p>flush preformed by an element</p>\n</li>\n<li>\n<p>after receiving a navigation event (DVD, \u2026)</p>\n</li>\n</ul>\n<p>When a playing sink is flushed by a <code>FLUSH_START</code> event, an <code>ASYNC_START</code>\nmessage is posted by the element. As part of the message, the fact that\nthe element got flushed is included. The element also goes to a pending\nPAUSED state and has to be set to the <code>PLAYING</code> state again later.</p>\n<p>The <code>ASYNC_START</code> message is kept by the parent bin. When the element\nprerolls, it posts an <code>ASYNC_DONE</code> message.</p>\n<p>When all <code>ASYNC_START</code> messages are matched with an <code>ASYNC_DONE</code> message,\nthe bin will capture a new base_time from the clock and will bring all\nthe sinks back to <code>PLAYING</code> after setting the new base time on them. It\u2019s\nalso possible to perform additional latency calculations and adjustments\nbefore doing this.</p>\n<h2 id=\"dynamically-adjusting-latency\">Dynamically adjusting latency</h2>\n<p>An element that wants to change the latency in the pipeline can do this\nby posting a LATENCY message on the bus. This message instructs the\npipeline to:</p>\n<ul>\n<li>\n<p>query the latency in the pipeline (which might now have changed)\nwith a LATENCY query.</p>\n</li>\n<li>\n<p>redistribute a new global latency to all elements with a LATENCY\nevent.</p>\n</li>\n</ul>\n<p>A use case where the latency in a pipeline can change could be a network\nelement that observes an increased inter-packet arrival jitter or\nexcessive packet loss and decides to increase its internal buffering\n(and thus the latency). The element must post a LATENCY message and\nperform the additional latency adjustments when it receives the LATENCY\nevent from the downstream peer element.</p>\n<p>In a similar way, the latency can be decreased when network conditions\nimprove.</p>\n<p>Latency adjustments will introduce playback glitches in the sinks and\nmust only be performed in special conditions.</p>\n\n</div>\n\n\n\t"});