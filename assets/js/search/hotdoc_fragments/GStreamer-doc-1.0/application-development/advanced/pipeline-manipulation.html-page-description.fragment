fragment_downloaded_cb({"url": "GStreamer-doc-1.0/application-development/advanced/pipeline-manipulation.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"pipeline-manipulation.md\">\n<h1 id=\"pipeline-manipulation\">Pipeline manipulation</h1>\n<p>This chapter will discuss how you can manipulate your pipeline in\nseveral ways from your application on. Parts of this chapter are very\nlowlevel, so be assured that you'll need some programming knowledge and\na good understanding of GStreamer before you start reading this.</p>\n<p>Topics that will be discussed here include how you can insert data into\na pipeline from your application, how to read data from a pipeline, how\nto manipulate the pipeline's speed, length, starting point and how to\nlisten to a pipeline's data processing.</p>\n<h2 id=\"using-probes\">Using probes</h2>\n<p>Probing is best envisioned as a pad listener. Technically, a probe is\nnothing more than a callback that can be attached to a pad. You can\nattach a probe using <code>gst_pad_add_probe ()</code>. Similarly, one can use the\n<code>gst_pad_remove_probe ()</code> to remove the callback again. The probe\nnotifies you of any activity that happens on the pad, like buffers,\nevents and queries. You can define what kind of notifications you are\ninterested in when you add the probe.</p>\n<p>The probe can notify you of the following activity on pads:</p>\n<ul>\n<li>\n<p>A buffer is pushed or pulled. You want to specify the\nGST_PAD_PROBE_TYPE_BUFFER when registering the probe. Because\nthe pad can be scheduled in different ways, it is possible to also\nspecify in what scheduling mode you are interested with the optional\nGST_PAD_PROBE_TYPE_PUSH and GST_PAD_PROBE_TYPE_PULL flags.</p>\n<p>You can use this probe to inspect, modify or drop the buffer. See\n<a href=\"../../#data-probes\">Data probes</a>.</p>\n</li>\n<li>\n<p>A bufferlist is pushed. Use the GST_PAD_PROBE_TYPE_BUFFER_LIST\nwhen registering the probe.</p>\n</li>\n<li>\n<p>An event travels over a pad. Use the\nGST_PAD_PROBE_TYPE_EVENT_DOWNSTREAM and\nGST_PAD_PROBE_TYPE_EVENT_UPSTREAM flags to select downstream\nand upstream events. There is also a convenience\nGST_PAD_PROBE_TYPE_EVENT_BOTH to be notified of events going\nboth upstream and downstream. By default, flush events do not cause\na notification. You need to explicitly enable\nGST_PAD_PROBE_TYPE_EVENT_FLUSH to receive callbacks from\nflushing events. Events are always only notified in push mode.</p>\n<p>You can use this probe to inspect, modify or drop the event.</p>\n</li>\n<li>\n<p>A query travels over a pad. Use the\nGST_PAD_PROBE_TYPE_QUERY_DOWNSTREAM and\nGST_PAD_PROBE_TYPE_QUERY_UPSTREAM flags to select downstream\nand upstream queries. The convenience\nGST_PAD_PROBE_TYPE_QUERY_BOTH can also be used to select both\ndirections. Query probes will be notified twice, once when the query\ntravels upstream/downstream and once when the query result is\nreturned. You can select in what stage the callback will be called\nwith the GST_PAD_PROBE_TYPE_PUSH and\nGST_PAD_PROBE_TYPE_PULL, respectively when the query is\nperformed and when the query result is returned.</p>\n<p>You can use this probe to inspect or modify the query. You can also\nanswer the query in the probe callback by placing the result value\nin the query and by returning GST_PAD_PROBE_DROP from the\ncallback.</p>\n</li>\n<li>\n<p>In addition to notifying you of dataflow, you can also ask the probe\nto block the dataflow when the callback returns. This is called a\nblocking probe and is activated by specifying the\nGST_PAD_PROBE_TYPE_BLOCK flag. You can use this flag with the\nother flags to only block dataflow on selected activity. A pad\nbecomes unblocked again if you remove the probe or when you return\nGST_PAD_PROBE_REMOVE from the callback. You can let only the\ncurrently blocked item pass by returning GST_PAD_PROBE_PASS from\nthe callback, it will block again on the next item.</p>\n<p>Blocking probes are used to temporarily block pads because they are\nunlinked or because you are going to unlink them. If the dataflow is\nnot blocked, the pipeline would go into an error state if data is\npushed on an unlinked pad. We will se how to use blocking probes to\npartially preroll a pipeline. See also <a href=\"../../#play-a-region-of-a-media-file\">Play a region of a media\nfile</a>.</p>\n</li>\n<li>\n<p>Be notified when no activity is happening on a pad. You install this\nprobe with the GST_PAD_PROBE_TYPE_IDLE flag. You can specify\nGST_PAD_PROBE_TYPE_PUSH and/or GST_PAD_PROBE_TYPE_PULL to\nonly be notified depending on the pad scheduling mode. The IDLE\nprobe is also a blocking probe in that it will not let any data pass\non the pad for as long as the IDLE probe is installed.</p>\n<p>You can use idle probes to dynamically relink a pad. We will see how\nto use idle probes to replace an element in the pipeline. See also\n<a href=\"../../#dynamically-changing-the-pipeline\">Dynamically changing the\npipeline</a>.</p>\n</li>\n</ul>\n<h3 id=\"data-probes\">Data probes</h3>\n<p>Data probes allow you to be notified when there is data passing on a\npad. When adding the probe, specify the GST_PAD_PROBE_TYPE_BUFFER\nand/or GST_PAD_PROBE_TYPE_BUFFER_LIST.</p>\n<p>Data probes run in pipeline streaming thread context, so callbacks\nshould try to not block and generally not do any weird stuff, since this\ncould have a negative impact on pipeline performance or, in case of\nbugs, cause deadlocks or crashes. More precisely, one should usually not\ncall any GUI-related functions from within a probe callback, nor try to\nchange the state of the pipeline. An application may post custom\nmessages on the pipeline's bus though to communicate with the main\napplication thread and have it do things like stop the pipeline.</p>\n<p>In any case, most common buffer operations that elements can do in\n<code>_chain ()</code> functions, can be done in probe callbacks as well. The\nexample below gives a short impression on how to use them.</p>\n<pre><code class=\"language-c\">\n\n#include &lt;gst/gst.h&gt;\n\nstatic GstPadProbeReturn\ncb_have_data (GstPad          *pad,\n              GstPadProbeInfo *info,\n              gpointer         user_data)\n{\n  gint x, y;\n  GstMapInfo map;\n  guint16 *ptr, t;\n  GstBuffer *buffer;\n\n  buffer = GST_PAD_PROBE_INFO_BUFFER (info);\n\n  buffer = gst_buffer_make_writable (buffer);\n\n  /* Making a buffer writable can fail (for example if it\n   * cannot be copied and is used more than once)\n   */\n  if (buffer == NULL)\n    return GST_PAD_PROBE_OK;\n\n  /* Mapping a buffer can fail (non-writable) */\n  if (gst_buffer_map (buffer, &amp;map, GST_MAP_WRITE)) {\n    ptr = (guint16 *) map.data;\n    /* invert data */\n    for (y = 0; y &lt; 288; y++) {\n      for (x = 0; x &lt; 384 / 2; x++) {\n        t = ptr[384 - 1 - x];\n        ptr[384 - 1 - x] = ptr[x];\n        ptr[x] = t;\n      }\n      ptr += 384;\n    }\n    gst_buffer_unmap (buffer, &amp;map);\n  }\n\n  GST_PAD_PROBE_INFO_DATA (info) = buffer;\n\n  return GST_PAD_PROBE_OK;\n}\n\ngint\nmain (gint   argc,\n      gchar *argv[])\n{\n  GMainLoop *loop;\n  GstElement *pipeline, *src, *sink, *filter, *csp;\n  GstCaps *filtercaps;\n  GstPad *pad;\n\n  /* init GStreamer */\n  gst_init (&amp;argc, &amp;argv);\n  loop = g_main_loop_new (NULL, FALSE);\n\n  /* build */\n  pipeline = gst_pipeline_new (\"my-pipeline\");\n  src = gst_element_factory_make (\"videotestsrc\", \"src\");\n  if (src == NULL)\n    g_error (\"Could not create 'videotestsrc' element\");\n\n  filter = gst_element_factory_make (\"capsfilter\", \"filter\");\n  g_assert (filter != NULL); /* should always exist */\n\n  csp = gst_element_factory_make (\"videoconvert\", \"csp\");\n  if (csp == NULL)\n    g_error (\"Could not create 'videoconvert' element\");\n\n  sink = gst_element_factory_make (\"xvimagesink\", \"sink\");\n  if (sink == NULL) {\n    sink = gst_element_factory_make (\"ximagesink\", \"sink\");\n    if (sink == NULL)\n      g_error (\"Could not create neither 'xvimagesink' nor 'ximagesink' element\");\n  }\n\n  gst_bin_add_many (GST_BIN (pipeline), src, filter, csp, sink, NULL);\n  gst_element_link_many (src, filter, csp, sink, NULL);\n  filtercaps = gst_caps_new_simple (\"video/x-raw\",\n               \"format\", G_TYPE_STRING, \"RGB16\",\n               \"width\", G_TYPE_INT, 384,\n               \"height\", G_TYPE_INT, 288,\n               \"framerate\", GST_TYPE_FRACTION, 25, 1,\n               NULL);\n  g_object_set (G_OBJECT (filter), \"caps\", filtercaps, NULL);\n  gst_caps_unref (filtercaps);\n\n  pad = gst_element_get_static_pad (src, \"src\");\n  gst_pad_add_probe (pad, GST_PAD_PROBE_TYPE_BUFFER,\n      (GstPadProbeCallback) cb_have_data, NULL, NULL);\n  gst_object_unref (pad);\n\n  /* run */\n  gst_element_set_state (pipeline, GST_STATE_PLAYING);\n\n  /* wait until it's up and running or failed */\n  if (gst_element_get_state (pipeline, NULL, NULL, -1) == GST_STATE_CHANGE_FAILURE) {\n    g_error (\"Failed to go into PLAYING state\");\n  }\n\n  g_print (\"Running ...\\n\");\n  g_main_loop_run (loop);\n\n  /* exit */\n  gst_element_set_state (pipeline, GST_STATE_NULL);\n  gst_object_unref (pipeline);\n\n  return 0;\n}\n\n\n\n</code></pre>\n<p>Compare that output with the output of \u201cgst-launch-1.0 videotestsrc !\nxvimagesink\u201d, just so you know what you're looking for.</p>\n<p>Strictly speaking, a pad probe callback is only allowed to modify the\nbuffer content if the buffer is writable. Whether this is the case or\nnot depends a lot on the pipeline and the elements involved. Often\nenough, this is the case, but sometimes it is not, and if it is not then\nunexpected modification of the data or metadata can introduce bugs that\nare very hard to debug and track down. You can check if a buffer is\nwritable with <code>gst_buffer_is_writable ()</code>. Since you can pass back a\ndifferent buffer than the one passed in, it is a good idea to make the\nbuffer writable in the callback function with <code>gst_buffer_make_writable ()</code>.</p>\n<p>Pad probes are suited best for looking at data as it passes through the\npipeline. If you need to modify data, you should better write your own\nGStreamer element. Base classes like GstAudioFilter, GstVideoFilter or\nGstBaseTransform make this fairly easy.</p>\n<p>If you just want to inspect buffers as they pass through the pipeline,\nyou don't even need to set up pad probes. You could also just insert an\nidentity element into the pipeline and connect to its \"handoff\" signal.\nThe identity element also provides a few useful debugging tools like the\n\"dump\" property or the \"last-message\" property (the latter is enabled by\npassing the '-v' switch to gst-launch and by setting the silent property\non the identity to FALSE).</p>\n<h3 id=\"play-a-region-of-a-media-file\">Play a region of a media file</h3>\n<p>In this example we will show you how to play back a region of a media\nfile. The goal is to only play the part of a file from 2 seconds to 5\nseconds and then EOS.</p>\n<p>In a first step we will set a uridecodebin element to the PAUSED state\nand make sure that we block all the source pads that are created. When\nall the source pads are blocked, we have data on all source pads and we\nsay that the uridecodebin is prerolled.</p>\n<p>In a prerolled pipeline we can ask for the duration of the media and we\ncan also perform seeks. We are interested in performing a seek operation\non the pipeline to select the range of media that we are interested in.</p>\n<p>After we configure the region we are interested in, we can link the sink\nelement, unblock the source pads and set the pipeline to the playing\nstate. You will see that exactly the requested region is played by the\nsink before it goes to EOS.</p>\n<p>What follows is an example application that loosly follows this\nalgorithm.</p>\n<pre><code class=\"language-c\">\n\n#include &lt;gst/gst.h&gt;\n\nstatic GMainLoop *loop;\nstatic volatile gint counter;\nstatic GstBus *bus;\nstatic gboolean prerolled = FALSE;\nstatic GstPad *sinkpad;\n\nstatic void\ndec_counter (GstElement * pipeline)\n{\n  if (prerolled)\n    return;\n\n  if (g_atomic_int_dec_and_test (&amp;counter)) {\n    /* all probes blocked and no-more-pads signaled, post\n     * message on the bus. */\n    prerolled = TRUE;\n\n    gst_bus_post (bus, gst_message_new_application (\n          GST_OBJECT_CAST (pipeline),\n          gst_structure_new_empty (\"ExPrerolled\")));\n  }\n}\n\n/* called when a source pad of uridecodebin is blocked */\nstatic GstPadProbeReturn\ncb_blocked (GstPad          *pad,\n            GstPadProbeInfo *info,\n            gpointer         user_data)\n{\n  GstElement *pipeline = GST_ELEMENT (user_data);\n\n  if (prerolled)\n    return GST_PAD_PROBE_REMOVE;\n\n  dec_counter (pipeline);\n\n  return GST_PAD_PROBE_OK;\n}\n\n/* called when uridecodebin has a new pad */\nstatic void\ncb_pad_added (GstElement *element,\n              GstPad     *pad,\n              gpointer    user_data)\n{\n  GstElement *pipeline = GST_ELEMENT (user_data);\n\n  if (prerolled)\n    return;\n\n  g_atomic_int_inc (&amp;counter);\n\n  gst_pad_add_probe (pad, GST_PAD_PROBE_TYPE_BLOCK_DOWNSTREAM,\n      (GstPadProbeCallback) cb_blocked, pipeline, NULL);\n\n  /* try to link to the video pad */\n  gst_pad_link (pad, sinkpad);\n}\n\n/* called when uridecodebin has created all pads */\nstatic void\ncb_no_more_pads (GstElement *element,\n                 gpointer    user_data)\n{\n  GstElement *pipeline = GST_ELEMENT (user_data);\n\n  if (prerolled)\n    return;\n\n  dec_counter (pipeline);\n}\n\n/* called when a new message is posted on the bus */\nstatic void\ncb_message (GstBus     *bus,\n            GstMessage *message,\n            gpointer    user_data)\n{\n  GstElement *pipeline = GST_ELEMENT (user_data);\n\n  switch (GST_MESSAGE_TYPE (message)) {\n    case GST_MESSAGE_ERROR:\n      g_print (\"we received an error!\\n\");\n      g_main_loop_quit (loop);\n      break;\n    case GST_MESSAGE_EOS:\n      g_print (\"we reached EOS\\n\");\n      g_main_loop_quit (loop);\n      break;\n    case GST_MESSAGE_APPLICATION:\n    {\n      if (gst_message_has_name (message, \"ExPrerolled\")) {\n        /* it's our message */\n        g_print (\"we are all prerolled, do seek\\n\");\n        gst_element_seek (pipeline,\n            1.0, GST_FORMAT_TIME,\n            GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_ACCURATE,\n            GST_SEEK_TYPE_SET, 2 * GST_SECOND,\n            GST_SEEK_TYPE_SET, 5 * GST_SECOND);\n\n        gst_element_set_state (pipeline, GST_STATE_PLAYING);\n      }\n      break;\n    }\n    default:\n      break;\n  }\n}\n\ngint\nmain (gint   argc,\n      gchar *argv[])\n{\n  GstElement *pipeline, *src, *csp, *vs, *sink;\n\n  /* init GStreamer */\n  gst_init (&amp;argc, &amp;argv);\n  loop = g_main_loop_new (NULL, FALSE);\n\n  if (argc &lt; 2) {\n    g_print (\"usage: %s &lt;uri&gt;\", argv[0]);\n    return -1;\n  }\n\n  /* build */\n  pipeline = gst_pipeline_new (\"my-pipeline\");\n\n  bus = gst_pipeline_get_bus (GST_PIPELINE (pipeline));\n  gst_bus_add_signal_watch (bus);\n  g_signal_connect (bus, \"message\", (GCallback) cb_message,\n      pipeline);\n\n  src = gst_element_factory_make (\"uridecodebin\", \"src\");\n  if (src == NULL)\n    g_error (\"Could not create 'uridecodebin' element\");\n\n  g_object_set (src, \"uri\", argv[1], NULL);\n\n  csp = gst_element_factory_make (\"videoconvert\", \"csp\");\n  if (csp == NULL)\n    g_error (\"Could not create 'videoconvert' element\");\n\n  vs = gst_element_factory_make (\"videoscale\", \"vs\");\n  if (csp == NULL)\n    g_error (\"Could not create 'videoscale' element\");\n\n  sink = gst_element_factory_make (\"autovideosink\", \"sink\");\n  if (sink == NULL)\n    g_error (\"Could not create 'autovideosink' element\");\n\n  gst_bin_add_many (GST_BIN (pipeline), src, csp, vs, sink, NULL);\n\n  /* can't link src yet, it has no pads */\n  gst_element_link_many (csp, vs, sink, NULL);\n\n  sinkpad = gst_element_get_static_pad (csp, \"sink\");\n\n  /* for each pad block that is installed, we will increment\n   * the counter. for each pad block that is signaled, we\n   * decrement the counter. When the counter is 0 we post\n   * an app message to tell the app that all pads are\n   * blocked. Start with 1 that is decremented when no-more-pads\n   * is signaled to make sure that we only post the message\n   * after no-more-pads */\n  g_atomic_int_set (&amp;counter, 1);\n\n  g_signal_connect (src, \"pad-added\",\n      (GCallback) cb_pad_added, pipeline);\n  g_signal_connect (src, \"no-more-pads\",\n      (GCallback) cb_no_more_pads, pipeline);\n\n  gst_element_set_state (pipeline, GST_STATE_PAUSED);\n\n  g_main_loop_run (loop);\n\n  gst_element_set_state (pipeline, GST_STATE_NULL);\n\n  gst_object_unref (sinkpad);\n  gst_object_unref (bus);\n  gst_object_unref (pipeline);\n  g_main_loop_unref (loop);\n\n  return 0;\n}\n\n</code></pre>\n<p>Note that we use a custom application message to signal the main thread\nthat the uridecidebin is prerolled. The main thread will then issue a\nflushing seek to the requested region. The flush will temporarily\nunblock the pad and reblock them when new data arrives again. We detect\nthis second block to remove the probes. Then we set the pipeline to\nPLAYING and it should play from 2 to 5 seconds, then EOS and exit the\napplication.</p>\n<h2 id=\"manually-adding-or-removing-data-fromto-a-pipeline\">Manually adding or removing data from/to a pipeline</h2>\n<p>Many people have expressed the wish to use their own sources to inject\ndata into a pipeline. Some people have also expressed the wish to grab\nthe output in a pipeline and take care of the actual output inside their\napplication. While either of these methods are strongly discouraged,\nGStreamer offers support for this. <em>Beware! You need to know what you\nare doing.</em> Since you don't have any support from a base class you need\nto thoroughly understand state changes and synchronization. If it\ndoesn't work, there are a million ways to shoot yourself in the foot.\nIt's always better to simply write a plugin and have the base class\nmanage it. See the Plugin Writer's Guide for more information on this\ntopic. Also see the next section, which will explain how to embed\nplugins statically in your application.</p>\n<p>There's two possible elements that you can use for the above-mentioned\npurposes. Those are called \u201cappsrc\u201d (an imaginary source) and \u201cappsink\u201d\n(an imaginary sink). The same method applies to each of those elements.\nHere, we will discuss how to use those elements to insert (using appsrc)\nor grab (using appsink) data from a pipeline, and how to set\nnegotiation.</p>\n<p>Both appsrc and appsink provide 2 sets of API. One API uses standard\nGObject (action) signals and properties. The same API is also available\nas a regular C api. The C api is more performant but requires you to\nlink to the app library in order to use the elements.</p>\n<h3 id=\"inserting-data-with-appsrc\">Inserting data with appsrc</h3>\n<p>First we look at some examples for appsrc, which lets you insert data\ninto the pipeline from the application. Appsrc has some configuration\noptions that define how it will operate. You should decide about the\nfollowing configurations:</p>\n<ul>\n<li>\n<p>Will the appsrc operate in push or pull mode. The stream-type\nproperty can be used to control this. stream-type of \u201crandom-access\u201d\nwill activate pull mode scheduling while the other stream-types\nactivate push mode.</p>\n</li>\n<li>\n<p>The caps of the buffers that appsrc will push out. This needs to be\nconfigured with the caps property. The caps must be set to a fixed\ncaps and will be used to negotiate a format downstream.</p>\n</li>\n<li>\n<p>If the appsrc operates in live mode or not. This can be configured\nwith the is-live property. When operating in live-mode it is\nimportant to configure the min-latency and max-latency in appsrc.\nThe min-latency should be set to the amount of time it takes between\ncapturing a buffer and when it is pushed inside appsrc. In live\nmode, you should timestamp the buffers with the pipeline\nrunning-time when the first byte of the buffer was captured before\nfeeding them to appsrc. You can let appsrc do the timestaping with\nthe do-timestamp property (but then the min-latency must be set to 0\nbecause it timestamps based on the running-time when the buffer\nentered appsrc).</p>\n</li>\n<li>\n<p>The format of the SEGMENT event that appsrc will push. The format\nhas implications for how the running-time of the buffers will be\ncalculated so you must be sure you understand this. For live sources\nyou probably want to set the format property to GST_FORMAT_TIME.\nFor non-live source it depends on the media type that you are\nhandling. If you plan to timestamp the buffers, you should probably\nput a GST_FORMAT_TIME format, otherwise GST_FORMAT_BYTES might\nbe appropriate.</p>\n</li>\n<li>\n<p>If appsrc operates in random-access mode, it is important to\nconfigure the size property of appsrc with the number of bytes in\nthe stream. This will allow downstream elements to know the size of\nthe media and alows them to seek to the end of the stream when\nneeded.</p>\n</li>\n</ul>\n<p>The main way of handling data to appsrc is by using the function\n<code>gst_app_src_push_buffer ()</code> or by emiting the push-buffer action\nsignal. This will put the buffer onto a queue from which appsrc will\nread from in its streaming thread. It is important to note that data\ntransport will not happen from the thread that performed the push-buffer\ncall.</p>\n<p>The \u201cmax-bytes\u201d property controls how much data can be queued in appsrc\nbefore appsrc considers the queue full. A filled internal queue will\nalways signal the \u201cenough-data\u201d signal, which signals the application\nthat it should stop pushing data into appsrc. The \u201cblock\u201d property will\ncause appsrc to block the push-buffer method until free data becomes\navailable again.</p>\n<p>When the internal queue is running out of data, the \u201cneed-data\u201d signal\nis emitted, which signals the application that it should start pushing\nmore data into appsrc.</p>\n<p>In addition to the \u201cneed-data\u201d and \u201cenough-data\u201d signals, appsrc can\nemit the \u201cseek-data\u201d signal when the \u201cstream-mode\u201d property is set to\n\u201cseekable\u201d or \u201crandom-access\u201d. The signal argument will contain the\nnew desired position in the stream expressed in the unit set with the\n\u201cformat\u201d property. After receiving the seek-data signal, the\napplication should push-buffers from the new position.</p>\n<p>When the last byte is pushed into appsrc, you must call\n<code>gst_app_src_end_of_stream ()</code> to make it send an EOS downstream.</p>\n<p>These signals allow the application to operate appsrc in push and pull\nmode as will be explained next.</p>\n<h4 id=\"using-appsrc-in-push-mode\">Using appsrc in push mode</h4>\n<p>When appsrc is configured in push mode (stream-type is stream or\nseekable), the application repeatedly calls the push-buffer method with\na new buffer. Optionally, the queue size in the appsrc can be controlled\nwith the enough-data and need-data signals by respectively\nstopping/starting the push-buffer calls. The value of the min-percent\nproperty defines how empty the internal appsrc queue needs to be before\nthe need-data signal will be fired. You can set this to some value &gt;0\nto avoid completely draining the queue.</p>\n<p>When the stream-type is set to seekable, don't forget to implement a\nseek-data callback.</p>\n<p>Use this model when implementing various network protocols or hardware\ndevices.</p>\n<h4 id=\"using-appsrc-in-pull-mode\">Using appsrc in pull mode</h4>\n<p>In the pull model, data is fed to appsrc from the need-data signal\nhandler. You should push exactly the amount of bytes requested in the\nneed-data signal. You are only allowed to push less bytes when you are\nat the end of the stream.</p>\n<p>Use this model for file access or other randomly accessable sources.</p>\n<h4 id=\"appsrc-example\">Appsrc example</h4>\n<p>This example application will generate black/white (it switches every\nsecond) video to an Xv-window output by using appsrc as a source with\ncaps to force a format. We use a colorspace conversion element to make\nsure that we feed the right format to your X server. We configure a\nvideo stream with a variable framerate (0/1) and we set the timestamps\non the outgoing buffers in such a way that we play 2 frames per second.</p>\n<p>Note how we use the pull mode method of pushing new buffers into appsrc\nalthough appsrc is running in push mode.</p>\n<pre><code class=\"language-c\">\n\n#include &lt;gst/gst.h&gt;\n\nstatic GMainLoop *loop;\n\nstatic void\ncb_need_data (GstElement *appsrc,\n          guint       unused_size,\n          gpointer    user_data)\n{\n  static gboolean white = FALSE;\n  static GstClockTime timestamp = 0;\n  GstBuffer *buffer;\n  guint size;\n  GstFlowReturn ret;\n\n  size = 385 * 288 * 2;\n\n  buffer = gst_buffer_new_allocate (NULL, size, NULL);\n\n  /* this makes the image black/white */\n  gst_buffer_memset (buffer, 0, white ? 0xff : 0x0, size);\n\n  white = !white;\n\n  GST_BUFFER_PTS (buffer) = timestamp;\n  GST_BUFFER_DURATION (buffer) = gst_util_uint64_scale_int (1, GST_SECOND, 2);\n\n  timestamp += GST_BUFFER_DURATION (buffer);\n\n  g_signal_emit_by_name (appsrc, \"push-buffer\", buffer, &amp;ret);\n  gst_buffer_unref (buffer);\n\n  if (ret != GST_FLOW_OK) {\n    /* something wrong, stop pushing */\n    g_main_loop_quit (loop);\n  }\n}\n\ngint\nmain (gint   argc,\n      gchar *argv[])\n{\n  GstElement *pipeline, *appsrc, *conv, *videosink;\n\n  /* init GStreamer */\n  gst_init (&amp;argc, &amp;argv);\n  loop = g_main_loop_new (NULL, FALSE);\n\n  /* setup pipeline */\n  pipeline = gst_pipeline_new (\"pipeline\");\n  appsrc = gst_element_factory_make (\"appsrc\", \"source\");\n  conv = gst_element_factory_make (\"videoconvert\", \"conv\");\n  videosink = gst_element_factory_make (\"xvimagesink\", \"videosink\");\n\n  /* setup */\n  g_object_set (G_OBJECT (appsrc), \"caps\",\n        gst_caps_new_simple (\"video/x-raw\",\n                     \"format\", G_TYPE_STRING, \"RGB16\",\n                     \"width\", G_TYPE_INT, 384,\n                     \"height\", G_TYPE_INT, 288,\n                     \"framerate\", GST_TYPE_FRACTION, 0, 1,\n                     NULL), NULL);\n  gst_bin_add_many (GST_BIN (pipeline), appsrc, conv, videosink, NULL);\n  gst_element_link_many (appsrc, conv, videosink, NULL);\n\n  /* setup appsrc */\n  g_object_set (G_OBJECT (appsrc),\n        \"stream-type\", 0,\n        \"format\", GST_FORMAT_TIME, NULL);\n  g_signal_connect (appsrc, \"need-data\", G_CALLBACK (cb_need_data), NULL);\n\n  /* play */\n  gst_element_set_state (pipeline, GST_STATE_PLAYING);\n  g_main_loop_run (loop);\n\n  /* clean up */\n  gst_element_set_state (pipeline, GST_STATE_NULL);\n  gst_object_unref (GST_OBJECT (pipeline));\n  g_main_loop_unref (loop);\n\n  return 0;\n  }\n\n\n\n</code></pre>\n<h3 id=\"grabbing-data-with-appsink\">Grabbing data with appsink</h3>\n<p>Unlike appsrc, appsink is a little easier to use. It also supports a\npull and push based model of getting data from the pipeline.</p>\n<p>The normal way of retrieving samples from appsink is by using the\n<code>gst_app_sink_pull_sample()</code> and <code>gst_app_sink_pull_preroll()</code> methods\nor by using the \u201cpull-sample\u201d and \u201cpull-preroll\u201d signals. These methods\nblock until a sample becomes available in the sink or when the sink is\nshut down or reaches EOS.</p>\n<p>Appsink will internally use a queue to collect buffers from the\nstreaming thread. If the application is not pulling samples fast enough,\nthis queue will consume a lot of memory over time. The \u201cmax-buffers\u201d\nproperty can be used to limit the queue size. The \u201cdrop\u201d property\ncontrols whether the streaming thread blocks or if older buffers are\ndropped when the maximum queue size is reached. Note that blocking the\nstreaming thread can negatively affect real-time performance and should\nbe avoided.</p>\n<p>If a blocking behaviour is not desirable, setting the \u201cemit-signals\u201d\nproperty to TRUE will make appsink emit the \u201cnew-sample\u201d and\n\u201cnew-preroll\u201d signals when a sample can be pulled without blocking.</p>\n<p>The \u201ccaps\u201d property on appsink can be used to control the formats that\nappsink can receive. This property can contain non-fixed caps, the\nformat of the pulled samples can be obtained by getting the sample caps.</p>\n<p>If one of the pull-preroll or pull-sample methods return NULL, the\nappsink is stopped or in the EOS state. You can check for the EOS state\nwith the \u201ceos\u201d property or with the <code>gst_app_sink_is_eos()</code> method.</p>\n<p>The eos signal can also be used to be informed when the EOS state is\nreached to avoid polling.</p>\n<p>Consider configuring the following properties in the appsink:</p>\n<ul>\n<li>\n<p>The \u201csync\u201d property if you want to have the sink base class\nsynchronize the buffer against the pipeline clock before handing you\nthe sample.</p>\n</li>\n<li>\n<p>Enable Quality-of-Service with the \u201cqos\u201d property. If you are\ndealing with raw video frames and let the base class sycnhronize on\nthe clock, it might be a good idea to also let the base class send\nQOS events upstream.</p>\n</li>\n<li>\n<p>The caps property that contains the accepted caps. Upstream elements\nwill try to convert the format so that it matches the configured\ncaps on appsink. You must still check the <code>GstSample</code> to get the\nactual caps of the buffer.</p>\n</li>\n</ul>\n<h4 id=\"appsink-example\">Appsink example</h4>\n<p>What follows is an example on how to capture a snapshot of a video\nstream using appsink.</p>\n<pre><code class=\"language-c\">\n\n#include &lt;gst/gst.h&gt;\n#ifdef HAVE_GTK\n#include &lt;gtk/gtk.h&gt;\n#endif\n\n#include &lt;stdlib.h&gt;\n\n#define CAPS \"video/x-raw,format=RGB,width=160,pixel-aspect-ratio=1/1\"\n\nint\nmain (int argc, char *argv[])\n{\n  GstElement *pipeline, *sink;\n  gint width, height;\n  GstSample *sample;\n  gchar *descr;\n  GError *error = NULL;\n  gint64 duration, position;\n  GstStateChangeReturn ret;\n  gboolean res;\n  GstMapInfo map;\n\n  gst_init (&amp;argc, &amp;argv);\n\n  if (argc != 2) {\n    g_print (\"usage: %s &lt;uri&gt;\\n Writes snapshot.png in the current directory\\n\",\n        argv[0]);\n    exit (-1);\n  }\n\n  /* create a new pipeline */\n  descr =\n      g_strdup_printf (\"uridecodebin uri=%s ! videoconvert ! videoscale ! \"\n      \" appsink name=sink caps=\\\"\" CAPS \"\\\"\", argv[1]);\n  pipeline = gst_parse_launch (descr, &amp;error);\n\n  if (error != NULL) {\n    g_print (\"could not construct pipeline: %s\\n\", error-&gt;message);\n    g_clear_error (&amp;error);\n    exit (-1);\n  }\n\n  /* get sink */\n  sink = gst_bin_get_by_name (GST_BIN (pipeline), \"sink\");\n\n  /* set to PAUSED to make the first frame arrive in the sink */\n  ret = gst_element_set_state (pipeline, GST_STATE_PAUSED);\n  switch (ret) {\n    case GST_STATE_CHANGE_FAILURE:\n      g_print (\"failed to play the file\\n\");\n      exit (-1);\n    case GST_STATE_CHANGE_NO_PREROLL:\n      /* for live sources, we need to set the pipeline to PLAYING before we can\n       * receive a buffer. We don't do that yet */\n      g_print (\"live sources not supported yet\\n\");\n      exit (-1);\n    default:\n      break;\n  }\n  /* This can block for up to 5 seconds. If your machine is really overloaded,\n   * it might time out before the pipeline prerolled and we generate an error. A\n   * better way is to run a mainloop and catch errors there. */\n  ret = gst_element_get_state (pipeline, NULL, NULL, 5 * GST_SECOND);\n  if (ret == GST_STATE_CHANGE_FAILURE) {\n    g_print (\"failed to play the file\\n\");\n    exit (-1);\n  }\n\n  /* get the duration */\n  gst_element_query_duration (pipeline, GST_FORMAT_TIME, &amp;duration);\n\n  if (duration != -1)\n    /* we have a duration, seek to 5% */\n    position = duration * 5 / 100;\n  else\n    /* no duration, seek to 1 second, this could EOS */\n    position = 1 * GST_SECOND;\n\n  /* seek to the a position in the file. Most files have a black first frame so\n   * by seeking to somewhere else we have a bigger chance of getting something\n   * more interesting. An optimisation would be to detect black images and then\n   * seek a little more */\n  gst_element_seek_simple (pipeline, GST_FORMAT_TIME,\n      GST_SEEK_FLAG_KEY_UNIT | GST_SEEK_FLAG_FLUSH, position);\n\n  /* get the preroll buffer from appsink, this block untils appsink really\n   * prerolls */\n  g_signal_emit_by_name (sink, \"pull-preroll\", &amp;sample, NULL);\n\n  /* if we have a buffer now, convert it to a pixbuf. It's possible that we\n   * don't have a buffer because we went EOS right away or had an error. */\n  if (sample) {\n    GstBuffer *buffer;\n    GstCaps *caps;\n    GstStructure *s;\n\n    /* get the snapshot buffer format now. We set the caps on the appsink so\n     * that it can only be an rgb buffer. The only thing we have not specified\n     * on the caps is the height, which is dependant on the pixel-aspect-ratio\n     * of the source material */\n    caps = gst_sample_get_caps (sample);\n    if (!caps) {\n      g_print (\"could not get snapshot format\\n\");\n      exit (-1);\n    }\n    s = gst_caps_get_structure (caps, 0);\n\n    /* we need to get the final caps on the buffer to get the size */\n    res = gst_structure_get_int (s, \"width\", &amp;width);\n    res |= gst_structure_get_int (s, \"height\", &amp;height);\n    if (!res) {\n      g_print (\"could not get snapshot dimension\\n\");\n      exit (-1);\n    }\n\n    /* create pixmap from buffer and save, gstreamer video buffers have a stride\n     * that is rounded up to the nearest multiple of 4 */\n    buffer = gst_sample_get_buffer (sample);\n    /* Mapping a buffer can fail (non-readable) */\n    if (gst_buffer_map (buffer, &amp;map, GST_MAP_READ)) {\n#ifdef HAVE_GTK\n      pixbuf = gdk_pixbuf_new_from_data (map.data,\n          GDK_COLORSPACE_RGB, FALSE, 8, width, height,\n          GST_ROUND_UP_4 (width * 3), NULL, NULL);\n\n      /* save the pixbuf */\n      gdk_pixbuf_save (pixbuf, \"snapshot.png\", \"png\", &amp;error, NULL);\n#endif\n      gst_buffer_unmap (buffer, &amp;map);\n    }\n    gst_sample_unref (sample);\n  } else {\n    g_print (\"could not make snapshot\\n\");\n  }\n\n  /* cleanup and exit */\n  gst_element_set_state (pipeline, GST_STATE_NULL);\n  gst_object_unref (pipeline);\n\n  exit (0);\n}\n\n</code></pre>\n<h2 id=\"forcing-a-format\">Forcing a format</h2>\n<p>Sometimes you'll want to set a specific format, for example a video size\nand format or an audio bitsize and number of channels. You can do this\nby forcing a specific <code>GstCaps</code> on the pipeline, which is possible by\nusing <em>filtered caps</em>. You can set a filtered caps on a link by using\nthe \u201ccapsfilter\u201d element in between the two elements, and specifying a\n<code>GstCaps</code> as \u201ccaps\u201d property on this element. It will then only allow\ntypes matching that specified capability set for negotiation. See also\n<a href=\"../basics/pads.html#creating-capabilities-for-filtering\">Creating capabilities for filtering</a>.</p>\n<h3 id=\"changing-format-in-a-playing-pipeline\">Changing format in a PLAYING pipeline</h3>\n<p>It is also possible to dynamically change the format in a pipeline while\nPLAYING. This can simply be done by changing the caps property on a\ncapsfilter. The capsfilter will send a RECONFIGURE event upstream that\nwill make the upstream element attempt to renegotiate a new format and\nallocator. This only works if the upstream element is not using fixed\ncaps on the source pad.</p>\n<p>Below is an example of how you can change the caps of a pipeline while\nin the PLAYING state:</p>\n<pre><code class=\"language-c\">\n\n#include &lt;stdlib.h&gt;\n\n#include &lt;gst/gst.h&gt;\n\n#define MAX_ROUND 100\n\nint\nmain (int argc, char **argv)\n{\n  GstElement *pipe, *filter;\n  GstCaps *caps;\n  gint width, height;\n  gint xdir, ydir;\n  gint round;\n  GstMessage *message;\n\n  gst_init (&amp;argc, &amp;argv);\n\n  pipe = gst_parse_launch_full (\"videotestsrc ! capsfilter name=filter ! \"\n             \"ximagesink\", NULL, GST_PARSE_FLAG_NONE, NULL);\n  g_assert (pipe != NULL);\n\n  filter = gst_bin_get_by_name (GST_BIN (pipe), \"filter\");\n  g_assert (filter);\n\n  width = 320;\n  height = 240;\n  xdir = ydir = -10;\n\n  for (round = 0; round &lt; MAX_ROUND; round++) {\n    gchar *capsstr;\n    g_print (\"resize to %dx%d (%d/%d)   \\r\", width, height, round, MAX_ROUND);\n\n    /* we prefer our fixed width and height but allow other dimensions to pass\n     * as well */\n    capsstr = g_strdup_printf (\"video/x-raw, width=(int)%d, height=(int)%d\",\n        width, height);\n\n    caps = gst_caps_from_string (capsstr);\n    g_free (capsstr);\n    g_object_set (filter, \"caps\", caps, NULL);\n    gst_caps_unref (caps);\n\n    if (round == 0)\n      gst_element_set_state (pipe, GST_STATE_PLAYING);\n\n    width += xdir;\n    if (width &gt;= 320)\n      xdir = -10;\n    else if (width &lt; 200)\n      xdir = 10;\n\n    height += ydir;\n    if (height &gt;= 240)\n      ydir = -10;\n    else if (height &lt; 150)\n      ydir = 10;\n\n    message =\n        gst_bus_poll (GST_ELEMENT_BUS (pipe), GST_MESSAGE_ERROR,\n        50 * GST_MSECOND);\n    if (message) {\n      g_print (\"got error           \\n\");\n\n      gst_message_unref (message);\n    }\n  }\n  g_print (\"done                    \\n\");\n\n  gst_object_unref (filter);\n  gst_element_set_state (pipe, GST_STATE_NULL);\n  gst_object_unref (pipe);\n\n  return 0;\n}\n\n\n\n</code></pre>\n<p>Note how we use <code>gst_bus_poll()</code> with a small timeout to get messages\nand also introduce a short sleep.</p>\n<p>It is possible to set multiple caps for the capsfilter separated with a\n;. The capsfilter will try to renegotiate to the first possible format\nfrom the list.</p>\n<h2 id=\"dynamically-changing-the-pipeline\">Dynamically changing the pipeline</h2>\n<p>In this section we talk about some techniques for dynamically modifying\nthe pipeline. We are talking specifically about changing the pipeline\nwhile it is in the PLAYING state without interrupting the flow.</p>\n<p>There are some important things to consider when building dynamic\npipelines:</p>\n<ul>\n<li>\n<p>When removing elements from the pipeline, make sure that there is no\ndataflow on unlinked pads because that will cause a fatal pipeline\nerror. Always block source pads (in push mode) or sink pads (in pull\nmode) before unlinking pads. See also <a href=\"../../#changing-elements-in-a-pipeline\">Changing elements in a\npipeline</a>.</p>\n</li>\n<li>\n<p>When adding elements to a pipeline, make sure to put the element\ninto the right state, usually the same state as the parent, before\nallowing dataflow the element. When an element is newly created, it\nis in the NULL state and will return an error when it receives data.\nSee also <a href=\"../../#changing-elements-in-a-pipeline\">Changing elements in a\npipeline</a>.</p>\n</li>\n<li>\n<p>When adding elements to a pipeline, GStreamer will by default set\nthe clock and base-time on the element to the current values of the\npipeline. This means that the element will be able to construct the\nsame pipeline running-time as the other elements in the pipeline.\nThis means that sinks will synchronize buffers like the other sinks\nin the pipeline and that sources produce buffers with a running-time\nthat matches the other sources.</p>\n</li>\n<li>\n<p>When unlinking elements from an upstream chain, always make sure to\nflush any queued data in the element by sending an EOS event down\nthe element sink pad(s) and by waiting that the EOS leaves the\nelements (with an event probe).</p>\n<p>If you do not do this, you will lose the data which is buffered by\nthe unlinked element. This can result in a simple frame loss (one or\nmore video frames, several milliseconds of audio). However if you\nremove a muxer (and in some cases an encoder or similar elements)\nfrom the pipeline, you risk getting a corrupted file which could not\nbe played properly, as some relevant metadata (header, seek/index\ntables, internal sync tags) will not be stored or updated properly.</p>\n<p>See also <a href=\"../../#changing-elements-in-a-pipeline\">Changing elements in a\npipeline</a>.</p>\n</li>\n<li>\n<p>A live source will produce buffers with a running-time of the\ncurrent running-time in the pipeline.</p>\n<p>A pipeline without a live source produces buffers with a\nrunning-time starting from 0. Likewise, after a flushing seek, those\npipelines reset the running-time back to 0.</p>\n<p>The running-time can be changed with <code>gst_pad_set_offset ()</code>. It is\nimportant to know the running-time of the elements in the pipeline\nin order to maintain synchronization.</p>\n</li>\n<li>\n<p>Adding elements might change the state of the pipeline. Adding a\nnon-prerolled sink, for example, brings the pipeline back to the\nprerolling state. Removing a non-prerolled sink, for example, might\nchange the pipeline to PAUSED and PLAYING state.</p>\n<p>Adding a live source cancels the preroll stage and put the pipeline\nto the playing state. Adding a live source or other live elements\nmight also change the latency of a pipeline.</p>\n<p>Adding or removing elements to the pipeline might change the clock\nselection of the pipeline. If the newly added element provides a\nclock, it might be worth changing the clock in the pipeline to the\nnew clock. If, on the other hand, the element that provides the\nclock for the pipeline is removed, a new clock has to be selected.</p>\n</li>\n<li>\n<p>Adding and removing elements might cause upstream or downstream\nelements to renegotiate caps and or allocators. You don't really\nneed to do anything from the application, plugins largely adapt\nthemself to the new pipeline topology in order to optimize their\nformats and allocation strategy.</p>\n<p>What is important is that when you add, remove or change elements in\nthe pipeline, it is possible that the pipeline needs to negotiate a\nnew format and this can fail. Usually you can fix this by inserting\nthe right converter elements where needed. See also <a href=\"../../#changing-elements-in-a-pipeline\">Changing\nelements in a pipeline</a>.</p>\n</li>\n</ul>\n<p>GStreamer offers support for doing about any dynamic pipeline\nmodification but it requires you to know a bit of details before you can\ndo this without causing pipeline errors. In the following sections we\nwill demonstrate a couple of typical use-cases.</p>\n<h3 id=\"changing-elements-in-a-pipeline\">Changing elements in a pipeline</h3>\n<p>In the next example we look at the following chain of elements:</p>\n<pre><code>            - ----.      .----------.      .---- -\n         element1 |      | element2 |      | element3\n                src -&gt; sink       src -&gt; sink\n            - ----'      '----------'      '---- -\n\n</code></pre>\n<p>We want to change element2 by element4 while the pipeline is in the\nPLAYING state. Let's say that element2 is a visualization and that you\nwant to switch the visualization in the pipeline.</p>\n<p>We can't just unlink element2's sinkpad from element1's source pad\nbecause that would leave element1's source pad unlinked and would cause\na streaming error in the pipeline when data is pushed on the source pad.\nThe technique is to block the dataflow from element1's source pad before\nwe change element2 by element4 and then resume dataflow as shown in the\nfollowing steps:</p>\n<ul>\n<li>\n<p>Block element1's source pad with a blocking pad probe. When the pad\nis blocked, the probe callback will be called.</p>\n</li>\n<li>\n<p>Inside the block callback nothing is flowing between element1 and\nelement2 and nothing will flow until unblocked.</p>\n</li>\n<li>\n<p>Unlink element1 and element2.</p>\n</li>\n<li>\n<p>Make sure data is flushed out of element2. Some elements might\ninternally keep some data, you need to make sure not to lose data by\nforcing it out of element2. You can do this by pushing EOS into\nelement2, like this:</p>\n<ul>\n<li>\n<p>Put an event probe on element2's source pad.</p>\n</li>\n<li>\n<p>Send EOS to element2's sinkpad. This makes sure the all the data\ninside element2 is forced out.</p>\n</li>\n<li>\n<p>Wait for the EOS event to appear on element2's source pad. When\nthe EOS is received, drop it and remove the event probe.</p>\n</li>\n</ul>\n</li>\n<li>\n<p>Unlink element2 and element3. You can now also remove element2 from\nthe pipeline and set the state to NULL.</p>\n</li>\n<li>\n<p>Add element4 to the pipeline, if not already added. Link element4\nand element3. Link element1 and element4.</p>\n</li>\n<li>\n<p>Make sure element4 is in the same state as the rest of the elements\nin the pipeline. It should be at least in the PAUSED state before it\ncan receive buffers and events.</p>\n</li>\n<li>\n<p>Unblock element1's source pad probe. This will let new data into\nelement4 and continue streaming.</p>\n</li>\n</ul>\n<p>The above algorithm works when the source pad is blocked, i.e. when\nthere is dataflow in the pipeline. If there is no dataflow, there is\nalso no point in changing the element (just yet) so this algorithm can\nbe used in the PAUSED state as well.</p>\n<p>Let show you how this works with an example. This example changes the\nvideo effect on a simple pipeline every second.</p>\n<pre><code class=\"language-c\">\n\n#include &lt;gst/gst.h&gt;\n\nstatic gchar *opt_effects = NULL;\n\n#define DEFAULT_EFFECTS \"identity,exclusion,navigationtest,\" \\\n    \"agingtv,videoflip,vertigotv,gaussianblur,shagadelictv,edgetv\"\n\nstatic GstPad *blockpad;\nstatic GstElement *conv_before;\nstatic GstElement *conv_after;\nstatic GstElement *cur_effect;\nstatic GstElement *pipeline;\n\nstatic GQueue effects = G_QUEUE_INIT;\n\nstatic GstPadProbeReturn\nevent_probe_cb (GstPad * pad, GstPadProbeInfo * info, gpointer user_data)\n{\n  GMainLoop *loop = user_data;\n  GstElement *next;\n\n  if (GST_EVENT_TYPE (GST_PAD_PROBE_INFO_DATA (info)) != GST_EVENT_EOS)\n    return GST_PAD_PROBE_PASS;\n\n  gst_pad_remove_probe (pad, GST_PAD_PROBE_INFO_ID (info));\n\n  /* push current effect back into the queue */\n  g_queue_push_tail (&amp;effects, gst_object_ref (cur_effect));\n  /* take next effect from the queue */\n  next = g_queue_pop_head (&amp;effects);\n  if (next == NULL) {\n    GST_DEBUG_OBJECT (pad, \"no more effects\");\n    g_main_loop_quit (loop);\n    return GST_PAD_PROBE_DROP;\n  }\n\n  g_print (\"Switching from '%s' to '%s'..\\n\", GST_OBJECT_NAME (cur_effect),\n      GST_OBJECT_NAME (next));\n\n  gst_element_set_state (cur_effect, GST_STATE_NULL);\n\n  /* remove unlinks automatically */\n  GST_DEBUG_OBJECT (pipeline, \"removing %\" GST_PTR_FORMAT, cur_effect);\n  gst_bin_remove (GST_BIN (pipeline), cur_effect);\n\n  GST_DEBUG_OBJECT (pipeline, \"adding   %\" GST_PTR_FORMAT, next);\n  gst_bin_add (GST_BIN (pipeline), next);\n\n  GST_DEBUG_OBJECT (pipeline, \"linking..\");\n  gst_element_link_many (conv_before, next, conv_after, NULL);\n\n  gst_element_set_state (next, GST_STATE_PLAYING);\n\n  cur_effect = next;\n  GST_DEBUG_OBJECT (pipeline, \"done\");\n\n  return GST_PAD_PROBE_DROP;\n}\n\nstatic GstPadProbeReturn\npad_probe_cb (GstPad * pad, GstPadProbeInfo * info, gpointer user_data)\n{\n  GstPad *srcpad, *sinkpad;\n\n  GST_DEBUG_OBJECT (pad, \"pad is blocked now\");\n\n  /* remove the probe first */\n  gst_pad_remove_probe (pad, GST_PAD_PROBE_INFO_ID (info));\n\n  /* install new probe for EOS */\n  srcpad = gst_element_get_static_pad (cur_effect, \"src\");\n  gst_pad_add_probe (srcpad, GST_PAD_PROBE_TYPE_BLOCK |\n      GST_PAD_PROBE_TYPE_EVENT_DOWNSTREAM, event_probe_cb, user_data, NULL);\n  gst_object_unref (srcpad);\n\n  /* push EOS into the element, the probe will be fired when the\n   * EOS leaves the effect and it has thus drained all of its data */\n  sinkpad = gst_element_get_static_pad (cur_effect, \"sink\");\n  gst_pad_send_event (sinkpad, gst_event_new_eos ());\n  gst_object_unref (sinkpad);\n\n  return GST_PAD_PROBE_OK;\n}\n\nstatic gboolean\ntimeout_cb (gpointer user_data)\n{\n  gst_pad_add_probe (blockpad, GST_PAD_PROBE_TYPE_BLOCK_DOWNSTREAM,\n      pad_probe_cb, user_data, NULL);\n\n  return TRUE;\n}\n\nstatic gboolean\nbus_cb (GstBus * bus, GstMessage * msg, gpointer user_data)\n{\n  GMainLoop *loop = user_data;\n\n  switch (GST_MESSAGE_TYPE (msg)) {\n    case GST_MESSAGE_ERROR:{\n      GError *err = NULL;\n      gchar *dbg;\n\n      gst_message_parse_error (msg, &amp;err, &amp;dbg);\n      gst_object_default_error (msg-&gt;src, err, dbg);\n      g_clear_error (&amp;err);\n      g_free (dbg);\n      g_main_loop_quit (loop);\n      break;\n    }\n    default:\n      break;\n  }\n  return TRUE;\n}\n\nint\nmain (int argc, char **argv)\n{\n  GOptionEntry options[] = {\n    {\"effects\", 'e', 0, G_OPTION_ARG_STRING, &amp;opt_effects,\n        \"Effects to use (comma-separated list of element names)\", NULL},\n    {NULL}\n  };\n  GOptionContext *ctx;\n  GError *err = NULL;\n  GMainLoop *loop;\n  GstElement *src, *q1, *q2, *effect, *filter1, *filter2, *sink;\n  gchar **effect_names, **e;\n\n  ctx = g_option_context_new (\"\");\n  g_option_context_add_main_entries (ctx, options, NULL);\n  g_option_context_add_group (ctx, gst_init_get_option_group ());\n  if (!g_option_context_parse (ctx, &amp;argc, &amp;argv, &amp;err)) {\n    g_print (\"Error initializing: %s\\n\", err-&gt;message);\n    g_clear_error (&amp;amp;err);\n    g_option_context_free (ctx);\n    return 1;\n  }\n  g_option_context_free (ctx);\n\n  if (opt_effects != NULL)\n    effect_names = g_strsplit (opt_effects, \",\", -1);\n  else\n    effect_names = g_strsplit (DEFAULT_EFFECTS, \",\", -1);\n\n  for (e = effect_names; e != NULL &amp;&amp; *e != NULL; ++e) {\n    GstElement *el;\n\n    el = gst_element_factory_make (*e, NULL);\n    if (el) {\n      g_print (\"Adding effect '%s'\\n\", *e);\n      g_queue_push_tail (&amp;effects, el);\n    }\n  }\n\n  pipeline = gst_pipeline_new (\"pipeline\");\n\n  src = gst_element_factory_make (\"videotestsrc\", NULL);\n  g_object_set (src, \"is-live\", TRUE, NULL);\n\n  filter1 = gst_element_factory_make (\"capsfilter\", NULL);\n  gst_util_set_object_arg (G_OBJECT (filter1), \"caps\",\n      \"video/x-raw, width=320, height=240, \"\n      \"format={ I420, YV12, YUY2, UYVY, AYUV, Y41B, Y42B, \"\n      \"YVYU, Y444, v210, v216, NV12, NV21, UYVP, A420, YUV9, YVU9, IYU1 }\");\n\n  q1 = gst_element_factory_make (\"queue\", NULL);\n\n  blockpad = gst_element_get_static_pad (q1, \"src\");\n\n  conv_before = gst_element_factory_make (\"videoconvert\", NULL);\n\n  effect = g_queue_pop_head (&amp;effects);\n  cur_effect = effect;\n\n  conv_after = gst_element_factory_make (\"videoconvert\", NULL);\n\n  q2 = gst_element_factory_make (\"queue\", NULL);\n\n  filter2 = gst_element_factory_make (\"capsfilter\", NULL);\n  gst_util_set_object_arg (G_OBJECT (filter2), \"caps\",\n      \"video/x-raw, width=320, height=240, \"\n      \"format={ RGBx, BGRx, xRGB, xBGR, RGBA, BGRA, ARGB, ABGR, RGB, BGR }\");\n\n  sink = gst_element_factory_make (\"ximagesink\", NULL);\n\n  gst_bin_add_many (GST_BIN (pipeline), src, filter1, q1, conv_before, effect,\n      conv_after, q2, sink, NULL);\n\n  gst_element_link_many (src, filter1, q1, conv_before, effect, conv_after,\n      q2, sink, NULL);\n\n  gst_element_set_state (pipeline, GST_STATE_PLAYING);\n\n  loop = g_main_loop_new (NULL, FALSE);\n\n  gst_bus_add_watch (GST_ELEMENT_BUS (pipeline), bus_cb, loop);\n\n  g_timeout_add_seconds (1, timeout_cb, loop);\n\n  g_main_loop_run (loop);\n\n  gst_element_set_state (pipeline, GST_STATE_NULL);\n  gst_object_unref (pipeline);\n\n  return 0;\n}\n\n\n\n</code></pre>\n<p>Note how we added videoconvert elements before and after the effect.\nThis is needed because some elements might operate in different\ncolorspaces than other elements. By inserting the conversion elements\nyou ensure that the right format can be negotiated at any time.</p>\n\n</div>\n\n\n\t"});