fragment_downloaded_cb({"url": "design/subtitle-overlays.html#api-needed", "fragment": "API needed \nRepresentation of subtitle overlays to be rendered \nWe need to pass the overlay pixels from the overlay element to the sink somehow. Whatever the exact mechanism let s assume we pass a refcounted GstVideoOverlayComposition struct or object. \nA composition is made up of one or more overlays rectangles. \nIn the simplest case an overlay rectangle is just a blob of RGBA ABGR FIXME or AYUV pixels with positioning info and other metadata and there is only one rectangle to render. \nWe re keeping the naming generic OverlayFoo rather than SubtitleFoo here since this might also be handy for other use cases such as e.g. logo overlays or so. It is not designed for full fledged video stream mixing though. \nFallback overlay rendering blitting on top of raw video \nEventually we want to use this overlay mechanism not only for hardware accelerated video but also for plain old raw video either at the sink or in the overlay element directly. \nApart from the advantages listed earlier in section this allows us to consolidate a lot of overlaying blitting code that is currently repeated in every single overlay element in one location. This makes it considerably easier to support a whole range of raw video formats out of the box add SIMD optimised rendering using ORC or handle corner cases correctly. \nNote side effect of overlaying raw video at the video sink is that if e.g. a screnshotter gets the last buffer via the last buffer property of basesink it would get an image without the subtitles on top. This could probably be fixed by re implementing the property in GstVideoSink though. Playbin2 could handle this internally as well \nFlatten all rectangles in a composition \nWe cannot assume that the video backend API can handle any number of rectangle overlays it s possible that it only supports one single overlay in which case we need to squash all rectangles into one. \nHowever we ll just declare this a corner case for now and implement it only if someone actually needs it. It s easy to add later API wise. Might be a bit tricky if we have rectangles with different PARs formats e.g. subs and a logo though we could probably always just use the code from b with a fully transparent video buffer to create a flattened overlay buffer. \nquery support for the new video composition mechanism \nThis is handled via GstMeta and an ALLOCATION query we can simply query whether downstream supports the GstVideoOverlayComposition meta. \nThere appears to be no issue with downstream possibly not being linked yet at the time when an overlay would want to do such a query but we would just have to default to something and update ourselves later on a reconfigure event then. \nOther considerations \nrenderers overlays or sinks may be able to handle only ARGB or only AYUV for most graphics hw API it s likely ARGB of some sort while our blending utility functions will likely want the same colour space as the underlying raw video format which is usually YUV of some sort We need to convert where required and should cache the conversion. \nrenderers may or may not be able to scale the overlay. We need to do the scaling internally if not simple case just horizontal scaling to adjust for PAR differences complex case both horizontal and vertical scaling e.g. if subs come from a different source than the video or the video has been rescaled or cropped between overlay element and sink \nrenderers may be able to generate possibly scaled pixels on demand from the original data e.g. a string or RLE encoded data We will ignore this for now since this functionality can still be added later via API additions. The most interesting case would be to pass a pango markup string since e.g. clutter can handle that natively. \nrenderers may be able to write data directly on top of the video pixels instead of creating an intermediary buffer with the overlay which is then blended on top of the actual video frame e.g. dvdspu dvbsuboverlay \nHowever in the interest of simplicity we should probably ignore the fact that some elements can blend their overlays directly on top of the video decoding uncompressing them on the fly even more so as it s not obvious that it s actually faster to decode the same overlay times say ie. ca. seconds of video frames and then blend it times instead of decoding it once into a temporary buffer and then blending it directly from there possibly SIMD accelerated. Also this is only relevant if the video is raw video and not some hardware acceleration backend object. \nAnd ultimately it is the overlay element that decides whether to do the overlay right there and then or have the sink do it if supported It could decide to keep doing the overlay itself for raw video and only use our new API for non raw video. \nrenderers may want to make sure they only upload the overlay pixels once per rectangle if that rectangle recurs in subsequent frames as part of the same composition or a different composition as is likely. This caching of e.g. surfaces needs to be done renderer side and can be accomplished based on the sequence numbers. The composition contains the lowest sequence number still in use upstream an overlay element may want to cache created compositions rectangles as well after all to re use them for multiple frames based on that the renderer can expire cached objects. The caching needs to be done renderer side because attaching renderer specific objects to the rectangles won t work well given the refcounted nature of rectangles and compositions making it unpredictable when a rectangle or composition will be freed or from which thread context it will be freed. The renderer specific objects are likely bound to other types of renderer specific contexts and need to be managed in connection with those. \ncomposition rectangles should internally provide a certain degree of thread safety. Multiple elements sinks overlay element might access or use the same objects from multiple threads at the same time and it is expected that elements will keep a ref to compositions and rectangles they push downstream for a while e.g. until the current subtitle composition expires. \n"});