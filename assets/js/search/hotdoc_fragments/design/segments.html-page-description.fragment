fragment_downloaded_cb({"url": "design/segments.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"segments.md\">\n<h1 id=\"segments\">Segments</h1>\n<p>A segment in GStreamer denotes a set of media samples that must be\nprocessed. A segment has a start time, a stop time and a processing\nrate.</p>\n<p>A media stream has a start and a stop time. The start time is always 0\nand the stop time is the total duration (or -1 if unknown, for example a\nlive stream). We call this the complete media stream.</p>\n<p>The segment of the complete media stream can be played by issuing a seek\non the stream. The seek has a start time, a stop time and a processing\nrate.</p>\n<pre><code>             complete stream\n+------------------------------------------------+\n0                                              duration\n       segment\n   |--------------------------|\n start                       stop\n</code></pre>\n<p>The playback of a segment starts with a source or demuxer element\npushing a <code>SEGMENT</code> event containing the start time, stop time and rate of\nthe segment. The purpose of this event is to inform downstream\nelements of the requested segment positions. Some elements might produce\nbuffers that fall outside of the segment and that might therefore be\ndiscarded or clipped.</p>\n<h2 id=\"use-cases\">Use cases</h2>\n<h3 id=\"flushing-seek\">FLUSHING seek</h3>\n<pre><code>filesrc ! avidemux ! videodecoder ! videosink\n</code></pre>\n<p>When doing a seek in this pipeline for a segment 1 to 5 seconds, avidemux\nwill perform the seek.</p>\n<p>Avidemux starts by sending a <code>FLUSH_START</code> event downstream and upstream. This\nwill cause its streaming task to <code>PAUSED</code> because <code>_pad_pull_range()</code> and\n<code>_pad_push()</code> will return <code>FLUSHING</code>. It then waits for the <code>STREAM_LOCK</code>,\nwhich will be unlocked when the streaming task pauses. At this point no\nstreaming is happening anymore in the pipeline and a <code>FLUSH_STOP</code> is sent\nupstream and downstream.</p>\n<p>When avidemux starts playback of the segment from second 1 to 5, it pushes\nout a segment with 1 and 5 as start and stop times. The <code>stream_time</code> in\nthe segment is also 1 as this is the position we seek to.</p>\n<p>The video decoder stores these values internally and forwards them to the\nnext downstream element (videosink, which also stores the values)</p>\n<p>Since second 1 does not contain a keyframe, the avi demuxer starts sending\ndata from the previous keyframe which is at timestamp 0.</p>\n<p>The video decoder decodes the keyframe but knows it should not push the\nvideo frame yet as it falls outside of the configured segment.</p>\n<p>When the video decoder receives the frame with timestamp 1, it is able to\ndecode this frame as it received and decoded the data up to the previous\nkeyframe. It then continues to decode and push frames with timestamps &gt;= 1.\nWhen it reaches timestamp 5, it does not decode and push frames anymore.</p>\n<p>The video sink receives a frame of timestamp 1. It takes the start value of\nthe previous segment and applies the following (simplified) formula:</p>\n<pre><code>render_time = BUFFER_TIMESTAMP - segment_start + element-&gt;base_time\n</code></pre>\n<p>It then syncs against the clock with this <code>render_time</code>. Note that\n<code>BUFFER_TIMESTAMP</code> is always &gt;= <code>segment_start</code> or else it would fall outside\nof the configured segment.</p>\n<p>Videosink reports its current position as (simplified):</p>\n<pre><code>current_position = clock_time - element-&gt;base_time + segment_time\n</code></pre>\n<p>See <a href=\"synchronisation.html\">synchronisation</a> for a more detailed and\naccurate explanation of synchronisation and position reporting.</p>\n<p>Since after a flushing seek the <code>stream_time</code> is reset to 0, the new buffer\nwill be rendered immediately after the seek and the <code>current_position</code> will be\nthe <code>stream_time</code> of the seek that was performed.</p>\n<p>The stop time is important when the video format contains B frames. The\nvideo decoder receives a P frame first, which it can decode but not push yet.\nWhen it receives a B frame, it can decode the B frame and push the B frame\nfollowed by the previously decoded P frame. If the P frame is outside of the\nsegment, the decoder knows it should not send the P frame.</p>\n<p>Avidemux stops sending data after pushing a frame with timestamp 5 and\nreturns <code>GST_FLOW_EOS</code> from the chain function to make the upstream\nelements perform the EOS logic.</p>\n<h3 id=\"live-stream\">Live stream</h3>\n<h3 id=\"segment-looping\">Segment looping</h3>\n<p>Consider the case of a wav file with raw audio.</p>\n<pre><code>filesrc ! wavparse ! alsasink\n</code></pre>\n<p>FIXME!</p>\n\n</div>\n\n\n        "});