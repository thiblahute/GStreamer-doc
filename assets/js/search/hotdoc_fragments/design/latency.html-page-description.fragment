fragment_downloaded_cb({"url": "design/latency.html#page-description", "fragment": "The latency is the time it takes for a sample captured at timestamp to reach the sink. This time is measured against the pipeline s clock. For pipelines where the only elements that synchronize against the clock are the sinks the latency is always since no other element is delaying the buffer. \nFor pipelines with live sources a latency is introduced mostly because of the way a live source works. Consider an audio source it will start capturing the first sample at time If the source pushes buffers with samples at a time at Hz it will have collected the buffer at second Since the timestamp of the buffer is and the time of the clock is now second the sink will drop this buffer because it is too late. Without any latency compensation in the sink all buffers will be dropped. \nThe situation becomes more complex in the presence of \nlive sources connected to live sinks with different latencies \nlive source connected to live sinks \nmixed live source and non live source scenarios. \nclock slaving in the sinks due to the live sources providing their own clocks. \nTo perform the needed latency corrections in the above scenarios we must develop an algorithm to calculate a global latency for the pipeline. This algorithm must be extensible so that it can optimize the latency at runtime. It must also be possible to disable or tune the algorithm based on specific application needs required minimal latency \nWe show some examples to demonstrate the problem of latency in typical capture pipelines. \nAn audio capture playback pipeline. \nNULL READY \nREADY PAUSED \nSince the source is a live source it will only produce data in the PLAYING state. To note this fact it returns NO_PREROLL from the state change function. \nThis sink returns ASYNC because it can only complete the state change to PAUSED when it receives the first buffer. \nAt this point the pipeline is not processing data and the clock is not running. Unless a new action is performed on the pipeline this situation will never change. \nPAUSED PLAYING asrc clock selected because it is the most upstream clock provider. asink can only provide a clock when it received the first buffer and configured the device with the samplerate in the caps. \nsink PAUSED PLAYING sets pending state to PLAYING returns ASYNC because it is not prerolled. The sink will commit state to PLAYING when it prerolls. \nsrc PAUSED PLAYING starts pushing buffers. \nsince the sink is still performing a state change from READY PAUSED it remains ASYNC. The pending state will be set to PLAYING. \nThe clock starts running as soon as all the elements have been set to PLAYING. \nthe source is a live source with a latency. Since it is synchronized with the clock it will produce a buffer with timestamp and duration D after time D ie. it will only be able to produce the last sample of the buffer with timestamp D at time D. This latency depends on the size of the buffer. \nthe sink will receive the buffer with timestamp at time D. At this point the buffer is too late already and might be dropped. This state of constantly dropping data will not change unless a constant latency correction is added to the incoming buffer timestamps. \nThe problem is due to the fact that the sink is set to pending PLAYING without being prerolled which only happens in live pipelines. \nAn audio video capture playback pipeline. We capture both audio and video and have them played back synchronized again. \nThe state changes happen in the same way as example Both sinks end up with pending state of PLAYING and a return value of ASYNC until they receive the first buffer. \nFor audio and video to be played in sync both sinks must compensate for the latency of its source but must also use exactly the same latency correction. \nSuppose asrc has a latency of ms and vsrc a latency of ms the total latency in the pipeline has to be at least ms. This also means that the pipeline must have at least a ms buffering on the audio stream or else the audio src will underrun while the audiosink waits for the previous sample to play. \nAn example of the combination of a non live file and a live source vsrc connected to live sinks vsink sink \nThe state changes happen in the same way as example Except sink will be able to preroll commit its state to PAUSED \nIn this case sink will have no latency but vsink will. The total latency should be that of vsink. \nNote that because of the presence of a live source vsrc the pipeline can be set to playing before the sink is able to preroll. Without compensation for the live source this might lead to synchronisation problems because the latency should be configured in the element before it can go to PLAYING. \nAn example of the combination of a non live and a live source. The non live source is connected to a live sink and the live source to a non live sink. \nThe state changes happen in the same way as example Sink will be able to preroll commit its state to PAUSED files will not be able to preroll. \nsink will have no latency since it is not connected to a live source. files does not do synchronisation so it does not care about latency. \nThe total latency in the pipeline is The vsrc captures in sync with the playback in sink. \nAs in example sink can only be set to PLAYING after it successfully prerolled. \nA sink is never set to PLAYING before it is prerolled. In order to do this the pipeline at the GstBin level keeps track of all elements that require preroll the ones that return ASYNC from the state change These elements posted an ASYNC_START message without a matching ASYNC_DONE one. \nThe pipeline will not change the state of the elements that are still doing an ASYNC state change. \nWhen an ASYNC element prerolls it commits its state to PAUSED and posts an ASYNC_DONE message. The pipeline notices this ASYNC_DONE message and matches it with the ASYNC_START message it cached for the corresponding element. \nWhen all ASYNC_START messages are matched with an ASYNC_DONE message the pipeline proceeds with setting the elements to the final state again. \nThe base time of the element was already set by the pipeline when it changed the NO_PREROLL element to PLAYING. This operation has to be performed in the separate async state change thread like the one currently used for going from PAUSED PLAYING in a non live pipeline \nThe pipeline latency is queried with the LATENCY query. \nlive G_TYPE_BOOLEAN default FALSE if a live element is found upstream \nmin latency G_TYPE_UINT64 default must not be NONE the minimum latency in the pipeline meaning the minimum time downstream elements synchronizing to the clock have to wait until they can be sure all data for the current running time has been received. \nElements answering the latency query and introducing latency must set this to the maximum time for which they will delay data while considering upstream s minimum latency. As such from an element s perspective this is not its own minimum latency but its own maximum latency. Considering upstream s minimum latency generally means that the element s own value is added to upstream s value as this will give the overall minimum latency of all elements from the source to the current element \nElements answering the latency query should set this to the maximum time for which they can buffer upstream data without blocking or dropping further data. For an element this value will generally be its own minimum latency but might be bigger than that if it can buffer more data. As such queue elements can be used to increase the maximum latency. \nThe value set in the query should again consider upstream s maximum latency \nIf the element has multiple sinkpads the minimum upstream latency is the maximum of all live upstream minimum latencies. \nIf the current element has leaky buffering i.e. it drops data by itself when its internal buffer is full it should take the minimum of its own maximum latency and upstream s. Examples for such elements are audio sinks and sources with an internal ringbuffer leaky queues and in general live sources with a limited amount of internal buffers that can be used. \nNote many GStreamer base classes allow subclasses to set a minimum and maximum latency and handle the query themselves. These base classes assume non leaky i.e. blocking buffering for the maximum latency. The base class default query handler needs to be overridden to correctly handle leaky buffering. \nIf the element has multiple sinkpads the maximum upstream latency is the minimum of all live upstream maximum latencies. \nThe latency in the pipeline is configured with the LATENCY event which contains the following fields \nLatency calculation and compensation is performed before the pipeline proceeds to the PLAYING state. \nWhen the pipeline collected all ASYNC_DONE messages it can calculate the global latency as follows \nThe sinks gather this information with a LATENCY query upstream. Intermediate elements pass the query upstream and add the amount of latency they add to the result. \nThe latency is set on the pipeline by sending a LATENCY event to the sinks in the pipeline. This event configures the total latency on the sinks. The sink forwards this LATENCY event upstream so that intermediate elements can configure themselves as well. \nAfter this step the pipeline continues setting the pending state on its elements. \nA sink adds the latency value received in the LATENCY event to the times used for synchronizing against the clock. This will effectively delay the rendering of the buffer with the required latency. Since this delay is the same for all sinks all sinks will render data relatively synchronised. \nWe can implement resynchronisation after an uncontrolled FLUSH in part of a pipeline in the same way. Indeed when a flush is performed on a PLAYING live element a new base time must be distributed to this element. \nA flush in a pipeline can happen in the following cases \nflushing seek in the pipeline \nperformed by the application on the pipeline \nperformed by the application on an element \nflush preformed by an element \nafter receiving a navigation event DVD \nWhen a playing sink is flushed by a FLUSH_START event an ASYNC_START message is posted by the element. As part of the message the fact that the element got flushed is included. The element also goes to a pending PAUSED state and has to be set to the PLAYING state again later. \nThe ASYNC_START message is kept by the parent bin. When the element prerolls it posts an ASYNC_DONE message. \nWhen all ASYNC_START messages are matched with an ASYNC_DONE message the bin will capture a new base_time from the clock and will bring all the sinks back to PLAYING after setting the new base time on them. It s also possible to perform additional latency calculations and adjustments before doing this. \nAn element that wants to change the latency in the pipeline can do this by posting a LATENCY message on the bus. This message instructs the pipeline to \nquery the latency in the pipeline which might now have changed with a LATENCY query. \nredistribute a new global latency to all elements with a LATENCY event. \nA use case where the latency in a pipeline can change could be a network element that observes an increased inter packet arrival jitter or excessive packet loss and decides to increase its internal buffering and thus the latency The element must post a LATENCY message and perform the additional latency adjustments when it receives the LATENCY event from the downstream peer element. \nIn a similar way the latency can be decreased when network conditions improve. \nLatency adjustments will introduce playback glitches in the sinks and must only be performed in special conditions. \n"});