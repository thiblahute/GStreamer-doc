fragment_downloaded_cb({"url": "design/stereo-multiview-video.html#page-description", "fragment": "Stereoscopic Multiview Video Handling \nEncoded Video Properties that need to be encoded into caps \nBuffer representation for raw video \nOutput Considerations with OpenGL \nOther elements for handling multiview content \nImplementing MVC handling in decoders parsers and encoders \nOverriding frame packing interpretation \nAdding extra GstVideoMeta to buffers \nvideooverlay interface extensions \nThere are two cases to handle \nEncoded video output from a demuxer to parser decoder or from encoders into a muxer. \nRaw video buffers \nThe design below is somewhat based on the proposals from bug \nMultiview is used as a generic term to refer to handling both stereo content left and right eye only as well as extensions for videos containing multiple independent viewpoints. \nmultiview mode called Channel Layout in bug \nFrame packing arrangements view sequence orderings \nview encoding order \nFrame layout flags \nIf we have support for stereo GL buffer formats we can output separate left right eye images and let the hardware take care of display. \nOtherwise glimagesink needs to render one window with left right in a suitable frame packing and that will only show correctly in fullscreen on a device set for the right D packing requires app intervention to set the video mode. \nWhich could be done manually on the TV or with HDMI by setting the right video mode for the screen to inform the TV or third option we support rendering to two separate overlay areas on the screen one for left eye one for right which can be supported using the splitter element and two output sinks or better add a nd window overlay for split stereo output \nIntel hardware doesn t do stereo GL buffers only nvidia and AMD so initial implementation won t include that \nvideooverlay interface extensions \nConverter element \nMixer element \nSplitter element \nOutput one pad per view \nThings to do to implement MVC handling \nMost sample videos available are frame packed with no metadata to say so. How should we override that interpretation \nThere should be one GstVideoMeta for the entire video frame in packed layouts and one GstVideoMeta per GstGLMemory when views are attached to a GstBuffer separately. This should be done by the buffer pool which knows from the caps. \nGstVideoOverlay needs \n"});