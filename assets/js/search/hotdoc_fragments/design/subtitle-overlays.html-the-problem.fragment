fragment_downloaded_cb({"url": "design/subtitle-overlays.html#the-problem", "fragment": "The Problem \nIn the case of such hardware accelerated decoding the decoder will not output raw pixels that can easily be manipulated. Instead it will output hardware API specific objects that can later be used to render a frame using the same API. \nEven if we could transform such a buffer into raw pixels we most likely would want to avoid that in order to avoid the need to map the data back into system memory and then later back to the GPU It s much better to upload the much smaller encoded data to the GPU DSP and then leave it there until rendered. \nBefore GstVideoOverlayComposition playbin only supported subtitles on top of raw decoded video. It would try to find a suitable overlay element from the plugin registry based on the input subtitle caps and the rank. It is assumed that we will be able to convert any raw video format into any format required by the overlay using a converter such as videoconvert. \nIt would not render subtitles if the video sent to the sink is not raw YUV or RGB or if conversions had been disabled by setting the native video flag on playbin. \nSubtitle rendering is considered an important feature. Enabling hardware accelerated decoding by default should not lead to a major feature regression in this area. \nThis means that we need to support subtitle rendering on top of non raw video. \n"});