fragment_downloaded_cb({"url": "design/encoding.html#page-description", "fragment": "Duplication of pipeline code for gstreamer based applications wishing to encode and or mux streams leading to subtle differences and inconsistencies across those applications. \nNo unified system for describing encoding targets for applications in a user friendly way. \nNo unified system for creating encoding targets for applications resulting in duplication of code across all applications differences and inconsistencies that come with that duplication and applications hardcoding element names and settings resulting in poor portability. \nConvenience encoding element \nCreate a convenience GstBin for encoding and muxing several streams hereafter called EncodeBin \nThis element will only contain one single property which is a profile. \nDefine a encoding profile system \nEncoding profile helper library \nCreate a helper library to \ncreate EncodeBin instances based on profiles and \nhelp applications to create load save browse those profiles. \nEncodeBin is a GstBin subclass. \nIt implements the GstTagSetter interface by which it will proxy the calls to the muxer. \nOnly two introspectable property i.e. usable without extra API \nWhen a profile is selected encodebin will \nWhenever a request pad is created encodebin will \nThis allows reducing the code to the minimum for applications wishing to encode a source for a given profile \nThis describes the various stages which can happen in order to end up with a multiplexed stream that can then be stored or streamed. \nThe streams fed to EncodeBin can be of various types \nIncoming Stream \nTransform raw video feed optional \nHere we modify the various fundamental properties of a raw video stream to be compatible with the intersection of The encoder GstCaps and The specified Stream Restriction of the profile target \nThe fundamental properties that can be modified are width height This is done with a video scaler. The DAR Display Aspect Ratio MUST be respected. If needed black borders can be added to comply with the target DAR. framerate format colorspace depth All of this is done with a colorspace converter \nAn encoder with some optional settings is used. \nA muxer with some optional settings is used. \nThis is roughly the same as for raw video expect for \nWe modify the various fundamental properties of a raw audio stream to be compatible with the intersection of The encoder GstCaps and The specified Stream Restriction of the profile target \nThe fundamental properties that can be modifier are Number of channels Type of raw audio integer or floating point Depth number of bits required to encode one sample \nSteps and are replaced by a parser if a parser is available for the given format. \nOther streams will just be forwarded as is to the muxer provided the muxer accepts the stream type. \nThis work is based on \nThe existing GstPreset API documentation system for elements \nThe gnome media GConf audio profile system \nThe investigation done into device profiles by Arista and Transmageddon Research on a Device Profile API and Research on defining presets usage. \nSuch a classification is required in order for Applications with a very specific use case to limit the number of profiles they can offer the user. A screencasting application has no use with the online services targets for example. Offering the user some initial classification in the case of a more generic encoding application like a video editor or a transcoder \nEx Consumer devices Online service Intermediate Editing Format Screencast Capture Computer \nEncoding Profile Target A Profile Target describes a specific entity for which we wish to encode. A Profile Target must belong to at least one Target Category. It will define at least one Encoding Profile. \nExamples with category Nokia N900 Consumer device Sony PlayStation Consumer device Youtube Online service DNxHD Intermediate editing format HuffYUV Screencast Theora Computer \nEncoding Profile A specific combination of muxer encoders presets and limitations. \nExamples Nokia N900 H264 HQ Ipod High Quality DVD Pal Youtube High Quality HTML5 Low Bandwith DNxHD \nAn encoding profile requires the following information \nStream Profiles \nA Stream Profile consists of \nThe representation used here is XML only as an example. No decision is made as to which formatting to use for storing targets and profiles. \nA proposed C API is contained in the gstprofile.h file in this directory. \nCurrently a preset needs to be saved on disk in order to be used. \nThis makes it impossible to have temporary presets that exist only during the lifetime of a process which might be required in the new proposed profile system \nCurrently presets are just aliases of a group of property value without any meanings or explanation as to how they exclude each other. \nTake for example the H264 encoder. It can have presets for passes or passes profiles Baseline Main quality Low medium High \nIn order to programmatically know which presets exclude each other we here propose the categorisation of these presets. \nThis can be done in one of two ways in the name by making the name be This would give for example Quality High Profile Baseline by adding a new _meta key This would give for example _meta category quality \nThere can be more than one choice of presets to be done for an element quality profile pass \nThis means that one can not currently describe the full configuration of an element with a single string but with many. \nThe proposal here is to extend the GstPreset API to be able to set all presets using one string and a well known separator \nThis change only requires changes in the core preset handling code. \nThis would allow doing the following gst_preset_load_preset h264enc pass profile baseline quality high \nThis document hasn t determined yet how to solve the following problems \nOne proposal for storage would be to use a system wide directory like prefix share gstreamer profiles and store XML files for every individual profiles. \nUsers could then add their own profiles in gstreamer profiles \nThis poses some limitations as to what to do if some applications want to have some profiles limited to their own usage. \nThese helper methods could also be added to existing libraries like GstPreset GstPbUtils \nThe various API proposed are in the accompanying gstprofile.h file. \nThis is already provided by GstPbUtils. \nThe goal is for applications to be able to present to the user a list of combo boxes for choosing their output profile \nCategory optional depends on the application Device Site optional depends on the application Profile \nConvenience methods are offered to easily get lists of categories devices and profiles. \nThe goal is for applications to be able to easily create profiles. \nThe applications needs to be able to have a fast efficient way to select a container format and see all compatible streams he can use with it. select a codec format and see which container formats he can use with it. \nThe remaining parts concern the restrictions to encoder input. \nWhen an application wishes to use a Profile it should be able to query whether it has all the needed plugins to use it. \nThis part will use GstPbUtils to query and if needed install the missing plugins through the installed distribution plugin installer. \nThis is a list of various use cases where encoding muxing is being used. \nThe goal is to convert with as minimal loss of quality any input file for a target use. A specific variant of this is transmuxing see below \nExample applications Arista Transmageddon \nThe incoming streams are a collection of various segments that need to be rendered. Those segments can vary in nature i.e. the video width height can change This requires the use of identiy with the single segment property activated to transform the incoming collection of segments to a single continuous segment. \nExample applications PiTiVi Jokosher \nThe major risk to take into account is the encoder not encoding the incoming stream fast enough. This is outside of the scope of encodebin and should be solved by using queues between the sources and encodebin as well as implementing QoS in encoders and sources the encoders emitting QoS events and the upstream elements adapting themselves accordingly \nExample applications camerabin cheese \nThis is similar to encoding of live sources. The difference being that due to the nature of the source size and amount frequency of updates one might want to do the encoding in two parts The actual live capture is encoded with a almost lossless codec such as huffyuv Once the capture is done the file created in the first step is then rendered to the desired target format. \nFixing sources to only emit region updates and having encoders capable of encoding those streams would fix the need for the first step but is outside of the scope of encodebin. \nExample applications Istanbul gnome shell recordmydesktop \nThis is the case of an incoming live stream which will be broadcasted transmitted live. One issue to take into account is to reduce the encoding latency to a minimum. This should mostly be done by picking low latency encoders. \nExample applications Rygel Coherence \nGiven a certain file the aim is to remux the contents WITHOUT decoding into either a different container format or the same container format. Remuxing into the same container format is useful when the file was not created properly for example the index is missing Whenever available parsers should be applied on the encoded streams to validate and or fix the streams before muxing them. \nMetadata from the original file must be kept in the newly created file. \nExample applications Arista Transmaggedon \nGiven a certain file the aim is to extract a certain part of the file without going through the process of decoding and re encoding that file. This is similar to the transmuxing use case. \nExample applications PiTiVi Transmageddon Arista \nSome encoders allow doing a multi pass encoding. The initial pass es are only used to collect encoding estimates and are not actually muxed and outputted. The final pass uses previously collected information and the output is then muxed and outputted. \nThe requirement is to have lossless \nExample applications Sound juicer \nExample application Thoggen \nSome of these are still active documents some other not \n"});