fragment_downloaded_cb({"url": "design/qos.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"qos.md\">\n        <h1 id=\"qualityofservice\">Quality-of-Service</h1>\n<p>Quality of service is about measuring and adjusting the real-time\nperformance of a pipeline.</p>\n<p>The real-time performance is always measured relative to the pipeline\nclock and typically happens in the sinks when they synchronize buffers\nagainst the clock.</p>\n<p>The measurements result in QOS events that aim to adjust the datarate in\none or more upstream elements. Two types of adjustments can be made:</p>\n<ul>\n<li>\n<p>short time \"emergency\" corrections based on latest observation in\nthe sinks.</p>\n</li>\n<li>\n<p>long term rate corrections based on trends observed in the sinks.</p>\n</li>\n</ul>\n<p>It is also possible for the application to artificially introduce delay\nbetween synchronized buffers, this is called throttling. It can be used\nto reduce the framerate, for example.</p>\n<h2 id=\"sources-of-quality-problems\">Sources of quality problems</h2>\n<ul>\n<li>\n<p>High CPU load</p>\n</li>\n<li>\n<p>Network problems</p>\n</li>\n<li>\n<p>Other resource problems such as disk load, memory bottlenecks etc.</p>\n</li>\n<li>\n<p>application level throttling</p>\n</li>\n</ul>\n<h2 id=\"qos-event\">QoS event</h2>\n<p>The QoS event is generated by an element that synchronizes against the\nclock. It travels upstream and contains the following fields:</p>\n<ul>\n<li>\n<p><strong><code>type</code></strong>: <code>GST_TYPE_QOS_TYPE:</code> The type of the QoS event, we have the\nfollowing types and the default type is <code>GST_QOS_TYPE_UNDERFLOW</code>:</p>\n<ul>\n<li>\n<p><code>GST_QOS_TYPE_OVERFLOW</code>:  an element is receiving buffers too fast and can't\nkeep up processing them. Upstream should reduce the rate.</p>\n</li>\n<li>\n<p><code>GST_QOS_TYPE_UNDERFLOW</code>: an element is receiving buffers too slowly\nand has to drop them because they are too late. Upstream should\nincrease the processing rate.</p>\n</li>\n<li>\n<p><code>GST_QOS_TYPE_THROTTLE</code>:  the application is asking to add extra delay\nbetween buffers, upstream is allowed to drop buffers</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong><code>timestamp</code></strong>: <code>G_TYPE_UINT64</code>: The timestamp on the buffer that\ngenerated the QoS event. These timestamps are expressed in total\n<code>running_time</code> in the sink so that the value is ever increasing.</p>\n</li>\n<li>\n<p><strong><code>jitter</code></strong>: <code>G_TYPE_INT64</code>: The difference of that timestamp against the\ncurrent clock time. Negative values mean the timestamp was on time.\nPositive values indicate the timestamp was late by that amount. When\nbuffers are received in time and throttling is not enabled, the QoS\ntype field is set to OVERFLOW. When throttling, the jitter contains\nthe throttling delay added by the application and the type is set to\nTHROTTLE.</p>\n</li>\n<li>\n<p><strong><code>proportion</code></strong>: <code>G_TYPE_DOUBLE</code>: Long term prediction of the ideal rate\nrelative to normal rate to get optimal quality.</p>\n</li>\n</ul>\n<p>The rest of this document deals with how these values can be calculated\nin a sink and how the values can be used by other elements to adjust\ntheir operations.</p>\n<h2 id=\"qos-message\">QoS message</h2>\n<p>A QOS message is posted on the bus whenever an element decides to:</p>\n<ul>\n<li>\n<p>drop a buffer because of QoS reasons</p>\n</li>\n<li>\n<p>change its processing strategy because of QoS reasons (quality)</p>\n</li>\n</ul>\n<p>It should be expected that creating and posting the QoS message is\nreasonably fast and does not significantly contribute to the QoS\nproblems. Options to disable this feature could also be presented on\nelements.</p>\n<p>This message can be posted by a sink/src that performs synchronisation\nagainst the clock (live) or it could be posted by an upstream element\nthat performs QoS because of QOS events received from a downstream\nelement (!live).</p>\n<p>The <code>GST_MESSAGE_QOS</code> contains at least the following info:</p>\n<ul>\n<li>\n<p><strong><code>live</code></strong>: <code>G_TYPE_BOOLEAN</code>: If the QoS message was dropped by a live\nelement such as a sink or a live source. If the live property is\nFALSE, the QoS message was generated as a response to a QoS event in\na non-live element.</p>\n</li>\n<li>\n<p><strong><code>running-time</code></strong>: <code>G_TYPE_UINT64</code>: The <code>running_time</code> of the buffer that\ngenerated the QoS message.</p>\n</li>\n<li>\n<p><strong><code>stream-time</code></strong>: <code>G_TYPE_UINT64</code>: The <code>stream_time</code> of the buffer that\ngenerated the QoS message.</p>\n</li>\n<li>\n<p><strong><code>timestamp</code></strong>: <code>G_TYPE_UINT64</code>: The timestamp of the buffer that\ngenerated the QoS message.</p>\n</li>\n<li>\n<p><strong><code>duration</code></strong>: <code>G_TYPE_UINT64</code>: The duration of the buffer that generated\nthe QoS message.</p>\n</li>\n<li>\n<p><strong><code>jitter</code></strong>: <code>G_TYPE_INT64</code>: The difference of the running-time against\nthe deadline. Negative values mean the timestamp was on time.\nPositive values indicate the timestamp was late (and dropped) by\nthat amount. The deadline can be a realtime <code>running_time</code> or an\nestimated <code>running_time</code>.</p>\n</li>\n<li>\n<p><strong><code>proportion</code></strong>: <code>G_TYPE_DOUBLE</code>: Long term prediction of the ideal rate\nrelative to normal rate to get optimal quality.</p>\n</li>\n<li>\n<p><strong><code>quality</code></strong>: <code>G_TYPE_INT</code>: An element dependent integer value that\nspecifies the current quality level of the element. The default\nmaximum quality is 1000000.</p>\n</li>\n<li>\n<p><strong><code>format</code></strong>: <code>GST_TYPE_FORMAT</code> Units of the <em>processed</em> and <em>dropped</em>\nfields. Video sinks and video filters will use <code>GST_FORMAT_BUFFERS</code>\n(frames). Audio sinks and audio filters will likely use\n<code>GST_FORMAT_DEFAULT</code> (samples).</p>\n</li>\n<li>\n<p><strong><code>processed</code></strong>: <code>G_TYPE_UINT64</code>: Total number of units correctly\nprocessed since the last state change to READY or a flushing\noperation.</p>\n</li>\n<li>\n<p><strong><code>dropped</code></strong>: <code>G_TYPE_UINT64</code>: Total number of units dropped since the\nlast state change to READY or a flushing operation.</p>\n</li>\n</ul>\n<p>The <em>running-time</em> and <em>processed</em> fields can be used to estimate the\naverage processing rate (framerate for video).</p>\n<p>Elements might add additional fields in the message which are documented\nin the relevant elements or baseclasses.</p>\n<h2 id=\"collecting-statistics\">Collecting statistics</h2>\n<p>A buffer with timestamp B1 arrives in the sink at time T1. The buffer\ntimestamp is then synchronized against the clock which yields a jitter\nJ1 return value from the clock. The jitter J1 is simply calculated as</p>\n<pre><code>J1 = CT - B1\n</code></pre>\n<p>Where CT is the clock time when the entry arrives in the sink. This\nvalue is calculated inside the clock when we perform\n<code>gst_clock_id_wait()</code>.</p>\n<p>If the jitter is negative, the entry arrived in time and can be rendered\nafter waiting for the clock to reach time B1 (which is also CT - J1).</p>\n<p>If the jitter is positive however, the entry arrived too late in the\nsink and should therefore be dropped. J1 is the amount of time the entry\nwas late.</p>\n<p>Any buffer that arrives in the sink should generate a QoS event\nupstream.</p>\n<p>Using the jitter we can calculate the time when the buffer arrived in\nthe sink:</p>\n<pre><code>    T1 = B1 + J1.                                (1)\n</code></pre>\n<p>The time the buffer leaves the sink after synchronisation is measured\nas:</p>\n<pre><code>    T2 = B1 + (J1 &lt; 0 ? 0 : J1)                  (2)\n</code></pre>\n<p>For buffers that arrive in time (J1 &lt; 0) the buffer leaves after\nsynchronisation which is exactly B1. Late buffers (J1 &gt;= 0) leave the\nsink when they arrive, whithout any synchronisation, which is <code>T2 = T1 = B1 + J1</code>.</p>\n<p>Using a previous T0 and a new T1, we can calculate the time it took for\nupstream to generate a buffer with timestamp B1.</p>\n<pre><code>    PT1 = T1 - T0                                (3)\n</code></pre>\n<p>We call PT1 the processing time needed to generate buffer with timestamp\nB1.</p>\n<p>Moreover, given the duration of the buffer D1, the current data rate\n(DR1) of the upstream element is given as:</p>\n<pre><code>      PT1   T1 - T0\nDR1 = --- = -------                           (4)\n      D1      D1\n</code></pre>\n<p>For values 0.0 &lt; DR1 \u21d0 1.0 the upstream element is producing faster\nthan real-time. If DR1 is exactly 1.0, the element is running at a\nperfect speed.</p>\n<p>Values DR1 &gt; 1.0 mean that the upstream element cannot produce buffers\nof duration D1 in real-time. It is exactly DR1 that tells the amount of\nspeedup we require from upstream to regain real-time performance.</p>\n<p>An element that is not receiving enough data is said to be underflowed.</p>\n<h2 id=\"element-measurements\">Element measurements</h2>\n<p>In addition to the measurements of the datarate of the upstream element,\na typical element must also measure its own performance. Global pipeline\nperformance problems can indeed also be caused by the element itself\nwhen it receives too much data it cannot process in time. The element is\nthen said to be overflowed.</p>\n<h2 id=\"short-term-correction\">Short term correction</h2>\n<p>The timestamp and jitter serve as short term correction information for\nupstream elements. Indeed, given arrival time T1 as given in (1) we can\nbe certain that buffers with a timestamp B2 &lt; T1 will be too late in\nthe sink.</p>\n<p>In case of a positive jitter we can therefore send a QoS event with a\ntimestamp B1, jitter J1 and proportion given by (4).</p>\n<p>This allows an upstream element to not generate any data with timestamps\nB2 &lt; T1, where the element can derive T1 as B1 + J1.</p>\n<p>This will effectively result in frame drops.</p>\n<p>The element can even do a better estimation of the next valid timestamp\nit should output.</p>\n<p>Indeed, given the element generated a buffer with timestamp B0 that\narrived in time in the sink but then received a QoS event stating B1\narrived J1 too late. This means generating B1 took (B1 + J1) - B0 = T1 -\nT0 = PT1, as given in (3). Given the buffer B1 had a duration D1 and\nassuming that generating a new buffer B2 will take the same amount of\nprocessing time, a better estimation for B2 would then be:</p>\n<pre><code>    B2 = T1 + D2 * DR1\n</code></pre>\n<p>expanding gives:</p>\n<pre><code>    B2 = (B1 + J1) + D2 * (B1 + J1 - B0)\n                          --------------\n                               D1\n</code></pre>\n<p>assuming the durations of the frames are equal and thus D1 = D2:</p>\n<pre><code>    B2 = (B1 + J1) + (B1 + J1 - B0)\n\n    B2 =  2 * (B1 + J1) - B0\n</code></pre>\n<p>also:</p>\n<pre><code>    B0 = B1 - D1\n</code></pre>\n<p>so:</p>\n<pre><code>    B2 =  2 * (B1 + J1) - (B1 - D1)\n</code></pre>\n<p>Which yields a more accurate prediction for the next buffer given as:</p>\n<pre><code>    B2 =  B1 + 2 * J1 + D1                          (5)\n</code></pre>\n<h2 id=\"long-term-correction\">Long term correction</h2>\n<p>The datarate used to calculate (5) for the short term prediction is\nbased on a single observation. A more accurate datarate can be obtained\nby creating a running average over multiple datarate observations.</p>\n<p>This average is less susceptible to sudden changes that would only\ninfluence the datarate for a very short period.</p>\n<p>A running average is calculated over the observations given in (4) and\nis used as the proportion member in the QoS event that is sent upstream.</p>\n<p>Receivers of the QoS event should permanently reduce their datarate as\ngiven by the proportion member. Failure to do so will certainly lead to\nmore dropped frames and a generally worse QoS.</p>\n<h2 id=\"throttling\">Throttling</h2>\n<p>In throttle mode, the time distance between buffers is kept to a\nconfigurable throttle interval. This means that effectively the buffer\nrate is limited to 1 buffer per throttle interval. This can be used to\nlimit the framerate, for example.</p>\n<p>When an element is configured in throttling mode (this is usually only\nimplemented on sinks) it should produce QoS events upstream with the\njitter field set to the throttle interval. This should instruct upstream\nelements to skip or drop the remaining buffers in the configured\nthrottle interval.</p>\n<p>The proportion field is set to the desired slowdown needed to get the\ndesired throttle interval. Implementations can use the QoS Throttle\ntype, the proportion and the jitter member to tune their\nimplementations.</p>\n<h2 id=\"qos-strategies\">QoS strategies</h2>\n<p>Several strategies exist to reduce processing delay that might affect\nreal time performance.</p>\n<ul>\n<li>\n<p>lowering quality</p>\n</li>\n<li>\n<p>dropping frames (reduce CPU/bandwidth usage)</p>\n</li>\n<li>\n<p>switch to a lower decoding/encoding quality (reduce algorithmic\ncomplexity)</p>\n</li>\n<li>\n<p>switch to a lower quality source (reduce network usage)</p>\n</li>\n<li>\n<p>increasing thread priorities</p>\n</li>\n<li>\n<p>switch to real-time scheduling</p>\n</li>\n<li>\n<p>assign more CPU cycles to critial pipeline parts</p>\n</li>\n<li>\n<p>assign more CPU(s) to critical pipeline parts</p>\n</li>\n</ul>\n<h2 id=\"qos-implementations\">QoS implementations</h2>\n<p>Here follows a small overview of how QoS can be implemented in a range\nof different types of elements.</p>\n<h3 id=\"gstbasesink\">GstBaseSink</h3>\n<p>The primary implementor of QoS is GstBaseSink. It will calculate the\nfollowing values:</p>\n<ul>\n<li>\n<p>upstream running average of processing time (5) in stream time.</p>\n</li>\n<li>\n<p>running average of buffer durations.</p>\n</li>\n<li>\n<p>running average of render time (in system time)</p>\n</li>\n<li>\n<p>rendered/dropped buffers</p>\n</li>\n</ul>\n<p>The processing time and the average buffer durations will be used to\ncalculate a proportion.</p>\n<p>The processing time in system time is compared to render time to decide\nif the majority of the time is spend upstream or in the sink itself.\nThis value is used to decide overflow or underflow.</p>\n<p>The number of rendered and dropped buffers is used to query stats on the\nsink.</p>\n<p>A QoS event with the most current values is sent upstream for each\nbuffer that was received by the sink.</p>\n<p>Normally QoS is only enabled for video pipelines. The reason being that\ndrops in audio are more disturbing than dropping video frames. Also\nvideo requires in general more processing than audio.</p>\n<p>Normally there is a threshold for when buffers get dropped in a video\nsink. Frames that arrive 20 milliseconds late are still rendered as it\nis not noticeable for the human eye.</p>\n<p>A QoS message is posted whenever a (part of a) buffer is dropped.</p>\n<p>In throttle mode, the sink sends QoS event upstream with the timestamp\nset to the <code>running_time</code> of the latest buffer and the jitter set to the\nthrottle interval. If the throttled buffer is late, the lateness is\nsubtracted from the throttle interval in order to keep the desired\nthrottle interval.</p>\n<h3 id=\"gstbasetransform\">GstBaseTransform</h3>\n<p>Transform elements can entirely skip the transform based on the\ntimestamp and jitter values of recent QoS event since these buffers will\ncertainly arrive too late.</p>\n<p>With any intermediate element, the element should measure its\nperformance to decide if it is responsible for the quality problems or\nany upstream/downstream element.</p>\n<p>some transforms can reduce the complexity of their algorithms. Depending\non the algorithm, the changes in quality may have disturbing visual or\naudible effect that should be avoided.</p>\n<p>A QoS message should be posted when a frame is dropped or when the\nquality of the filter is reduced. The quality member in the QOS message\nshould reflect the quality setting of the filter.</p>\n<h3 id=\"video-decoders\">Video Decoders</h3>\n<p>A video decoder can, based on the codec in use, decide to not decode\nintermediate frames. A typical codec can for example skip the decoding\nof B-frames to reduce the CPU usage and framerate.</p>\n<p>If each frame is independantly decodable, any arbitrary frame can be\nskipped based on the timestamp and jitter values of the latest QoS\nevent. In addition can the proportion member be used to permanently skip\nframes.</p>\n<p>It is suggested to adjust the quality field of the QoS message with the\nexpected amount of dropped frames (skipping B and/or P frames). This\ndepends on the particular spacing of B and P frames in the stream. If\nthe quality control would result in half of the frames to be dropped\n(typical B frame skipping), the quality field would be set to <code>1000000 * 1/2 = 500000</code>. If a typical I frame spacing of 18 frames is used,\nskipping B and P frames would result in 17 dropped frames or 1 decoded\nframe every 18 frames. The quality member should be set to <code>1000000 * 1/18 = 55555</code>.</p>\n<ul>\n<li>\n<p>skipping B frames: quality = 500000</p>\n</li>\n<li>\n<p>skipping P/B frames: quality = 55555 (for I-frame spacing of 18\nframes)</p>\n</li>\n</ul>\n<h3 id=\"demuxers\">Demuxers</h3>\n<p>Demuxers usually cannot do a lot regarding QoS except for skipping\nframes to the next keyframe when a lateness QoS event arrives on a\nsource pad.</p>\n<p>A demuxer can however measure if the performance problems are upstream\nor downstream and forward an updated QoS event upstream.</p>\n<p>Most demuxers that have multiple output pads might need to combine the\nQoS events on all the pads and derive an aggregated QoS event for the\nupstream element.</p>\n<h3 id=\"sources\">Sources</h3>\n<p>The QoS events only apply to push based sources since pull based sources\nare entirely controlled by another downstream element.</p>\n<p>Sources can receive a overflow or underflow event that can be used to\nswitch to less demanding source material. In case of a network stream, a\nswitch could be done to a lower or higher quality stream or additional\nenhancement layers could be used or ignored.</p>\n<p>Live sources will automatically drop data when it takes too long to\nprocess the data that the element pushes out.</p>\n<p>Live sources should post a QoS message when data is dropped.</p>\n\n        \n\n    </div>\n\n\n        "});