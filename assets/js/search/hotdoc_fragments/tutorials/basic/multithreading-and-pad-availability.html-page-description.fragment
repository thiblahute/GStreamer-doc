fragment_downloaded_cb({"url": "tutorials/basic/multithreading-and-pad-availability.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"multithreading-and-pad-availability.md\">\n<h1 id=\"basic-tutorial-7-multithreading-and-pad-availability\">Basic tutorial 7: Multithreading and Pad Availability</h1>\n<h2 id=\"goal\">Goal</h2>\n<p>GStreamer handles multithreading automatically, but, under some\ncircumstances, you might need to decouple threads manually. This\ntutorial shows how to do this and, in addition, completes the exposition\nabout Pad Availability. More precisely, this document explains:</p>\n<ul>\n<li>\n<p>How to create new threads of execution for some parts of the\npipeline</p>\n</li>\n<li>\n<p>What is the Pad Availability</p>\n</li>\n<li>\n<p>How to replicate streams</p>\n</li>\n</ul>\n<h2 id=\"introduction\">Introduction</h2>\n<h3 id=\"multithreading\">Multithreading</h3>\n<p>GStreamer is a multithreaded framework. This means that, internally, it\ncreates and destroys threads as it needs them, for example, to decouple\nstreaming from the application thread. Moreover, plugins are also free\nto create threads for their own processing, for example, a video decoder\ncould create 4 threads to take full advantage of a CPU with 4 cores.</p>\n<p>On top of this, when building the pipeline an application can specify\nexplicitly that a <em>branch</em> (a part of the pipeline) runs on a different\nthread (for example, to have the audio and video decoders executing\nsimultaneously).</p>\n<p>This is accomplished using the <code>queue</code> element, which works as follows.\nThe sink pad just enqueues data and returns control. On a different\nthread, data is dequeued and pushed downstream. This element is also\nused for buffering, as seen later in the streaming tutorials. The size\nof the queue can be controlled through properties.</p>\n<h3 id=\"the-example-pipeline\">The example pipeline</h3>\n<p>This example builds the following pipeline:</p>\n<p><img src=\"images/tutorials/basic-tutorial-7.png\" alt=\"\"></p>\n<p>The source is a synthetic audio signal (a continuous tone) which is\nsplit using a <code>tee</code> element (it sends through its source pads everything\nit receives through its sink pad). One branch then sends the signal to\nthe audio card, and the other renders a video of the waveform and sends\nit to the screen.</p>\n<p>As seen in the picture, queues create a new thread, so this pipeline\nruns in 3 threads. Pipelines with more than one sink usually need to be\nmultithreaded, because, to be synchronized, sinks usually block\nexecution until all other sinks are ready, and they cannot get ready if\nthere is only one thread, being blocked by the first sink.</p>\n<h3 id=\"request-pads\">Request pads</h3>\n<p>In <a href=\"dynamic-pipelines.html\">Basic tutorial 3: Dynamic\npipelines</a> we saw\nan element (<code>uridecodebin</code>) which had no pads to begin with, and they\nappeared as data started to flow and the element learned about the\nmedia. These are called <strong>Sometimes Pads</strong>, and contrast with the\nregular pads which are always available and are called <strong>Always Pads</strong>.</p>\n<p>The third kind of pad is the <strong>Request Pad</strong>, which is created on\ndemand. The classical example is the <code>tee</code> element, which has one sink\npad and no initial source pads: they need to be requested and then\n<code>tee</code> adds them. In this way, an input stream can be replicated any\nnumber of times. The disadvantage is that linking elements with Request\nPads is not as automatic, as linking Always Pads, as the walkthrough for\nthis example will show.</p>\n<p>Also, to request (or release) pads in the PLAYING or PAUSED states, you\nneed to take additional cautions (Pad blocking) which are not described\nin this tutorial. It is safe to request (or release) pads in the NULL or\nREADY states, though.</p>\n<p>Without further delay, let's see the code.</p>\n<h2 id=\"simple-multithreaded-example\">Simple multithreaded example</h2>\n<p>Copy this code into a text file named <code>basic-tutorial-7.c</code> (or find it\nin the SDK installation).</p>\n<p><strong>basic-tutorial-7.c</strong></p>\n<pre><code class=\"language-c\">#include &lt;gst/gst.h&gt;\n\nint main(int argc, char *argv[]) {\n  GstElement *pipeline, *audio_source, *tee, *audio_queue, *audio_convert, *audio_resample, *audio_sink;\n  GstElement *video_queue, *visual, *video_convert, *video_sink;\n  GstBus *bus;\n  GstMessage *msg;\n  GstPadTemplate *tee_src_pad_template;\n  GstPad *tee_audio_pad, *tee_video_pad;\n  GstPad *queue_audio_pad, *queue_video_pad;\n\n  /* Initialize GStreamer */\n  gst_init (&amp;argc, &amp;argv);\n\n  /* Create the elements */\n  audio_source = gst_element_factory_make (\"audiotestsrc\", \"audio_source\");\n  tee = gst_element_factory_make (\"tee\", \"tee\");\n  audio_queue = gst_element_factory_make (\"queue\", \"audio_queue\");\n  audio_convert = gst_element_factory_make (\"audioconvert\", \"audio_convert\");\n  audio_resample = gst_element_factory_make (\"audioresample\", \"audio_resample\");\n  audio_sink = gst_element_factory_make (\"autoaudiosink\", \"audio_sink\");\n  video_queue = gst_element_factory_make (\"queue\", \"video_queue\");\n  visual = gst_element_factory_make (\"wavescope\", \"visual\");\n  video_convert = gst_element_factory_make (\"videoconvert\", \"csp\");\n  video_sink = gst_element_factory_make (\"autovideosink\", \"video_sink\");\n\n  /* Create the empty pipeline */\n  pipeline = gst_pipeline_new (\"test-pipeline\");\n\n  if (!pipeline || !audio_source || !tee || !audio_queue || !audio_convert || !audio_resample || !audio_sink ||\n      !video_queue || !visual || !video_convert || !video_sink) {\n    g_printerr (\"Not all elements could be created.\\n\");\n    return -1;\n  }\n\n  /* Configure elements */\n  g_object_set (audio_source, \"freq\", 215.0f, NULL);\n  g_object_set (visual, \"shader\", 0, \"style\", 1, NULL);\n\n  /* Link all elements that can be automatically linked because they have \"Always\" pads */\n  gst_bin_add_many (GST_BIN (pipeline), audio_source, tee, audio_queue, audio_convert, audio_resample, audio_sink,\n      video_queue, visual, video_convert, video_sink, NULL);\n  if (gst_element_link_many (audio_source, tee, NULL) != TRUE ||\n      gst_element_link_many (audio_queue, audio_convert, audio_resample, audio_sink, NULL) != TRUE ||\n      gst_element_link_many (video_queue, visual, video_convert, video_sink, NULL) != TRUE) {\n    g_printerr (\"Elements could not be linked.\\n\");\n    gst_object_unref (pipeline);\n    return -1;\n  }\n\n  /* Manually link the Tee, which has \"Request\" pads */\n  tee_src_pad_template = gst_element_class_get_pad_template (GST_ELEMENT_GET_CLASS (tee), \"src_%d\");\n  tee_audio_pad = gst_element_request_pad (tee, tee_src_pad_template, NULL, NULL);\n  g_print (\"Obtained request pad %s for audio branch.\\n\", gst_pad_get_name (tee_audio_pad));\n  queue_audio_pad = gst_element_get_static_pad (audio_queue, \"sink\");\n  tee_video_pad = gst_element_request_pad (tee, tee_src_pad_template, NULL, NULL);\n  g_print (\"Obtained request pad %s for video branch.\\n\", gst_pad_get_name (tee_video_pad));\n  queue_video_pad = gst_element_get_static_pad (video_queue, \"sink\");\n  if (gst_pad_link (tee_audio_pad, queue_audio_pad) != GST_PAD_LINK_OK ||\n      gst_pad_link (tee_video_pad, queue_video_pad) != GST_PAD_LINK_OK) {\n    g_printerr (\"Tee could not be linked.\\n\");\n    gst_object_unref (pipeline);\n    return -1;\n  }\n  gst_object_unref (queue_audio_pad);\n  gst_object_unref (queue_video_pad);\n\n  /* Start playing the pipeline */\n  gst_element_set_state (pipeline, GST_STATE_PLAYING);\n\n  /* Wait until error or EOS */\n  bus = gst_element_get_bus (pipeline);\n  msg = gst_bus_timed_pop_filtered (bus, GST_CLOCK_TIME_NONE, GST_MESSAGE_ERROR | GST_MESSAGE_EOS);\n\n  /* Release the request pads from the Tee, and unref them */\n  gst_element_release_request_pad (tee, tee_audio_pad);\n  gst_element_release_request_pad (tee, tee_video_pad);\n  gst_object_unref (tee_audio_pad);\n  gst_object_unref (tee_video_pad);\n\n  /* Free resources */\n  if (msg != NULL)\n    gst_message_unref (msg);\n  gst_object_unref (bus);\n  gst_element_set_state (pipeline, GST_STATE_NULL);\n\n  gst_object_unref (pipeline);\n  return 0;\n}\n</code></pre>\n<blockquote>\n<p><img src=\"images/icons/emoticons/information.png\" alt=\"Information\" id=\"information\">\nNeed help?</p>\n<p>If you need help to compile this code, refer to the <strong>Building the tutorials</strong>  section for your platform: <a href=\"../../installing/on-linux.html#InstallingonLinux-Build\">Linux</a>, <a href=\"../../installing/on-mac-osx.html#InstallingonMacOSX-Build\">Mac OS X</a> or <a href=\"../../installing/on-windows.html#InstallingonWindows-Build\">Windows</a>, or use this specific command on Linux:</p>\n<p><code>gcc basic-tutorial-7.c -o basic-tutorial-7 `pkg-config --cflags --libs gstreamer-1.0`</code></p>\n<p>If you need help to run this code, refer to the <strong>Running the tutorials</strong> section for your platform: <a href=\"../../installing/on-linux.html#InstallingonLinux-Run\">Linux</a>, <a href=\"../../installing/on-mac-osx.html#InstallingonMacOSX-Run\">Mac OS X</a> or <a href=\"../../installing/on-windows.html#InstallingonWindows-Run\">Windows</a>.</p>\n<p>This tutorial plays an audible tone through the audio card and opens a window with a waveform representation of the tone. The waveform should be a sinusoid, but due to the refreshing of the window might not appear so.</p>\n<p>Required libraries: <code>gstreamer-1.0</code></p>\n</blockquote>\n<h2 id=\"walkthrough\">Walkthrough</h2>\n<pre><code class=\"language-c\">/* Create the elements */\naudio_source = gst_element_factory_make (\"audiotestsrc\", \"audio_source\");\ntee = gst_element_factory_make (\"tee\", \"tee\");\naudio_queue = gst_element_factory_make (\"queue\", \"audio_queue\");\naudio_convert = gst_element_factory_make (\"audioconvert\", \"audio_convert\");\n  audio_resample = gst_element_factory_make (\"audioresample\", \"audio_resample\");\naudio_sink = gst_element_factory_make (\"autoaudiosink\", \"audio_sink\");\nvideo_queue = gst_element_factory_make (\"queue\", \"video_queue\");\nvisual = gst_element_factory_make (\"wavescope\", \"visual\");\nvideo_convert = gst_element_factory_make (\"videoconvert\", \"video_convert\");\nvideo_sink = gst_element_factory_make (\"autovideosink\", \"video_sink\");\n</code></pre>\n<p>All the elements in the above picture are instantiated here:</p>\n<p><code>audiotestsrc</code> produces a synthetic tone. <code>wavescope</code> consumes an audio\nsignal and renders a waveform as if it was an (admittedly cheap)\noscilloscope. We have already worked with the <code>autoaudiosink</code> and\n<code>autovideosink</code>.</p>\n<p>The conversion elements (<code>audioconvert</code>, <code>audioresample</code> and\n<code>videoconvert</code>) are necessary to guarantee that the pipeline can be\nlinked. Indeed, the Capabilities of the audio and video sinks depend on\nthe hardware, and you do not know at design time if they will match the\nCaps produced by the <code>audiotestsrc</code> and <code>wavescope</code>. If the Caps\nmatched, though, these elements act in \u201cpass-through\u201d mode and do not\nmodify the signal, having negligible impact on performance.</p>\n<pre><code class=\"language-c\">/* Configure elements */\ng_object_set (audio_source, \"freq\", 215.0f, NULL);\ng_object_set (visual, \"shader\", 0, \"style\", 1, NULL);\n</code></pre>\n<p>Small adjustments for better demonstration: The \u201cfreq\u201d property of\n<code>audiotestsrc</code> controls the frequency of the wave (215Hz makes the wave\nappear almost stationary in the window), and this style and shader for\n<code>wavescope</code> make the wave continuous. Use the <code>gst-inspect-1.0</code> tool\ndescribed in <a href=\"gstreamer-tools.html\">Basic tutorial 10: GStreamer\ntools</a> to learn all\nthe properties of these\nelements.</p>\n<pre><code class=\"language-c\">/* Link all elements that can be automatically linked because they have \"Always\" pads */\ngst_bin_add_many (GST_BIN (pipeline), audio_source, tee, audio_queue, audio_convert, audio_sink,\n    video_queue, visual, video_convert, video_sink, NULL);\nif (gst_element_link_many (audio_source, tee, NULL) != TRUE ||\n    gst_element_link_many (audio_queue, audio_convert, audio_sink, NULL) != TRUE ||\n    gst_element_link_many (video_queue, visual, video_convert, video_sink, NULL) != TRUE) {\n  g_printerr (\"Elements could not be linked.\\n\");\n  gst_object_unref (pipeline);\n  return -1;\n}\n</code></pre>\n<p>This code block adds all elements to the pipeline and then links the\nones that can be automatically linked (the ones with Always Pads, as the\ncomment says).</p>\n<blockquote>\n<p><img src=\"images/icons/emoticons/warning.png\" alt=\"Warning\" id=\"warning\">\n<code>gst_element_link_many()</code> can actually link elements with Request Pads. It internally requests the Pads so you do not have worry about the elements being linked having Always or Request Pads. Strange as it might seem, this is actually inconvenient, because you still need to release the requested Pads afterwards, and, if the Pad was requested automatically by <code>gst_element_link_many()</code>, it is easy to forget. Stay out of trouble by always requesting Request Pads manually, as shown in the next code block.</p>\n</blockquote>\n<pre><code class=\"language-c\">/* Manually link the Tee, which has \"Request\" pads */\ntee_src_pad_template = gst_element_class_get_pad_template (GST_ELEMENT_GET_CLASS (tee), \"src_%d\");\ntee_audio_pad = gst_element_request_pad (tee, tee_src_pad_template, NULL, NULL);\ng_print (\"Obtained request pad %s for audio branch.\\n\", gst_pad_get_name (tee_audio_pad));\nqueue_audio_pad = gst_element_get_static_pad (audio_queue, \"sink\");\ntee_video_pad = gst_element_request_pad (tee, tee_src_pad_template, NULL, NULL);\ng_print (\"Obtained request pad %s for video branch.\\n\", gst_pad_get_name (tee_video_pad));\nqueue_video_pad = gst_element_get_static_pad (video_queue, \"sink\");\nif (gst_pad_link (tee_audio_pad, queue_audio_pad) != GST_PAD_LINK_OK ||\n    gst_pad_link (tee_video_pad, queue_video_pad) != GST_PAD_LINK_OK) {\n  g_printerr (\"Tee could not be linked.\\n\");\n  gst_object_unref (pipeline);\n  return -1;\n}\ngst_object_unref (queue_audio_pad);\ngst_object_unref (queue_video_pad);\n</code></pre>\n<p>To link Request Pads, they need to be obtained by \u201crequesting\u201d them to\nthe element. An element might be able to produce different kinds of\nRequest Pads, so, when requesting them, the desired Pad Template must be\nprovided. Pad templates are obtained with\n<code>gst_element_class_get_pad_template()</code> and are identified by their name.\nIn the documentation for the <code>tee</code> element we see that it has two pad\ntemplates named \u201csink\u201d (for its sink Pads) and \u201csrc_%d\u201d (for the Request\nPads).</p>\n<p>Once we have the Pad template, we request two Pads from the tee (for the\naudio and video branches) with <code>gst_element_request_pad()</code>.</p>\n<p>We then obtain the Pads from the downstream elements to which these\nRequest Pads need to be linked. These are normal Always Pads, so we\nobtain them with <code>gst_element_get_static_pad()</code>.</p>\n<p>Finally, we link the pads with <code>gst_pad_link()</code>. This is the function\nthat <code>gst_element_link()</code> and <code>gst_element_link_many()</code> use internally.</p>\n<p>The sink Pads we have obtained need to be released with\n<code>gst_object_unref()</code>. The Request Pads will be released when we no\nlonger need them, at the end of the program.</p>\n<p>We then set the pipeline to playing as usual, and wait until an error\nmessage or an EOS is produced. The only thing left to so is cleanup the\nrequested Pads:</p>\n<pre><code class=\"language-c\">/* Release the request pads from the Tee, and unref them */\ngst_element_release_request_pad (tee, tee_audio_pad);\ngst_element_release_request_pad (tee, tee_video_pad);\ngst_object_unref (tee_audio_pad);\ngst_object_unref (tee_video_pad);\n</code></pre>\n<p><code>gst_element_release_request_pad()</code> releases the pad from the <code>tee</code>, but\nit still needs to be unreferenced (freed) with <code>gst_object_unref()</code>.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>This tutorial has shown:</p>\n<ul>\n<li>\n<p>How to make parts of a pipeline run on a different thread by using\n<code>queue</code> elements.</p>\n</li>\n<li>\n<p>What is a Request Pad and how to link elements with request pads,\nwith <code>gst_element_class_get_pad_template()</code>, <code>gst_element_request_pad()</code>, <code>gst_pad_link()</code> and\n<code>gst_element_release_request_pad()</code>.</p>\n</li>\n<li>\n<p>How to have the same stream available in different branches by using\n<code>tee</code> elements.</p>\n</li>\n</ul>\n<p>The next tutorial builds on top of this one to show how data can be\nmanually injected into and extracted from a running pipeline.</p>\n<p>It has been a pleasure having you here, and see you soon!</p>\n\n</div>\n\n\n        "});