fragment_downloaded_cb({"url": "tutorials/basic/handy-elements.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"handy-elements.md\">\n<h1 id=\"basic-tutorial-14-handy-elements\">Basic tutorial 14: Handy elements</h1>\n<h2 id=\"goal\">Goal</h2>\n<p>This tutorial gives a list of handy GStreamer elements that are worth\nknowing. They range from powerful all-in-one elements that allow you to\nbuild complex pipelines easily (like <code>playbin</code>), to little helper\nelements which are extremely useful when debugging.</p>\n<p>For simplicity, the following examples are given using the\n<code>gst-launch-1.0</code> tool (Learn about it in\n<a href=\"gstreamer-tools.html\">Basic tutorial 10: GStreamer tools</a>). Use the <code>-v</code> command line\nparameter if you want to see the Pad Caps that are being negotiated.</p>\n<h2 id=\"bins\">Bins</h2>\n<p>These are Bin elements which you treat as a single element and they take\ncare of instantiating all the necessary internal pipeline to accomplish\ntheir task.</p>\n<h3 id=\"playbin\"><code>playbin</code></h3>\n<p>This element has been extensively used throughout the tutorials. It\nmanages all aspects of media playback, from source to display, passing\nthrough demuxing and decoding. It is so flexible and has so many options\nthat a whole set of tutorials are devoted to it. See the <a href=\"../playback/index.html\">Playback tutorials</a> for more details.</p>\n<h3 id=\"uridecodebin\"><code>uridecodebin</code></h3>\n<p>This element decodes data from a URI into raw media. It selects a source\nelement that can handle the given URI scheme and connects it to\na <code>decodebin</code> element. It acts like a demuxer, so it offers as many\nsource pads as streams are found in the\nmedia.</p>\n<pre><code class=\"language-bash\">gst-launch-1.0 uridecodebin uri=https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm ! videoconvert ! autovideosink\n</code></pre>\n<pre><code class=\"language-bash\">gst-launch-1.0 uridecodebin uri=https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm ! audioconvert ! autoaudiosink\n</code></pre>\n<h3 id=\"decodebin\"><code>decodebin</code></h3>\n<p>This element automatically constructs a decoding pipeline using\navailable decoders and demuxers via auto-plugging until raw media is\nobtained.  It is used internally by <code>uridecodebin</code> which is often more\nconvenient to use, as it creates a suitable source element as well. It\nreplaces the old <code>decodebin</code> element. It acts like a demuxer, so it\noffers as many source pads as streams are found in the\nmedia.</p>\n<pre><code class=\"language-bash\">gst-launch-1.0 souphttpsrc location=https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm ! decodebin ! autovideosink\n</code></pre>\n<h2 id=\"file-inputoutput\">File input/output</h2>\n<h3 id=\"filesrc\"><code>filesrc</code></h3>\n<p>This element reads a local file and produces media with <code>ANY</code> Caps. If\nyou want to obtain the correct Caps for the media, explore the stream by\nusing a <code>typefind</code> element or by setting the <code>typefind</code> property\nof <code>filesrc</code> to\n<code>TRUE</code>.</p>\n<pre><code class=\"language-c\">gst-launch-1.0 filesrc location=f:\\\\media\\\\sintel\\\\sintel_trailer-480p.webm ! decodebin ! autovideosink\n</code></pre>\n<h3 id=\"filesink\"><code>filesink</code></h3>\n<p>This element writes to a file all the media it receives. Use the\n<code>location</code> property to specify the file\nname.</p>\n<pre><code>gst-launch-1.0 audiotestsrc ! vorbisenc ! oggmux ! filesink location=test.ogg\n</code></pre>\n<h2 id=\"network\">Network</h2>\n<h3 id=\"souphttpsrc\"><code>souphttpsrc</code></h3>\n<p>This element receives data as a client over the network via HTTP using\nthe <a href=\"https://wiki.gnome.org/Projects/libsoup\">libsoup</a> library. Set the URL to retrieve through the <code>location</code>\nproperty.</p>\n<pre><code class=\"language-bash\">gst-launch-1.0 souphttpsrc location=https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm ! decodebin ! autovideosink\n</code></pre>\n<h2 id=\"test-media-generation\">Test media generation</h2>\n<p>These elements are very useful to check if other parts of the pipeline\nare working, by replacing the source by one of these test sources which\nare \u201cguaranteed\u201d to work.</p>\n<h3 id=\"videotestsrc\"><code>videotestsrc</code></h3>\n<p>This element produces a video pattern (selectable among many different\noptions with the <code>pattern</code> property). Use it to test video pipelines.</p>\n<pre><code class=\"language-bash\">gst-launch-1.0 videotestsrc ! videoconvert ! autovideosink\n</code></pre>\n<h3 id=\"audiotestsrc\"><code>audiotestsrc</code></h3>\n<p>This element produces an audio wave (selectable among many different\noptions with the <code>wave</code> property). Use it to test video pipelines.</p>\n<pre><code class=\"language-bash\">gst-launch-1.0 audiotestsrc ! audioconvert ! autoaudiosink\n</code></pre>\n<h2 id=\"video-adapters\">Video adapters</h2>\n<h3 id=\"videoconvert\"><code>videoconvert</code></h3>\n<p>This element converts from one color space (e.g. RGB) to another one\n(e.g. YUV). It can also convert between different YUV formats (e.g.\nI420, NV12, YUY2 \u2026) or RGB format arrangements (e.g. RGBA, ARGB, BGRA\u2026).</p>\n<p>This is normally your first choice when solving negotiation problems.\nWhen not needed, because its upstream and downstream elements can\nalready understand each other, it acts in pass-through mode having\nminimal impact on the performance.</p>\n<p>As a rule of thumb, always use <code>videoconvert</code> whenever you use\nelements whose Caps are unknown at design time, like <code>autovideosink</code>, or\nthat can vary depending on external factors, like decoding a\nuser-provided file.</p>\n<pre><code class=\"language-bash\">gst-launch-1.0 videotestsrc ! videoconvert ! autovideosink\n</code></pre>\n<h3 id=\"videorate\"><code>videorate</code></h3>\n<p>This element takes an incoming stream of time-stamped video frames and\nproduces a stream that matches the source pad's frame rate. The\ncorrection is performed by dropping and duplicating frames, no fancy\nalgorithm is used to interpolate frames.</p>\n<p>This is useful to allow elements requiring different frame rates to\nlink. As with the other adapters, if it is not needed (because there is\na frame rate on which both Pads can agree), it acts in pass-through mode\nand does not impact performance.</p>\n<p>It is therefore a good idea to always use it whenever the actual frame\nrate is unknown at design time, just in\ncase.</p>\n<pre><code class=\"language-c\">gst-launch-1.0 videotestsrc ! video/x-raw,framerate=30/1 ! videorate ! video/x-raw,framerate=1/1 ! videoconvert ! autovideosink\n</code></pre>\n<h3 id=\"videoscale\"><code>videoscale</code></h3>\n<p>This element resizes video frames. By default the element tries to\nnegotiate to the same size on the source and sink Pads so that no\nscaling is needed. It is therefore safe to insert this element in a\npipeline to get more robust behavior without any cost if no scaling is\nneeded.</p>\n<p>This element supports a wide range of color spaces including various YUV\nand RGB formats and is therefore generally able to operate anywhere in a\npipeline.</p>\n<p>If the video is to be output to a window whose size is controlled by the\nuser, it is a good idea to use a <code>videoscale</code> element, since not all\nvideo sinks are capable of performing scaling\noperations.</p>\n<pre><code class=\"language-bash\">gst-launch-1.0 uridecodebin uri=https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm ! videoscale ! video/x-raw,width=178,height=100 ! videoconvert ! autovideosink\n</code></pre>\n<h2 id=\"audio-adapters\">Audio adapters</h2>\n<h3 id=\"audioconvert\"><code>audioconvert</code></h3>\n<p>This element converts raw audio buffers between various possible\nformats. It supports integer to float conversion, width/depth\nconversion, signedness and endianness conversion and channel\ntransformations.</p>\n<p>Like <code>videoconvert</code> does for video, you use this to solve\nnegotiation problems with audio, and it is generally safe to use it\nliberally, since this element does nothing if it is not needed.</p>\n<pre><code class=\"language-bash\">gst-launch-1.0 audiotestsrc ! audioconvert ! autoaudiosink\n</code></pre>\n<h3 id=\"audioresample\"><code>audioresample</code></h3>\n<p>This element resamples raw audio buffers to different sampling rates\nusing a configurable windowing function to enhance quality</p>\n<p>Again, use it to solve negotiation problems regarding sampling rates and\ndo not fear to use it\ngenerously.</p>\n<pre><code class=\"language-bash\">gst-launch-1.0 uridecodebin uri=https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-480p.webm ! audioresample ! audio/x-raw-float,rate=4000 ! audioconvert ! autoaudiosink\n</code></pre>\n<h3 id=\"audiorate\"><code>audiorate</code></h3>\n<p>This element takes an incoming stream of time-stamped raw audio frames\nand produces a perfect stream by inserting or dropping samples as\nneeded. It does not allow the sample rate to be changed\nas <code>videorate</code> does, it just fills gaps and removes overlapped samples\nso the output stream is continuous and \u201cclean\u201d.</p>\n<p>It is useful in situations where the timestamps are going to be lost\n(when storing into certain file formats, for example) and the receiver\nwill require all samples to be present. It is cumbersome to exemplify\nthis, so no example is given.</p>\n<p><img src=\"images/icons/emoticons/warning.png\" alt=\"Warning\" id=\"warning\">\nMost of the time, <code>audiorate</code> is not what you want.</p>\n<h2 id=\"multithreading\">Multithreading</h2>\n<h3 id=\"queue\"><code>queue</code></h3>\n<p>Queues have been explained in <a href=\"multithreading-and-pad-availability.html\">Basic tutorial 7: Multithreading and Pad Availability</a>. Basically, a queue performs two tasks:</p>\n<ul>\n<li>Data is queued until a selected limit is reached. Any attempt to\npush more buffers into the queue blocks the pushing thread until\nmore space becomes available.</li>\n<li>The queue creates a new thread on the source Pad to decouple the\nprocessing on sink and source Pads.</li>\n</ul>\n<p>Additionally, <code>queue</code> triggers signals when it is about to become empty\nor full (according to some configurable thresholds), and can be\ninstructed to drop buffers instead of blocking when it is full.</p>\n<p>As a rule of thumb, prefer the simpler <code>queue</code> element\nover <code>queue2</code> whenever network buffering is not a concern to you.\nSee <a href=\"multithreading-and-pad-availability.html\">Basic tutorial 7: Multithreading and Pad Availability</a>\nfor an example.</p>\n<h3 id=\"queue2\"><code>queue2</code></h3>\n<p>This element is not an evolution of <code>queue</code>. It has the same design\ngoals but follows a different implementation approach, which results in\ndifferent features. Unfortunately, it is often not easy to tell which\nqueue is the best choice.</p>\n<p><code>queue2</code> performs the two tasks listed above for <code>queue</code>, and,\nadditionally, is able to store the received data (or part of it) on a\ndisk file, for later retrieval. It also replaces the signals with the\nmore general and convenient buffering messages described in\n<a href=\"streaming.html\">Basic tutorial 12: Streaming</a>.</p>\n<p>As a rule of thumb, prefer <code>queue2</code> over <code>queue</code> whenever network\nbuffering is a concern to you. See <a href=\"streaming.html\">Basic tutorial 12: Streaming</a>\nfor an example (<code>queue2</code> is hidden inside <code>playbin</code>).</p>\n<h3 id=\"multiqueue\"><code>multiqueue</code></h3>\n<p>This element provides queues for multiple streams simultaneously, and\neases their management, by allowing some queues to grow if no data is\nbeing received on other streams, or by allowing some queues to drop data\nif they are not connected to anything (instead of returning an error, as\na simpler queue would do). Additionally, it synchronizes the different\nstreams, ensuring that none of them goes too far ahead of the others.</p>\n<p>This is an advanced element. It is found inside <code>decodebin</code>, but you\nwill rarely need to instantiate it yourself in a normal playback\napplication.</p>\n<h3 id=\"tee\"><code>tee</code></h3>\n<p><a href=\"multithreading-and-pad-availability.html\">Basic tutorial 7: Multithreading and Pad Availability</a> already\nshowed how to use a <code>tee</code> element, which splits data to multiple pads.\nSplitting the data flow is useful, for example, when capturing a video\nwhere the video is shown on the screen and also encoded and written to a\nfile. Another example is playing music and hooking up a visualization\nmodule.</p>\n<p>One needs to use separate <code>queue</code> elements in each branch to provide\nseparate threads for each branch. Otherwise a blocked dataflow in one\nbranch would stall the other\nbranches.</p>\n<pre><code>gst-launch-1.0 audiotestsrc ! tee name=t ! queue ! audioconvert ! autoaudiosink t. ! queue ! wavescope ! videoconvert ! autovideosink\n</code></pre>\n<h2 id=\"capabilities\">Capabilities</h2>\n<h3 id=\"capsfilter\"><code>capsfilter</code></h3>\n<p><a href=\"gstreamer-tools.html\">Basic tutorial 10: GStreamer tools</a> already\nexplained how to use Caps filters with <code>gst-launch-1.0</code>. When building a\npipeline programmatically, Caps filters are implemented with\nthe <code>capsfilter</code> element. This element does not modify data as such,\nbut enforces limitations on the data format.</p>\n<pre><code class=\"language-bash\">gst-launch-1.0 videotestsrc ! video/x-raw, format=GRAY8 ! videoconvert ! autovideosink\n</code></pre>\n<h3 id=\"typefind\"><code>typefind</code></h3>\n<p>This element determines the type of media a stream contains. It applies\ntypefind functions in the order of their rank. Once the type has been\ndetected it sets its source Pad Caps to the found media type and emits\nthe <code>have-type</code> signal.</p>\n<p>It is instantiated internally by <code>decodebin</code>, and you can use it too to\nfind the media type, although you can normally use the\n<code>GstDiscoverer</code> which provides more information (as seen in\n<a href=\"media-information-gathering.html\">Basic tutorial 9: Media information gathering</a>).</p>\n<h2 id=\"debugging\">Debugging</h2>\n<h3 id=\"fakesink\"><code>fakesink</code></h3>\n<p>This sink element simply swallows any data fed to it. It is useful when\ndebugging, to replace your normal sinks and rule them out of the\nequation. It can be very verbose when combined with the <code>-v</code> switch\nof <code>gst-launch-1.0</code>, so use the <code>silent</code> property to remove any unwanted\nnoise.</p>\n<pre><code>gst-launch-1.0 audiotestsrc num-buffers=1000 ! fakesink sync=false\n</code></pre>\n<h3 id=\"identity\"><code>identity</code></h3>\n<p>This is a dummy element that passes incoming data through unmodified. It\nhas several useful diagnostic functions, such as offset and timestamp\nchecking, or buffer dropping. Read its documentation to learn all the\nthings this seemingly harmless element can\ndo.</p>\n<pre><code>gst-launch-1.0 audiotestsrc ! identity drop-probability=0.1 ! audioconvert ! autoaudiosink\n</code></pre>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>This tutorial has listed a few elements which are worth knowing, due to\ntheir usefulness in the day-to-day work with GStreamer. Some are\nvaluable for production pipelines, whereas others are only needed for\ndebugging purposes.</p>\n<p>It has been a pleasure having you here, and see you soon!</p>\n\n</div>\n\n\n\t"});