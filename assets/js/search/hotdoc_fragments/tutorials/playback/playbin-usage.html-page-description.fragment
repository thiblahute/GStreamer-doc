fragment_downloaded_cb({"url": "tutorials/playback/playbin-usage.html#page-description", "fragment": "We have already worked with the playbin element which is capable of building a complete playback pipeline without much work on our side. This tutorial shows how to further customize playbin in case its default values do not suit our particular needs. \nWe will learn \nHow to find out how many streams a file contains and how to switch among them. \nHow to gather information regarding each stream. \nMore often than not multiple audio video and subtitle streams can be found embedded in a single file. The most common case are regular movies which contain one video and one audio stream Stereo or audio tracks are considered a single stream It is also increasingly common to find movies with one video and multiple audio streams to account for different languages. In this case the user selects one audio stream and the application will only play that one ignoring the others. \nTo be able to select the appropriate stream the user needs to know certain information about them for example their language. This information is embedded in the streams in the form of metadata annexed data and this tutorial shows how to retrieve it. \nSubtitles can also be embedded in a file along with audio and video but they are dealt with in more detail in Playback tutorial Subtitle management. Finally multiple video streams can also be found in a single file for example in DVD with multiple angles of the same scene but they are somewhat rare. \nEmbedding multiple streams inside a single file is called multiplexing or muxing and such file is then known as a container Common container formats are Matroska mkv Quicktime qt mov mp4 Ogg ogg or Webm webm \nRetrieving the individual streams from within the container is called demultiplexing or demuxing \nThe following code recovers the amount of streams in the file their associated metadata and allows switching the audio stream while the media is playing. \nCopy this code into a text file named playback tutorial c or find it in the GStreamer installation \nplayback tutorial c \nIf you need help to compile this code refer to the Building the tutorials section for your platform Mac or Windows or use this specific command on Linux \ngcc playback tutorial c o playback tutorial pkg config cflags libs gstreamer \nIf you need help to run this code refer to the Running the tutorials section for your platform Mac OS X Windows for iOS or for android. \nThis tutorial opens a window and displays a movie with accompanying audio. The media is fetched from the Internet so the window might take a few seconds to appear depending on your connection speed. The number of audio streams is shown in the terminal and the user can switch from one to another by entering a number and pressing enter. A small delay is to be expected. \nBear in mind that there is no latency management buffering so on slow connections the movie might stop after a few seconds. See how Tutorial Live streaming solves this issue. \nRequired libraries gstreamer \nWe start as usual putting all our variables in a structure so we can pass it around to functions. For this tutorial we need the amount of streams of each type and the currently playing one. Also we are going to use a different mechanism to wait for messages that allows interactivity so we need a GLib s main loop object. \nLater we are going to set some of playbin s flags. We would like to have a handy enum that allows manipulating these flags easily but since playbin is a plug in and not a part of the GStreamer core this enum is not available to us. The trick is simply to declare this enum in our code as it appears in the playbin documentation GstPlayFlags. GObject allows introspection so the possible values for these flags can be retrieved at runtime without using this trick but in a far more cumbersome way. \nForward declarations for the two callbacks we will be using. handle_message for the GStreamer messages as we have already seen and handle_keyboard for key strokes since this tutorial is introducing a limited amount of interactivity. \nWe skip over the creation of the pipeline the instantiation of playbin and pointing it to our test media through the uri property. playbin is in itself a pipeline and in this case it is the only element in the pipeline so we skip completely the creation of the pipeline and use directly the playbin element. \nWe focus on some of the other properties of playbin though \nplaybin s behavior can be changed through its flags property which can have any combination of GstPlayFlags. The most interesting values are \nIn our case for demonstration purposes we are enabling audio and video and disabling subtitles leaving the rest of flags to their default values this is why we read the current value of the flags with g_object_get before overwriting it with g_object_set \nThis property is not really useful in this example. connection speed informs playbin of the maximum speed of our network connection so in case multiple versions of the requested media are available in the server playbin chooses the most appropriate. This is mostly used in combination with streaming protocols like mms or rtsp. \nWe have set all these properties one by one but we could have all of them with a single call to g_object_set \nThis is why g_object_set requires a NULL as the last parameter. \nThese lines connect a callback function to the standard input the keyboard The mechanism shown here is specific to GLib and not really related to GStreamer so there is no point in going into much depth. Applications normally have their own way of handling user input and GStreamer has little to do with it besides the Navigation interface discussed briefly in Tutorial DVD playback \nTo allow interactivity we will no longer poll the GStreamer bus manually. Instead we create a GMainLoop GLib main loop and set it running with g_main_loop_run This function blocks and will not return until g_main_loop_quit is issued. In the meantime it will call the callbacks we have registered at the appropriate times handle_message when a message appears on the bus and handle_keyboard when the user presses any key. \nThere is nothing new in handle_message except that when the pipeline moves to the PLAYING state it will call the analyze_streams function \nAs the comment says this function just gathers information from the media and prints it on the screen. The number of video audio and subtitle streams is directly available through the n video n audio and n text properties. \nNow for each stream we want to retrieve its metadata. Metadata is stored as tags in a GstTagList structure which is a list of data pieces identified by a name. The GstTagList associated with a stream can be recovered with g_signal_emit_by_name and then individual tags are extracted with the gst_tag_list_get_ functions like gst_tag_list_get_string for example. \nThis rather unintuitive way of retrieving the tag list is called an Action Signal. Action signals are emitted by the application to a specific element which then performs an action and returns a result. They behave like a dynamic function call in which methods of a class are identified by their name the signal s name instead of their memory address. These signals are listed In the documentation along with the regular signals and are tagged Action See playbin for example. \nplaybin defines action signals to retrieve metadata get video tags get audio tags and get text tags. The name if the tags is standardized and the list can be found in the GstTagList documentation. In this example we are interested in the GST_TAG_LANGUAGE_CODE of the streams and their GST_TAG_ _CODEC audio video or text \nOnce we have extracted all the metadata we want we get the streams that are currently selected through more properties of playbin current video current audio and current text. \nIt is interesting to always check the currently selected streams and never make any assumption. Multiple internal conditions can make playbin behave differently in different executions. Also the order in which the streams are listed can change from one run to another so checking the metadata to identify one particular stream becomes crucial. \nFinally we allow the user to switch the running audio stream. This very basic function just reads a string from the standard input the keyboard interprets it as a number and tries to set the current audio property of playbin which previously we have only read \nBear in mind that the switch is not immediate. Some of the previously decoded audio will still be flowing through the pipeline while the new stream becomes active and is decoded. The delay depends on the particular multiplexing of the streams in the container and the length playbin has selected for its internal queues which depends on the network conditions \nIf you execute the tutorial you will be able to switch from one language to another while the movie is running by pressing or and ENTER This concludes this tutorial. \nThis tutorial has shown \nA few more of playbin s properties flags connection speed n video n audio n text current video current audio and current text. \nHow to retrieve the list of tags associated with a stream with g_signal_emit_by_name \nHow to retrieve a particular tag from the list with gst_tag_list_get_string or gst_tag_list_get_uint \nHow to switch the current audio simply by writing to the current audio property. \nThe next playback tutorial shows how to handle subtitles either embedded in the container or in an external file. \nRemember that attached to this page you should find the complete source code of the tutorial and any accessory files needed to build it. \nIt has been a pleasure having you here and see you soon \n"});