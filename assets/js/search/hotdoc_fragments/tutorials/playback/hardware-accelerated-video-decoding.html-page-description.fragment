fragment_downloaded_cb({"url": "tutorials/playback/hardware-accelerated-video-decoding.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"hardware-accelerated-video-decoding.md\">\n        <h1 id=\"playback-tutorial-8-hardwareaccelerated-video-decoding\">Playback tutorial 8: Hardware-accelerated video decoding</h1>\n<h3 id=\"goal\">Goal</h3>\n<p>Hardware-accelerated video decoding has rapidly become a necessity, as\nlow-power devices grow more common. This tutorial (more of a lecture,\nactually) gives some background on hardware acceleration and explains\nhow does GStreamer benefit from it.</p>\n<p>Sneak peek: if properly setup, you do not need to do anything special to\nactivate hardware acceleration; GStreamer automatically takes advantage\nof it.</p>\n<h3 id=\"introduction\">Introduction</h3>\n<p>Video decoding can be an extremely CPU-intensive task, especially for\nhigher resolutions like 1080p HDTV. Fortunately, modern graphics cards,\nequipped with programmable GPUs, are able to take care of this job,\nallowing the CPU to concentrate on other duties. Having dedicated\nhardware becomes essential for low-power CPUs which are simply incapable\nof decoding such media fast enough.</p>\n<p>In the current state of things (June 2016) each GPU manufacturer offers\na different method to access their hardware (a different API), and a\nstrong industry standard has not emerged yet.</p>\n<p>As of June 2016, there exist at least 8 different video decoding\nacceleration APIs:</p>\n<ul>\n<li>\n<p><a href=\"http://en.wikipedia.org/wiki/Video_Acceleration_API\">VAAPI</a> (<em>Video\nAcceleration API</em>): Initially designed by\n<a href=\"http://en.wikipedia.org/wiki/Intel\">Intel</a> in 2007, targeted at the X\nWindow System on Unix-based operating systems, now open-source. It now also\nsupports Wayland through dmabuf. It is\ncurrently not limited to Intel GPUs as other manufacturers are free to\nuse this API, for example, <a href=\"http://en.wikipedia.org/wiki/Imagination_Technologies\">Imagination\nTechnologies</a> or\n<a href=\"http://en.wikipedia.org/wiki/S3_Graphics\">S3 Graphics</a>. Accessible to\nGStreamer through the <a href=\"https://cgit.freedesktop.org/gstreamer/gstreamer-vaapi/\">gstreamer-vaapi</a> package.</p>\n</li>\n<li>\n<p><a href=\"http://en.wikipedia.org/wiki/VDPAU\">VDPAU</a> (<em>Video Decode and\nPresentation API for UNIX</em>): Initially designed by\n<a href=\"http://en.wikipedia.org/wiki/NVidia\">NVidia</a> in 2008, targeted at the X\nWindow System on Unix-based operating systems, now open-source. Although\nit is also an open-source library, no manufacturer other than NVidia is\nusing it yet. Accessible to GStreamer through\nthe <a href=\"http://cgit.freedesktop.org/gstreamer/gst-plugins-bad/tree/sys/vdpau\">vdpau</a> element in plugins-bad.</p>\n</li>\n<li>\n<p><a href=\"http://en.wikipedia.org/wiki/OpenMAX\">OpenMAX</a> (<em>Open Media\nAcceleration</em>): Managed by the non-profit technology consortium <a href=\"http://en.wikipedia.org/wiki/Khronos_Group\" title=\"Khronos Group\">Khronos\nGroup</a>,\nit is a \"royalty-free, cross-platform set of C-language programming\ninterfaces that provides abstractions for routines especially useful for\naudio, video, and still images\". Accessible to GStreamer through\nthe <a href=\"http://git.freedesktop.org/gstreamer/gst-omx\">gst-omx</a> plugin.</p>\n</li>\n<li>\n<p><a href=\"http://developer.amd.com/sdks/AMDAPPSDK/assets/OpenVideo_Decode_API.PDF\">OVD</a>\n(<em>Open Video Decode</em>): Another API from <a href=\"http://en.wikipedia.org/wiki/AMD_Graphics\">AMD\nGraphics</a>, designed to be a\nplatform agnostic method for softrware developers to leverage the\n<a href=\"http://en.wikipedia.org/wiki/Unified_Video_Decoder\">Universal Video\nDecode</a> (UVD)\nhardware inside AMD Radeon graphics cards. Currently unavailable to\nGStreamer .</p>\n</li>\n<li>\n<p><a href=\"http://en.wikipedia.org/wiki/Distributed_Codec_Engine\">DCE</a>\n(<em>Distributed Codec Engine</em>): An open source software library (\"libdce\")\nand API specification by <a href=\"http://en.wikipedia.org/wiki/Texas_Instruments\">Texas\nInstruments</a>, targeted\nat Linux systems and ARM platforms. Accessible to GStreamer through\nthe <a href=\"https://github.com/robclark/gst-ducati\">gstreamer-ducati</a> plugin.</p>\n</li>\n<li>\n<p><a href=\"https://developer.android.com/reference/android/media/MediaCodec.html\">Android\nMediaCodec</a>: This is Android's API to access the device's\nhardware decoder and encoder if available. This is accessible through the\n<code>androidmedia</code> plugin in gst-plugins-bad. This includes both encoding and\ndecoding.</p>\n</li>\n<li>\n<p>Apple VideoTool Box Framework: Apple's API to access h is available\nthrough the <code>applemedia</code> plugin which includes both encoding through\nthe <code>vtenc</code> element and decoding through the <code>vtdec</code> element.</p>\n</li>\n<li>\n<p>Video4Linux: Recent Linux kernels have a kernel API to expose\nhardware codecs in a standard way, this is now supported by the\n<code>v4l2</code> plugin in <code>gst-plugins-good</code>. This can support both decoding\nand encoding depending on the platform.</p>\n</li>\n</ul>\n<h3 id=\"inner-workings-of-hardwareaccelerated-video-decoding-plugins\">Inner workings of hardware-accelerated video decoding plugins</h3>\n<p>These APIs generally offer a number of functionalities, like video\ndecoding, post-processing, or presentation of the decoded\nframes. Correspondingly, plugins generally offer a different GStreamer\nelement for each of these functions, so pipelines can be built to\naccommodate any need.</p>\n<p>For example, the <code>gstreamer-vaapi</code> plugin offers the <code>vaapidecode</code>,\n<code>vaapipostproc</code> and <code>vaapisink</code> elements that allow\nhardware-accelerated decoding through VAAPI, upload of raw video frames\nto GPU memory, download of GPU frames to system memory and presentation\nof GPU frames, respectively.</p>\n<p>It is important to distinguish between conventional GStreamer frames,\nwhich reside in system memory, and frames generated by\nhardware-accelerated APIs. The latter reside in GPU memory and cannot\nbe touched by GStreamer. They can usually be downloaded to system\nmemory and treated as conventional GStreamer frames when they are\nmapped, but it is far more efficient to leave them in the GPU and\ndisplay them from there.</p>\n<p>GStreamer needs to keep track of where these \u201chardware buffers\u201d are\nthough, so conventional buffers still travel from element to\nelement. They look like regular buffers, but mapping their content is\nmuch slower as it has to be retrieved from the special memory used by\nhardware accelerated elements. This special memory types are\nnegotiated using the allocation query mechanism.</p>\n<p>This all means that, if a particular hardware acceleration API is\npresent in the system, and the corresponding GStreamer plugin is also\navailable, auto-plugging elements like <code>playbin</code> are free to use\nhardware acceleration to build their pipelines; the application does not\nneed to do anything special to enable it. Almost:</p>\n<p>When <code>playbin</code> has to choose among different equally valid elements,\nlike conventional software decoding (through <code>vp8dec</code>, for example) or\nhardware accelerated decoding (through <code>vaapidecode</code>, for example), it\nuses their <em>rank</em> to decide. The rank is a property of each element that\nindicates its priority; <code>playbin</code> will simply select the element that\nis able to build a complete pipeline and has the highest rank.</p>\n<p>So, whether <code>playbin</code> will use hardware acceleration or not will depend\non the relative ranks of all elements capable of dealing with that media\ntype. Therefore, the easiest way to make sure hardware acceleration is\nenabled or disabled is by changing the rank of the associated element,\nas shown in this code:</p>\n<pre><code class=\"language-c\">static void enable_factory (const gchar *name, gboolean enable) {\n    GstRegistry *registry = NULL;\n    GstElementFactory *factory = NULL;\n\n    registry = gst_registry_get_default ();\n    if (!registry) return;\n\n    factory = gst_element_factory_find (name);\n    if (!factory) return;\n\n    if (enable) {\n        gst_plugin_feature_set_rank (GST_PLUGIN_FEATURE (factory), GST_RANK_PRIMARY + 1);\n    }\n    else {\n        gst_plugin_feature_set_rank (GST_PLUGIN_FEATURE (factory), GST_RANK_NONE);\n    }\n\n    gst_registry_add_feature (registry, GST_PLUGIN_FEATURE (factory));\n    return;\n}\n</code></pre>\n<p>The first parameter passed to this method is the name of the element to\nmodify, for example, <code>vaapidecode</code> or <code>fluvadec</code>.</p>\n<p>The key method is <code>gst_plugin_feature_set_rank()</code>, which will set the\nrank of the requested element factory to the desired level. For\nconvenience, ranks are divided in NONE, MARGINAL, SECONDARY and PRIMARY,\nbut any number will do. When enabling an element, we set it to\nPRIMARY+1, so it has a higher rank than the rest of elements which\ncommonly have PRIMARY rank. Setting an element\u2019s rank to NONE will make\nthe auto-plugging mechanism to never select it.</p>\n<blockquote>\n<p><img src=\"images/icons/emoticons/warning.png\" alt=\"warning\" id=\"warning\"> The GStreamer developers often rank hardware decoders lower than\nthe software ones when they are defective. This should act as a warning.</p>\n</blockquote>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>This tutorial has shown a bit how GStreamer internally manages hardware\naccelerated video decoding. Particularly,</p>\n<ul>\n<li>Applications do not need to do anything special to enable hardware\nacceleration if a suitable API and the corresponding GStreamer\nplugin are available.</li>\n<li>Hardware acceleration can be enabled or disabled by changing the\nrank of the decoding element with <code>gst_plugin_feature_set_rank()</code>.</li>\n</ul>\n<p>It has been a pleasure having you here, and see you soon!</p>\n\n        \n\n    </div>\n\n\n        "});