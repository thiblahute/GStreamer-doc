fragment_downloaded_cb({"url": "tutorials/android/media-player.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"media-player.md\">\n        <h1 id=\"android-tutorial-4-a-basic-media-player\">Android tutorial 4: A basic media player</h1>\n<h2 id=\"goal\">Goal</h2>\n<p><img src=\"images/tutorials/android-media-player-screenshot.png\" alt=\"screenshot\" id=\"screenshot\"></p>\n<p>Enough testing with synthetic images and audio tones! This tutorial\nfinally plays actual media, streamed directly from the Internet, in your\nAndroid device. It shows:</p>\n<ul>\n<li>How to keep the User Interface regularly updated with the current\nplayback position and duration</li>\n<li>How to implement a <a href=\"http://developer.android.com/reference/android/widget/SeekBar.html\">Seek\nBar</a></li>\n<li>How to report the media size to adapt the display surface</li>\n</ul>\n<p>It also uses the knowledge gathered in the <a href=\"../basic/index.html\">Basic tutorials</a> regarding:</p>\n<ul>\n<li>How to use <code>playbin</code> to play any kind of media</li>\n<li>How to handle network resilience problems</li>\n</ul>\n<h2 id=\"introduction\">Introduction</h2>\n<p>From the previous tutorials, we already have almost all necessary pieces\nto build a media player. The most complex part is assembling a pipeline\nwhich retrieves, decodes and displays the media, but we already know\nthat the <code>playbin</code> element can take care of all that for us. We only\nneed to replace the manual pipeline we used in\n<a href=\"video.html\">Android tutorial 3: Video</a> with a single-element\n<code>playbin</code> pipeline and we are good to go!</p>\n<p>However, we can do better than. We will add a <a href=\"http://developer.android.com/reference/android/widget/SeekBar.html\">Seek\nBar</a>,\nwith a moving thumb that will advance as our current position in the\nmedia advances. We will also allow the user to drag the thumb, to jump\n(or <em>seek</em>) to a different position.</p>\n<p>And finally, we will make the video surface adapt to the media size, so\nthe video sink is not forced to draw black borders around the clip.\nThis also allows the Android layout to adapt more nicely to the actual\nmedia content. You can still force the video surface to have a specific\nsize if you really want to.</p>\n<h2 id=\"a-basic-media-player-java-code\">A basic media player [Java code]</h2>\n<p><strong>src/com/gst_sdk_tutorials/tutorial_4/Tutorial4.java</strong></p>\n<pre><code class=\"language-java\">package com.gst_sdk_tutorials.tutorial_4;\n\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\nimport java.util.TimeZone;\n\nimport android.app.Activity;\nimport android.os.Bundle;\nimport android.util.Log;\nimport android.view.SurfaceHolder;\nimport android.view.SurfaceView;\nimport android.view.View;\nimport android.view.View.OnClickListener;\nimport android.widget.ImageButton;\nimport android.widget.SeekBar;\nimport android.widget.SeekBar.OnSeekBarChangeListener;\nimport android.widget.TextView;\nimport android.widget.Toast;\n\nimport org.freedesktop.gstreamer.GStreamer;\n\npublic class Tutorial4 extends Activity implements SurfaceHolder.Callback, OnSeekBarChangeListener {\n    private native void nativeInit();     // Initialize native code, build pipeline, etc\n    private native void nativeFinalize(); // Destroy pipeline and shutdown native code\n    private native void nativeSetUri(String uri); // Set the URI of the media to play\n    private native void nativePlay();     // Set pipeline to PLAYING\n    private native void nativeSetPosition(int milliseconds); // Seek to the indicated position, in milliseconds\n    private native void nativePause();    // Set pipeline to PAUSED\n    private static native boolean nativeClassInit(); // Initialize native class: cache Method IDs for callbacks\n    private native void nativeSurfaceInit(Object surface); // A new surface is available\n    private native void nativeSurfaceFinalize(); // Surface about to be destroyed\n    private long native_custom_data;      // Native code will use this to keep private data\n\n    private boolean is_playing_desired;   // Whether the user asked to go to PLAYING\n    private int position;                 // Current position, reported by native code\n    private int duration;                 // Current clip duration, reported by native code\n    private boolean is_local_media;       // Whether this clip is stored locally or is being streamed\n    private int desired_position;         // Position where the users wants to seek to\n    private String mediaUri;              // URI of the clip being played\n\n    private final String defaultMediaUri = \"https://www.freedesktop.org/software/gstreamer-sdk/data/media/sintel_trailer-368p.ogv\";\n\n    // Called when the activity is first created.\n    @Override\n    public void onCreate(Bundle savedInstanceState)\n    {\n        super.onCreate(savedInstanceState);\n\n        // Initialize GStreamer and warn if it fails\n        try {\n            GStreamer.init(this);\n        } catch (Exception e) {\n            Toast.makeText(this, e.getMessage(), Toast.LENGTH_LONG).show();\n            finish();\n            return;\n        }\n\n        setContentView(R.layout.main);\n\n        ImageButton play = (ImageButton) this.findViewById(R.id.button_play);\n        play.setOnClickListener(new OnClickListener() {\n            public void onClick(View v) {\n                is_playing_desired = true;\n                nativePlay();\n            }\n        });\n\n        ImageButton pause = (ImageButton) this.findViewById(R.id.button_stop);\n        pause.setOnClickListener(new OnClickListener() {\n            public void onClick(View v) {\n                is_playing_desired = false;\n                nativePause();\n            }\n        });\n\n        SurfaceView sv = (SurfaceView) this.findViewById(R.id.surface_video);\n        SurfaceHolder sh = sv.getHolder();\n        sh.addCallback(this);\n\n        SeekBar sb = (SeekBar) this.findViewById(R.id.seek_bar);\n        sb.setOnSeekBarChangeListener(this);\n\n        // Retrieve our previous state, or initialize it to default values\n        if (savedInstanceState != null) {\n            is_playing_desired = savedInstanceState.getBoolean(\"playing\");\n            position = savedInstanceState.getInt(\"position\");\n            duration = savedInstanceState.getInt(\"duration\");\n            mediaUri = savedInstanceState.getString(\"mediaUri\");\n            Log.i (\"GStreamer\", \"Activity created with saved state:\");\n        } else {\n            is_playing_desired = false;\n            position = duration = 0;\n            mediaUri = defaultMediaUri;\n            Log.i (\"GStreamer\", \"Activity created with no saved state:\");\n        }\n        is_local_media = false;\n        Log.i (\"GStreamer\", \"  playing:\" + is_playing_desired + \" position:\" + position +\n                \" duration: \" + duration + \" uri: \" + mediaUri);\n\n        // Start with disabled buttons, until native code is initialized\n        this.findViewById(R.id.button_play).setEnabled(false);\n        this.findViewById(R.id.button_stop).setEnabled(false);\n\n        nativeInit();\n    }\n\n    protected void onSaveInstanceState (Bundle outState) {\n        Log.d (\"GStreamer\", \"Saving state, playing:\" + is_playing_desired + \" position:\" + position +\n                \" duration: \" + duration + \" uri: \" + mediaUri);\n        outState.putBoolean(\"playing\", is_playing_desired);\n        outState.putInt(\"position\", position);\n        outState.putInt(\"duration\", duration);\n        outState.putString(\"mediaUri\", mediaUri);\n    }\n\n    protected void onDestroy() {\n        nativeFinalize();\n        super.onDestroy();\n    }\n\n    // Called from native code. This sets the content of the TextView from the UI thread.\n    private void setMessage(final String message) {\n        final TextView tv = (TextView) this.findViewById(R.id.textview_message);\n        runOnUiThread (new Runnable() {\n          public void run() {\n            tv.setText(message);\n          }\n        });\n    }\n\n    // Set the URI to play, and record whether it is a local or remote file\n    private void setMediaUri() {\n        nativeSetUri (mediaUri);\n        is_local_media = mediaUri.startsWith(\"file://\");\n    }\n\n    // Called from native code. Native code calls this once it has created its pipeline and\n    // the main loop is running, so it is ready to accept commands.\n    private void onGStreamerInitialized () {\n        Log.i (\"GStreamer\", \"GStreamer initialized:\");\n        Log.i (\"GStreamer\", \"  playing:\" + is_playing_desired + \" position:\" + position + \" uri: \" + mediaUri);\n\n        // Restore previous playing state\n        setMediaUri ();\n        nativeSetPosition (position);\n        if (is_playing_desired) {\n            nativePlay();\n        } else {\n            nativePause();\n        }\n\n        // Re-enable buttons, now that GStreamer is initialized\n        final Activity activity = this;\n        runOnUiThread(new Runnable() {\n            public void run() {\n                activity.findViewById(R.id.button_play).setEnabled(true);\n                activity.findViewById(R.id.button_stop).setEnabled(true);\n            }\n        });\n    }\n\n    // The text widget acts as an slave for the seek bar, so it reflects what the seek bar shows, whether\n    // it is an actual pipeline position or the position the user is currently dragging to.\n    private void updateTimeWidget () {\n        final TextView tv = (TextView) this.findViewById(R.id.textview_time);\n        final SeekBar sb = (SeekBar) this.findViewById(R.id.seek_bar);\n        final int pos = sb.getProgress();\n\n        SimpleDateFormat df = new SimpleDateFormat(\"HH:mm:ss\");\n        df.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n        final String message = df.format(new Date (pos)) + \" / \" + df.format(new Date (duration));\n        tv.setText(message);\n    }\n\n    // Called from native code\n    private void setCurrentPosition(final int position, final int duration) {\n        final SeekBar sb = (SeekBar) this.findViewById(R.id.seek_bar);\n\n        // Ignore position messages from the pipeline if the seek bar is being dragged\n        if (sb.isPressed()) return;\n\n        runOnUiThread (new Runnable() {\n          public void run() {\n            sb.setMax(duration);\n            sb.setProgress(position);\n            updateTimeWidget();\n          }\n        });\n        this.position = position;\n        this.duration = duration;\n    }\n\n    static {\n        System.loadLibrary(\"gstreamer_android\");\n        System.loadLibrary(\"tutorial-4\");\n        nativeClassInit();\n    }\n\n    public void surfaceChanged(SurfaceHolder holder, int format, int width,\n            int height) {\n        Log.d(\"GStreamer\", \"Surface changed to format \" + format + \" width \"\n                + width + \" height \" + height);\n        nativeSurfaceInit (holder.getSurface());\n    }\n\n    public void surfaceCreated(SurfaceHolder holder) {\n        Log.d(\"GStreamer\", \"Surface created: \" + holder.getSurface());\n    }\n\n    public void surfaceDestroyed(SurfaceHolder holder) {\n        Log.d(\"GStreamer\", \"Surface destroyed\");\n        nativeSurfaceFinalize ();\n    }\n\n    // Called from native code when the size of the media changes or is first detected.\n    // Inform the video surface about the new size and recalculate the layout.\n    private void onMediaSizeChanged (int width, int height) {\n        Log.i (\"GStreamer\", \"Media size changed to \" + width + \"x\" + height);\n        final GStreamerSurfaceView gsv = (GStreamerSurfaceView) this.findViewById(R.id.surface_video);\n        gsv.media_width = width;\n        gsv.media_height = height;\n        runOnUiThread(new Runnable() {\n            public void run() {\n                gsv.requestLayout();\n            }\n        });\n    }\n\n    // The Seek Bar thumb has moved, either because the user dragged it or we have called setProgress()\n    public void onProgressChanged(SeekBar sb, int progress, boolean fromUser) {\n        if (fromUser == false) return;\n        desired_position = progress;\n        // If this is a local file, allow scrub seeking, this is, seek as soon as the slider is moved.\n        if (is_local_media) nativeSetPosition(desired_position);\n        updateTimeWidget();\n    }\n\n    // The user started dragging the Seek Bar thumb\n    public void onStartTrackingTouch(SeekBar sb) {\n        nativePause();\n    }\n\n    // The user released the Seek Bar thumb\n    public void onStopTrackingTouch(SeekBar sb) {\n        // If this is a remote file, scrub seeking is probably not going to work smoothly enough.\n        // Therefore, perform only the seek when the slider is released.\n        if (!is_local_media) nativeSetPosition(desired_position);\n        if (is_playing_desired) nativePlay();\n    }\n}\n</code></pre>\n<h3 id=\"supporting-arbitrary-media-uris\">Supporting arbitrary media URIs</h3>\n<p>The C code provides the <code>nativeSetUri()</code> method so we can indicate the\nURI of the media to play. Since <code>playbin</code> will be taking care of\nretrieving the media, we can use local or remote URIs indistinctly\n(<code>file://</code> or <code>http://</code>, for example). From Java, though, we want to\nkeep track of whether the file is local or remote, because we will not\noffer the same functionalities. We keep track of this in the\n<code>is_local_media</code> variable, and update it every time we change the media\nURI:</p>\n<pre><code class=\"language-java\">private void setMediaUri() {\n    nativeSetUri (mediaUri);\n    is_local_media = mediaUri.startsWith(\"file://\");\n}\n</code></pre>\n<p>We call <code>setMediaUri()</code> in the <code>onGStreamerInitialized()</code> callback, once\nthe pipeline is ready to accept commands.</p>\n<h3 id=\"reporting-media-size\">Reporting media size</h3>\n<p>Every time the size of the media changes (which could happen mid-stream,\nfor some kind of streams), or when it is first detected, C code calls\nour <code>onMediaSizeChanged()</code> callback:</p>\n<pre><code class=\"language-java\">private void onMediaSizeChanged (int width, int height) {\n    Log.i (\"GStreamer\", \"Media size changed to \" + width + \"x\" + height);\n    final GStreamerSurfaceView gsv = (GStreamerSurfaceView) this.findViewById(R.id.surface_video);\n    gsv.media_width = width;\n    gsv.media_height = height;\n    runOnUiThread(new Runnable() {\n        public void run() {\n            gsv.requestLayout();\n        }\n    });\n}\n</code></pre>\n<p>Here we simply pass the new size onto the <code>GStreamerSurfaceView</code> in\ncharge of displaying the media, and ask the Android layout to be\nrecalculated. Eventually, the <code>onMeasure()</code> method in\nGStreamerSurfaceView will be called and the new size will be taken\ninto account. As we have already seen in\n<a href=\"a-running-pipeline.html\">Android tutorial 2: A running pipeline</a>, methods which change\nthe UI must be called from the main thread, and we are now in a\ncallback from some GStreamer internal thread. Hence, the usage of\n<a href=\"http://developer.android.com/reference/android/app/Activity.html#runOnUiThread(java.lang.Runnable)\">runOnUiThread()</a>.</p>\n<h3 id=\"refreshing-the-seek-bar\">Refreshing the Seek Bar</h3>\n<p><a href=\"../basic/toolkit-integration.html\">Basic tutorial 5: GUI toolkit integration</a>\nhas already shown how to implement a <a href=\"http://developer.android.com/reference/android/widget/SeekBar.html\">Seek\nBar</a> using\nthe GTK+ toolkit. The implementation on Android is very similar.</p>\n<p>The Seek Bar accomplishes to functions: First, it moves on its own to\nreflect the current playback position in the media. Second, it can be\ndragged by the user to seek to a different position.</p>\n<p>To realize the first function, C code will periodically call our\n<code>setCurrentPosition()</code> method so we can update the position of the thumb\nin the Seek Bar. Again we do so from the UI thread, using\n<code>RunOnUiThread()</code>.</p>\n<pre><code class=\"language-java\">private void setCurrentPosition(final int position, final int duration) {\n    final SeekBar sb = (SeekBar) this.findViewById(R.id.seek_bar);\n\n    // Ignore position messages from the pipeline if the seek bar is being dragged\n    if (sb.isPressed()) return;\n\n    runOnUiThread (new Runnable() {\n      public void run() {\n        sb.setMax(duration);\n        sb.setProgress(position);\n        updateTimeWidget();\n      }\n    });\n    this.position = position;\n    this.duration = duration;\n}\n</code></pre>\n<p>To the left of the Seek Bar (refer to the screenshot at the top of this\npage), there is a\n<a href=\"http://developer.android.com/reference/android/widget/TextView.html\">TextView</a>\nwidget which we will use to display the current position and duration in\n<code>HH:mm:ss / HH:mm:ss</code> textual format. The <code>updateTimeWidget()</code> method\ntakes care of it, and must be called every time the Seek Bar is updated:</p>\n<pre><code class=\"language-java\">private void updateTimeWidget () {\n    final TextView tv = (TextView) this.findViewById(R.id.textview_time);\n    final SeekBar sb = (SeekBar) this.findViewById(R.id.seek_bar);\n    final int pos = sb.getProgress();\n\n    SimpleDateFormat df = new SimpleDateFormat(\"HH:mm:ss\");\n    df.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n    final String message = df.format(new Date (pos)) + \" / \" + df.format(new Date (duration));\n    tv.setText(message);\n}\n</code></pre>\n<h3 id=\"seeking-with-the-seek-bar\">Seeking with the Seek Bar</h3>\n<p>To perform the second function of the <a href=\"http://developer.android.com/reference/android/widget/SeekBar.html\">Seek\nBar</a> (allowing\nthe user to seek by dragging the thumb), we implement the\n<a href=\"http://developer.android.com/reference/android/widget/SeekBar.OnSeekBarChangeListener.html\">OnSeekBarChangeListener</a>\ninterface in the\nActivity:</p>\n<pre><code class=\"language-java\">public class Tutorial4 extends Activity implements SurfaceHolder.Callback, OnSeekBarChangeListener {\n</code></pre>\n<p>And we register the Activity as the listener for the <a href=\"http://developer.android.com/reference/android/widget/SeekBar.html\">Seek\nBar</a>\u2019s\nevents in the <code>onCreate()</code> method:</p>\n<pre><code class=\"language-java\">SeekBar sb = (SeekBar) this.findViewById(R.id.seek_bar);\nsb.setOnSeekBarChangeListener(this);\n</code></pre>\n<p>We will now be notified of three events: When the user starts dragging\nthe thumb, every time the thumb moves and when the thumb is released by\nthe user:</p>\n<pre><code class=\"language-java\">public void onStartTrackingTouch(SeekBar sb) {\n    nativePause();\n}\n</code></pre>\n<p><a href=\"http://developer.android.com/reference/android/widget/SeekBar.OnSeekBarChangeListener.html#onStartTrackingTouch(android.widget.SeekBar)\">onStartTrackingTouch()</a>\nis called when the user starts dragging, and the only thing we do is\npause the pipeline. If the user is searching for a particular scene, we\ndo not want it to keep\nmoving.</p>\n<pre><code class=\"language-java\">public void onProgressChanged(SeekBar sb, int progress, boolean fromUser) {\n    if (fromUser == false) return;\n    desired_position = progress;\n    // If this is a local file, allow scrub seeking, this is, seek soon as the slider is moved.\n    if (is_local_media) nativeSetPosition(desired_position);\n    updateTimeWidget();\n}\n</code></pre>\n<p><a href=\"http://developer.android.com/reference/android/widget/SeekBar.OnSeekBarChangeListener.html#onProgressChanged(android.widget.SeekBar,%20int,%20boolean)\">onProgressChanged()</a> is\ncalled every time the thumb moves, be it because the user dragged it, or\nbecause we called <code>setProgress()</code> on the Seek Bar. We discard the latter\ncase with the handy <code>fromUser</code> parameter.</p>\n<p>As the comment says, if this is a local media, we allow scrub seeking,\nthis is, we jump to the indicated position as soon as the thumb moves.\nOtherwise, the seek will be performed when the thumb is released, and\nthe only thing we do here is update the textual time widget.</p>\n<pre><code class=\"language-java\">public void onStopTrackingTouch(SeekBar sb) {\n    // If this is a remote file, scrub seeking is probably not going to work smoothly enough.\n    // Therefore, perform only the seek when the slider is released.\n    if (!is_local_media) nativeSetPosition(desired_position);\n    if (is_playing_desired) nativePlay();\n}\n</code></pre>\n<p>Finally, <a href=\"http://developer.android.com/reference/android/widget/SeekBar.OnSeekBarChangeListener.html#onStopTrackingTouch(android.widget.SeekBar)\">onStopTrackingTouch()</a>\nis called when the thumb is released. We simply perform the seek\noperation if the file was non-local, and restore the pipeline to the\ndesired playing state.</p>\n<p>This concludes the User interface part of this tutorial. Let\u2019s review\nnow the under-the-hood C code that allows this to work.</p>\n<h2 id=\"a-basic-media-player-c-code\">A basic media player [C code]</h2>\n<p><strong>jni/tutorial-4.c</strong></p>\n<pre><code class=\"language-c\">#include &lt;string.h&gt;\n#include &lt;jni.h&gt;\n#include &lt;android/log.h&gt;\n#include &lt;android/native_window.h&gt;\n#include &lt;android/native_window_jni.h&gt;\n#include &lt;gst/gst.h&gt;\n#include &lt;gst/interfaces/xoverlay.h&gt;\n#include &lt;gst/video/video.h&gt;\n#include &lt;pthread.h&gt;\n\nGST_DEBUG_CATEGORY_STATIC (debug_category);\n#define GST_CAT_DEFAULT debug_category\n\n/*\n * These macros provide a way to store the native pointer to CustomData, which might be 32 or 64 bits, into\n * a jlong, which is always 64 bits, without warnings.\n */\n#if GLIB_SIZEOF_VOID_P == 8\n## define GET_CUSTOM_DATA(env, thiz, fieldID) (CustomData *)(*env)-&gt;GetLongField (env, thiz, fieldID)\n## define SET_CUSTOM_DATA(env, thiz, fieldID, data) (*env)-&gt;SetLongField (env, thiz, fieldID, (jlong)data)\n#else\n## define GET_CUSTOM_DATA(env, thiz, fieldID) (CustomData *)(jint)(*env)-&gt;GetLongField (env, thiz, fieldID)\n## define SET_CUSTOM_DATA(env, thiz, fieldID, data) (*env)-&gt;SetLongField (env, thiz, fieldID, (jlong)(jint)data)\n#endif\n\n/* Do not allow seeks to be performed closer than this distance. It is visually useless, and will probably\n * confuse some demuxers. */\n#define SEEK_MIN_DELAY (500 * GST_MSECOND)\n\n/* Structure to contain all our information, so we can pass it to callbacks */\ntypedef struct _CustomData {\n  jobject app;                  /* Application instance, used to call its methods. A global reference is kept. */\n  GstElement *pipeline;         /* The running pipeline */\n  GMainContext *context;        /* GLib context used to run the main loop */\n  GMainLoop *main_loop;         /* GLib main loop */\n  gboolean initialized;         /* To avoid informing the UI multiple times about the initialization */\n  ANativeWindow *native_window; /* The Android native window where video will be rendered */\n  GstState state;               /* Current pipeline state */\n  GstState target_state;        /* Desired pipeline state, to be set once buffering is complete */\n  gint64 duration;              /* Cached clip duration */\n  gint64 desired_position;      /* Position to seek to, once the pipeline is running */\n  GstClockTime last_seek_time;  /* For seeking overflow prevention (throttling) */\n  gboolean is_live;             /* Live streams do not use buffering */\n} CustomData;\n\n/* playbin flags */\ntypedef enum {\n  GST_PLAY_FLAG_TEXT = (1 &lt;&lt; 2)  /* We want subtitle output */\n} GstPlayFlags;\n\n/* These global variables cache values which are not changing during execution */\nstatic pthread_t gst_app_thread;\nstatic pthread_key_t current_jni_env;\nstatic JavaVM *java_vm;\nstatic jfieldID custom_data_field_id;\nstatic jmethodID set_message_method_id;\nstatic jmethodID set_current_position_method_id;\nstatic jmethodID on_gstreamer_initialized_method_id;\nstatic jmethodID on_media_size_changed_method_id;\n\n/*\n * Private methods\n */\n\n/* Register this thread with the VM */\nstatic JNIEnv *attach_current_thread (void) {\n  JNIEnv *env;\n  JavaVMAttachArgs args;\n\n  GST_DEBUG (\"Attaching thread %p\", g_thread_self ());\n  args.version = JNI_VERSION_1_4;\n  args.name = NULL;\n  args.group = NULL;\n\n  if ((*java_vm)-&gt;AttachCurrentThread (java_vm, &amp;env, &amp;args) &lt; 0) {\n    GST_ERROR (\"Failed to attach current thread\");\n    return NULL;\n  }\n\n  return env;\n}\n\n/* Unregister this thread from the VM */\nstatic void detach_current_thread (void *env) {\n  GST_DEBUG (\"Detaching thread %p\", g_thread_self ());\n  (*java_vm)-&gt;DetachCurrentThread (java_vm);\n}\n\n/* Retrieve the JNI environment for this thread */\nstatic JNIEnv *get_jni_env (void) {\n  JNIEnv *env;\n\n  if ((env = pthread_getspecific (current_jni_env)) == NULL) {\n    env = attach_current_thread ();\n    pthread_setspecific (current_jni_env, env);\n  }\n\n  return env;\n}\n\n/* Change the content of the UI's TextView */\nstatic void set_ui_message (const gchar *message, CustomData *data) {\n  JNIEnv *env = get_jni_env ();\n  GST_DEBUG (\"Setting message to: %s\", message);\n  jstring jmessage = (*env)-&gt;NewStringUTF(env, message);\n  (*env)-&gt;CallVoidMethod (env, data-&gt;app, set_message_method_id, jmessage);\n  if ((*env)-&gt;ExceptionCheck (env)) {\n    GST_ERROR (\"Failed to call Java method\");\n    (*env)-&gt;ExceptionClear (env);\n  }\n  (*env)-&gt;DeleteLocalRef (env, jmessage);\n}\n\n/* Tell the application what is the current position and clip duration */\nstatic void set_current_ui_position (gint position, gint duration, CustomData *data) {\n  JNIEnv *env = get_jni_env ();\n  (*env)-&gt;CallVoidMethod (env, data-&gt;app, set_current_position_method_id, position, duration);\n  if ((*env)-&gt;ExceptionCheck (env)) {\n    GST_ERROR (\"Failed to call Java method\");\n    (*env)-&gt;ExceptionClear (env);\n  }\n}\n\n/* If we have pipeline and it is running, query the current position and clip duration and inform\n * the application */\nstatic gboolean refresh_ui (CustomData *data) {\n  GstFormat fmt = GST_FORMAT_TIME;\n  gint64 current = -1;\n  gint64 position;\n\n  /* We do not want to update anything unless we have a working pipeline in the PAUSED or PLAYING state */\n  if (!data || !data-&gt;pipeline || data-&gt;state &lt; GST_STATE_PAUSED)\n    return TRUE;\n\n  /* If we didn't know it yet, query the stream duration */\n  if (!GST_CLOCK_TIME_IS_VALID (data-&gt;duration)) {\n    if (!gst_element_query_duration (data-&gt;pipeline, &amp;fmt, &amp;data-&gt;duration)) {\n      GST_WARNING (\"Could not query current duration\");\n    }\n  }\n\n  if (gst_element_query_position (data-&gt;pipeline, &amp;fmt, &amp;position)) {\n    /* Java expects these values in milliseconds, and GStreamer provides nanoseconds */\n    set_current_ui_position (position / GST_MSECOND, data-&gt;duration / GST_MSECOND, data);\n  }\n  return TRUE;\n}\n\n/* Forward declaration for the delayed seek callback */\nstatic gboolean delayed_seek_cb (CustomData *data);\n\n/* Perform seek, if we are not too close to the previous seek. Otherwise, schedule the seek for\n * some time in the future. */\nstatic void execute_seek (gint64 desired_position, CustomData *data) {\n  gint64 diff;\n\n  if (desired_position == GST_CLOCK_TIME_NONE)\n    return;\n\n  diff = gst_util_get_timestamp () - data-&gt;last_seek_time;\n\n  if (GST_CLOCK_TIME_IS_VALID (data-&gt;last_seek_time) &amp;&amp; diff &lt; SEEK_MIN_DELAY) {\n    /* The previous seek was too close, delay this one */\n    GSource *timeout_source;\n\n    if (data-&gt;desired_position == GST_CLOCK_TIME_NONE) {\n      /* There was no previous seek scheduled. Setup a timer for some time in the future */\n      timeout_source = g_timeout_source_new ((SEEK_MIN_DELAY - diff) / GST_MSECOND);\n      g_source_set_callback (timeout_source, (GSourceFunc)delayed_seek_cb, data, NULL);\n      g_source_attach (timeout_source, data-&gt;context);\n      g_source_unref (timeout_source);\n    }\n    /* Update the desired seek position. If multiple requests are received before it is time\n     * to perform a seek, only the last one is remembered. */\n    data-&gt;desired_position = desired_position;\n    GST_DEBUG (\"Throttling seek to %\" GST_TIME_FORMAT \", will be in %\" GST_TIME_FORMAT,\n        GST_TIME_ARGS (desired_position), GST_TIME_ARGS (SEEK_MIN_DELAY - diff));\n  } else {\n    /* Perform the seek now */\n    GST_DEBUG (\"Seeking to %\" GST_TIME_FORMAT, GST_TIME_ARGS (desired_position));\n    data-&gt;last_seek_time = gst_util_get_timestamp ();\n    gst_element_seek_simple (data-&gt;pipeline, GST_FORMAT_TIME, GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_KEY_UNIT, desired_position);\n    data-&gt;desired_position = GST_CLOCK_TIME_NONE;\n  }\n}\n\n/* Delayed seek callback. This gets called by the timer setup in the above function. */\nstatic gboolean delayed_seek_cb (CustomData *data) {\n  GST_DEBUG (\"Doing delayed seek to %\" GST_TIME_FORMAT, GST_TIME_ARGS (data-&gt;desired_position));\n  execute_seek (data-&gt;desired_position, data);\n  return FALSE;\n}\n\n/* Retrieve errors from the bus and show them on the UI */\nstatic void error_cb (GstBus *bus, GstMessage *msg, CustomData *data) {\n  GError *err;\n  gchar *debug_info;\n  gchar *message_string;\n\n  gst_message_parse_error (msg, &amp;err, &amp;debug_info);\n  message_string = g_strdup_printf (\"Error received from element %s: %s\", GST_OBJECT_NAME (msg-&gt;src), err-&gt;message);\n  g_clear_error (&amp;err);\n  g_free (debug_info);\n  set_ui_message (message_string, data);\n  g_free (message_string);\n  data-&gt;target_state = GST_STATE_NULL;\n  gst_element_set_state (data-&gt;pipeline, GST_STATE_NULL);\n}\n\n/* Called when the End Of the Stream is reached. Just move to the beginning of the media and pause. */\nstatic void eos_cb (GstBus *bus, GstMessage *msg, CustomData *data) {\n  data-&gt;target_state = GST_STATE_PAUSED;\n  data-&gt;is_live = (gst_element_set_state (data-&gt;pipeline, GST_STATE_PAUSED) == GST_STATE_CHANGE_NO_PREROLL);\n  execute_seek (0, data);\n}\n\n/* Called when the duration of the media changes. Just mark it as unknown, so we re-query it in the next UI refresh. */\nstatic void duration_cb (GstBus *bus, GstMessage *msg, CustomData *data) {\n  data-&gt;duration = GST_CLOCK_TIME_NONE;\n}\n\n/* Called when buffering messages are received. We inform the UI about the current buffering level and\n * keep the pipeline paused until 100% buffering is reached. At that point, set the desired state. */\nstatic void buffering_cb (GstBus *bus, GstMessage *msg, CustomData *data) {\n  gint percent;\n\n  if (data-&gt;is_live)\n    return;\n\n  gst_message_parse_buffering (msg, &amp;percent);\n  if (percent &lt; 100 &amp;&amp; data-&gt;target_state &gt;= GST_STATE_PAUSED) {\n    gchar * message_string = g_strdup_printf (\"Buffering %d%%\", percent);\n    gst_element_set_state (data-&gt;pipeline, GST_STATE_PAUSED);\n    set_ui_message (message_string, data);\n    g_free (message_string);\n  } else if (data-&gt;target_state &gt;= GST_STATE_PLAYING) {\n    gst_element_set_state (data-&gt;pipeline, GST_STATE_PLAYING);\n  } else if (data-&gt;target_state &gt;= GST_STATE_PAUSED) {\n    set_ui_message (\"Buffering complete\", data);\n  }\n}\n\n/* Called when the clock is lost */\nstatic void clock_lost_cb (GstBus *bus, GstMessage *msg, CustomData *data) {\n  if (data-&gt;target_state &gt;= GST_STATE_PLAYING) {\n    gst_element_set_state (data-&gt;pipeline, GST_STATE_PAUSED);\n    gst_element_set_state (data-&gt;pipeline, GST_STATE_PLAYING);\n  }\n}\n\n/* Retrieve the video sink's Caps and tell the application about the media size */\nstatic void check_media_size (CustomData *data) {\n  JNIEnv *env = get_jni_env ();\n  GstElement *video_sink;\n  GstPad *video_sink_pad;\n  GstCaps *caps;\n  GstVideoFormat fmt;\n  int width;\n  int height;\n\n  /* Retrieve the Caps at the entrance of the video sink */\n  g_object_get (data-&gt;pipeline, \"video-sink\", &amp;video_sink, NULL);\n  video_sink_pad = gst_element_get_static_pad (video_sink, \"sink\");\n  caps = gst_pad_get_negotiated_caps (video_sink_pad);\n\n  if (gst_video_format_parse_caps(caps, &amp;fmt, &amp;width, &amp;height)) {\n    int par_n, par_d;\n    if (gst_video_parse_caps_pixel_aspect_ratio (caps, &amp;par_n, &amp;par_d)) {\n      width = width * par_n / par_d;\n    }\n    GST_DEBUG (\"Media size is %dx%d, notifying application\", width, height);\n\n    (*env)-&gt;CallVoidMethod (env, data-&gt;app, on_media_size_changed_method_id, (jint)width, (jint)height);\n    if ((*env)-&gt;ExceptionCheck (env)) {\n      GST_ERROR (\"Failed to call Java method\");\n      (*env)-&gt;ExceptionClear (env);\n    }\n  }\n\n  gst_caps_unref(caps);\n  gst_object_unref (video_sink_pad);\n  gst_object_unref(video_sink);\n}\n\n/* Notify UI about pipeline state changes */\nstatic void state_changed_cb (GstBus *bus, GstMessage *msg, CustomData *data) {\n  GstState old_state, new_state, pending_state;\n  gst_message_parse_state_changed (msg, &amp;old_state, &amp;new_state, &amp;pending_state);\n  /* Only pay attention to messages coming from the pipeline, not its children */\n  if (GST_MESSAGE_SRC (msg) == GST_OBJECT (data-&gt;pipeline)) {\n    data-&gt;state = new_state;\n    gchar *message = g_strdup_printf(\"State changed to %s\", gst_element_state_get_name(new_state));\n    set_ui_message(message, data);\n    g_free (message);\n\n    /* The Ready to Paused state change is particularly interesting: */\n    if (old_state == GST_STATE_READY &amp;&amp; new_state == GST_STATE_PAUSED) {\n      /* By now the sink already knows the media size */\n      check_media_size(data);\n\n      /* If there was a scheduled seek, perform it now that we have moved to the Paused state */\n      if (GST_CLOCK_TIME_IS_VALID (data-&gt;desired_position))\n        execute_seek (data-&gt;desired_position, data);\n    }\n  }\n}\n\n/* Check if all conditions are met to report GStreamer as initialized.\n * These conditions will change depending on the application */\nstatic void check_initialization_complete (CustomData *data) {\n  JNIEnv *env = get_jni_env ();\n  if (!data-&gt;initialized &amp;&amp; data-&gt;native_window &amp;&amp; data-&gt;main_loop) {\n    GST_DEBUG (\"Initialization complete, notifying application. native_window:%p main_loop:%p\", data-&gt;native_window, data-&gt;main_loop);\n\n    /* The main loop is running and we received a native window, inform the sink about it */\n    gst_x_overlay_set_window_handle (GST_X_OVERLAY (data-&gt;pipeline), (guintptr)data-&gt;native_window);\n\n    (*env)-&gt;CallVoidMethod (env, data-&gt;app, on_gstreamer_initialized_method_id);\n    if ((*env)-&gt;ExceptionCheck (env)) {\n      GST_ERROR (\"Failed to call Java method\");\n      (*env)-&gt;ExceptionClear (env);\n    }\n    data-&gt;initialized = TRUE;\n  }\n}\n\n/* Main method for the native code. This is executed on its own thread. */\nstatic void *app_function (void *userdata) {\n  JavaVMAttachArgs args;\n  GstBus *bus;\n  CustomData *data = (CustomData *)userdata;\n  GSource *timeout_source;\n  GSource *bus_source;\n  GError *error = NULL;\n  guint flags;\n\n  GST_DEBUG (\"Creating pipeline in CustomData at %p\", data);\n\n  /* Create our own GLib Main Context and make it the default one */\n  data-&gt;context = g_main_context_new ();\n  g_main_context_push_thread_default(data-&gt;context);\n\n  /* Build pipeline */\n  data-&gt;pipeline = gst_parse_launch(\"playbin\", &amp;error);\n  if (error) {\n    gchar *message = g_strdup_printf(\"Unable to build pipeline: %s\", error-&gt;message);\n    g_clear_error (&amp;error);\n    set_ui_message(message, data);\n    g_free (message);\n    return NULL;\n  }\n\n  /* Disable subtitles */\n  g_object_get (data-&gt;pipeline, \"flags\", &amp;flags, NULL);\n  flags &amp;= ~GST_PLAY_FLAG_TEXT;\n  g_object_set (data-&gt;pipeline, \"flags\", flags, NULL);\n\n  /* Set the pipeline to READY, so it can already accept a window handle, if we have one */\n  data-&gt;target_state = GST_STATE_READY;\n  gst_element_set_state(data-&gt;pipeline, GST_STATE_READY);\n\n  /* Instruct the bus to emit signals for each received message, and connect to the interesting signals */\n  bus = gst_element_get_bus (data-&gt;pipeline);\n  bus_source = gst_bus_create_watch (bus);\n  g_source_set_callback (bus_source, (GSourceFunc) gst_bus_async_signal_func, NULL, NULL);\n  g_source_attach (bus_source, data-&gt;context);\n  g_source_unref (bus_source);\n  g_signal_connect (G_OBJECT (bus), \"message::error\", (GCallback)error_cb, data);\n  g_signal_connect (G_OBJECT (bus), \"message::eos\", (GCallback)eos_cb, data);\n  g_signal_connect (G_OBJECT (bus), \"message::state-changed\", (GCallback)state_changed_cb, data);\n  g_signal_connect (G_OBJECT (bus), \"message::duration\", (GCallback)duration_cb, data);\n  g_signal_connect (G_OBJECT (bus), \"message::buffering\", (GCallback)buffering_cb, data);\n  g_signal_connect (G_OBJECT (bus), \"message::clock-lost\", (GCallback)clock_lost_cb, data);\n  gst_object_unref (bus);\n\n  /* Register a function that GLib will call 4 times per second */\n  timeout_source = g_timeout_source_new (250);\n  g_source_set_callback (timeout_source, (GSourceFunc)refresh_ui, data, NULL);\n  g_source_attach (timeout_source, data-&gt;context);\n  g_source_unref (timeout_source);\n\n  /* Create a GLib Main Loop and set it to run */\n  GST_DEBUG (\"Entering main loop... (CustomData:%p)\", data);\n  data-&gt;main_loop = g_main_loop_new (data-&gt;context, FALSE);\n  check_initialization_complete (data);\n  g_main_loop_run (data-&gt;main_loop);\n  GST_DEBUG (\"Exited main loop\");\n  g_main_loop_unref (data-&gt;main_loop);\n  data-&gt;main_loop = NULL;\n\n  /* Free resources */\n  g_main_context_pop_thread_default(data-&gt;context);\n  g_main_context_unref (data-&gt;context);\n  data-&gt;target_state = GST_STATE_NULL;\n  gst_element_set_state (data-&gt;pipeline, GST_STATE_NULL);\n  gst_object_unref (data-&gt;pipeline);\n\n  return NULL;\n}\n\n/*\n * Java Bindings\n */\n\n/* Instruct the native code to create its internal data structure, pipeline and thread */\nstatic void gst_native_init (JNIEnv* env, jobject thiz) {\n  CustomData *data = g_new0 (CustomData, 1);\n  data-&gt;desired_position = GST_CLOCK_TIME_NONE;\n  data-&gt;last_seek_time = GST_CLOCK_TIME_NONE;\n  SET_CUSTOM_DATA (env, thiz, custom_data_field_id, data);\n  GST_DEBUG_CATEGORY_INIT (debug_category, \"tutorial-4\", 0, \"Android tutorial 4\");\n  gst_debug_set_threshold_for_name(\"tutorial-4\", GST_LEVEL_DEBUG);\n  GST_DEBUG (\"Created CustomData at %p\", data);\n  data-&gt;app = (*env)-&gt;NewGlobalRef (env, thiz);\n  GST_DEBUG (\"Created GlobalRef for app object at %p\", data-&gt;app);\n  pthread_create (&amp;gst_app_thread, NULL, &amp;app_function, data);\n}\n\n/* Quit the main loop, remove the native thread and free resources */\nstatic void gst_native_finalize (JNIEnv* env, jobject thiz) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  GST_DEBUG (\"Quitting main loop...\");\n  g_main_loop_quit (data-&gt;main_loop);\n  GST_DEBUG (\"Waiting for thread to finish...\");\n  pthread_join (gst_app_thread, NULL);\n  GST_DEBUG (\"Deleting GlobalRef for app object at %p\", data-&gt;app);\n  (*env)-&gt;DeleteGlobalRef (env, data-&gt;app);\n  GST_DEBUG (\"Freeing CustomData at %p\", data);\n  g_free (data);\n  SET_CUSTOM_DATA (env, thiz, custom_data_field_id, NULL);\n  GST_DEBUG (\"Done finalizing\");\n}\n\n/* Set playbin's URI */\nvoid gst_native_set_uri (JNIEnv* env, jobject thiz, jstring uri) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data || !data-&gt;pipeline) return;\n  const jbyte *char_uri = (*env)-&gt;GetStringUTFChars (env, uri, NULL);\n  GST_DEBUG (\"Setting URI to %s\", char_uri);\n  if (data-&gt;target_state &gt;= GST_STATE_READY)\n    gst_element_set_state (data-&gt;pipeline, GST_STATE_READY);\n  g_object_set(data-&gt;pipeline, \"uri\", char_uri, NULL);\n  (*env)-&gt;ReleaseStringUTFChars (env, uri, char_uri);\n  data-&gt;duration = GST_CLOCK_TIME_NONE;\n  data-&gt;is_live = (gst_element_set_state (data-&gt;pipeline, data-&gt;target_state) == GST_STATE_CHANGE_NO_PREROLL);\n}\n\n/* Set pipeline to PLAYING state */\nstatic void gst_native_play (JNIEnv* env, jobject thiz) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  GST_DEBUG (\"Setting state to PLAYING\");\n  data-&gt;target_state = GST_STATE_PLAYING;\n  data-&gt;is_live = (gst_element_set_state (data-&gt;pipeline, GST_STATE_PLAYING) == GST_STATE_CHANGE_NO_PREROLL);\n}\n\n/* Set pipeline to PAUSED state */\nstatic void gst_native_pause (JNIEnv* env, jobject thiz) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  GST_DEBUG (\"Setting state to PAUSED\");\n  data-&gt;target_state = GST_STATE_PAUSED;\n  data-&gt;is_live = (gst_element_set_state (data-&gt;pipeline, GST_STATE_PAUSED) == GST_STATE_CHANGE_NO_PREROLL);\n}\n\n/* Instruct the pipeline to seek to a different position */\nvoid gst_native_set_position (JNIEnv* env, jobject thiz, int milliseconds) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  gint64 desired_position = (gint64)(milliseconds * GST_MSECOND);\n  if (data-&gt;state &gt;= GST_STATE_PAUSED) {\n    execute_seek(desired_position, data);\n  } else {\n    GST_DEBUG (\"Scheduling seek to %\" GST_TIME_FORMAT \" for later\", GST_TIME_ARGS (desired_position));\n    data-&gt;desired_position = desired_position;\n  }\n}\n\n/* Static class initializer: retrieve method and field IDs */\nstatic jboolean gst_native_class_init (JNIEnv* env, jclass klass) {\n  custom_data_field_id = (*env)-&gt;GetFieldID (env, klass, \"native_custom_data\", \"J\");\n  set_message_method_id = (*env)-&gt;GetMethodID (env, klass, \"setMessage\", \"(Ljava/lang/String;)V\");\n  set_current_position_method_id = (*env)-&gt;GetMethodID (env, klass, \"setCurrentPosition\", \"(II)V\");\n  on_gstreamer_initialized_method_id = (*env)-&gt;GetMethodID (env, klass, \"onGStreamerInitialized\", \"()V\");\n  on_media_size_changed_method_id = (*env)-&gt;GetMethodID (env, klass, \"onMediaSizeChanged\", \"(II)V\");\n\n  if (!custom_data_field_id || !set_message_method_id || !on_gstreamer_initialized_method_id ||\n      !on_media_size_changed_method_id || !set_current_position_method_id) {\n    /* We emit this message through the Android log instead of the GStreamer log because the later\n     * has not been initialized yet.\n     */\n    __android_log_print (ANDROID_LOG_ERROR, \"tutorial-4\", \"The calling class does not implement all necessary interface methods\");\n    return JNI_FALSE;\n  }\n  return JNI_TRUE;\n}\n\nstatic void gst_native_surface_init (JNIEnv *env, jobject thiz, jobject surface) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  ANativeWindow *new_native_window = ANativeWindow_fromSurface(env, surface);\n  GST_DEBUG (\"Received surface %p (native window %p)\", surface, new_native_window);\n\n  if (data-&gt;native_window) {\n    ANativeWindow_release (data-&gt;native_window);\n    if (data-&gt;native_window == new_native_window) {\n      GST_DEBUG (\"New native window is the same as the previous one\", data-&gt;native_window);\n      if (data-&gt;pipeline) {\n        gst_x_overlay_expose(GST_X_OVERLAY (data-&gt;pipeline));\n        gst_x_overlay_expose(GST_X_OVERLAY (data-&gt;pipeline));\n      }\n      return;\n    } else {\n      GST_DEBUG (\"Released previous native window %p\", data-&gt;native_window);\n      data-&gt;initialized = FALSE;\n    }\n  }\n  data-&gt;native_window = new_native_window;\n\n  check_initialization_complete (data);\n}\n\nstatic void gst_native_surface_finalize (JNIEnv *env, jobject thiz) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  GST_DEBUG (\"Releasing Native Window %p\", data-&gt;native_window);\n\n  if (data-&gt;pipeline) {\n    gst_x_overlay_set_window_handle (GST_X_OVERLAY (data-&gt;pipeline), (guintptr)NULL);\n    gst_element_set_state (data-&gt;pipeline, GST_STATE_READY);\n  }\n\n  ANativeWindow_release (data-&gt;native_window);\n  data-&gt;native_window = NULL;\n  data-&gt;initialized = FALSE;\n}\n\n/* List of implemented native methods */\nstatic JNINativeMethod native_methods[] = {\n  { \"nativeInit\", \"()V\", (void *) gst_native_init},\n  { \"nativeFinalize\", \"()V\", (void *) gst_native_finalize},\n  { \"nativeSetUri\", \"(Ljava/lang/String;)V\", (void *) gst_native_set_uri},\n  { \"nativePlay\", \"()V\", (void *) gst_native_play},\n  { \"nativePause\", \"()V\", (void *) gst_native_pause},\n  { \"nativeSetPosition\", \"(I)V\", (void*) gst_native_set_position},\n  { \"nativeSurfaceInit\", \"(Ljava/lang/Object;)V\", (void *) gst_native_surface_init},\n  { \"nativeSurfaceFinalize\", \"()V\", (void *) gst_native_surface_finalize},\n  { \"nativeClassInit\", \"()Z\", (void *) gst_native_class_init}\n};\n\n/* Library initializer */\njint JNI_OnLoad(JavaVM *vm, void *reserved) {\n  JNIEnv *env = NULL;\n\n  java_vm = vm;\n\n  if ((*vm)-&gt;GetEnv(vm, (void**) &amp;env, JNI_VERSION_1_4) != JNI_OK) {\n    __android_log_print (ANDROID_LOG_ERROR, \"tutorial-4\", \"Could not retrieve JNIEnv\");\n    return 0;\n  }\n  jclass klass = (*env)-&gt;FindClass (env, \"com/gst_sdk_tutorials/tutorial_4/Tutorial4\");\n  (*env)-&gt;RegisterNatives (env, klass, native_methods, G_N_ELEMENTS(native_methods));\n\n  pthread_key_create (&amp;current_jni_env, detach_current_thread);\n\n  return JNI_VERSION_1_4;\n}\n</code></pre>\n<h3 id=\"supporting-arbitrary-media-uris1\">Supporting arbitrary media URIs</h3>\n<p>Java code will call <code>gst_native_set_uri()</code> whenever it wants to change\nthe playing URI (in this tutorial the URI never changes, but it could):</p>\n<pre><code class=\"language-c\">void gst_native_set_uri (JNIEnv* env, jobject thiz, jstring uri) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data || !data-&gt;pipeline) return;\n  const jbyte *char_uri = (*env)-&gt;GetStringUTFChars (env, uri, NULL);\n  GST_DEBUG (\"Setting URI to %s\", char_uri);\n  if (data-&gt;target_state &gt;= GST_STATE_READY)\n    gst_element_set_state (data-&gt;pipeline, GST_STATE_READY);\n  g_object_set(data-&gt;pipeline, \"uri\", char_uri, NULL);\n  (*env)-&gt;ReleaseStringUTFChars (env, uri, char_uri);\n  data-&gt;duration = GST_CLOCK_TIME_NONE;\n  data-&gt;is_live = (gst_element_set_state (data-&gt;pipeline, data-&gt;target_state) == GST_STATE_CHANGE_NO_PREROLL);\n}\n</code></pre>\n<p>We first need to convert between the\n<a href=\"http://en.wikipedia.org/wiki/UTF-16\">UTF16</a> encoding used by Java and\nthe <a href=\"http://en.wikipedia.org/wiki/UTF-8#Modified_UTF-8\">Modified\nUTF8</a> used by\nGStreamer with\n<a href=\"http://docs.oracle.com/javase/1.5.0/docs/guide/jni/spec/functions.html#wp17265\">GetStringUTFChars()</a>\nand\n<a href=\"http://docs.oracle.com/javase/1.5.0/docs/guide/jni/spec/functions.html#wp17294\">ReleaseStringUTFChars()</a>.</p>\n<p><code>playbin</code> will only care about URI changes in the READY to PAUSED state\nchange, because the new URI might need a completely different playback\npipeline (think about switching from a local Matroska file to a remote\nOGG file: this would require, at least, different source and demuxing\nelements). Thus, before passing the new URI to <code>playbin</code> we set its\nstate to READY (if we were in PAUSED or PLAYING).</p>\n<p><code>playbin</code>\u2019s URI is exposed as a common GObject property, so we simply\nset it with <code>g_object_set()</code>.</p>\n<p>We then reset the clip duration, so it is re-queried later, and bring\nthe pipeline to the playing state it had before. In this last step, we\nalso take note of whether the new URI corresponds to a live source or\nnot. Live sources must not use buffering (otherwise latency is\nintroduced which is inacceptable for them), so we keep track of this\ninformation in the <code>is_live</code> variable.</p>\n<h3 id=\"reporting-media-size1\">Reporting media size</h3>\n<p>Some codecs allow the media size (width and height of the video) to\nchange during playback. For simplicity, this tutorial assumes that they\ndo not. Therefore, in the READY to PAUSED state change, once the Caps of\nthe decoded media are known, we inspect them in <code>check_media_size()</code>:</p>\n<pre><code class=\"language-c\">static void check_media_size (CustomData *data) {\n  JNIEnv *env = get_jni_env ();\n  GstElement *video_sink;\n  GstPad *video_sink_pad;\n  GstCaps *caps;\n  GstVideoFormat fmt;\n  int width;\n  int height;\n\n  /* Retrieve the Caps at the entrance of the video sink */\n  g_object_get (data-&gt;pipeline, \"video-sink\", &amp;video_sink, NULL);\n  video_sink_pad = gst_element_get_static_pad (video_sink, \"sink\");\n  caps = gst_pad_get_negotiated_caps (video_sink_pad);\n\n  if (gst_video_format_parse_caps(caps, &amp;fmt, &amp;width, &amp;height)) {\n    int par_n, par_d;\n    if (gst_video_parse_caps_pixel_aspect_ratio (caps, &amp;par_n, &amp;par_d)) {\n      width = width * par_n / par_d;\n    }\n    GST_DEBUG (\"Media size is %dx%d, notifying application\", width, height);\n\n    (*env)-&gt;CallVoidMethod (env, data-&gt;app, on_media_size_changed_method_id, (jint)width, (jint)height);\n    if ((*env)-&gt;ExceptionCheck (env)) {\n      GST_ERROR (\"Failed to call Java method\");\n      (*env)-&gt;ExceptionClear (env);\n    }\n  }\n\n  gst_caps_unref(caps);\n  gst_object_unref (video_sink_pad);\n  gst_object_unref(video_sink);\n}\n</code></pre>\n<p>We first retrieve the video sink element from the pipeline, using the\n<code>video-sink</code> property of <code>playbin</code>, and then its sink Pad. The\nnegotiated Caps of this Pad, which we recover using\n<code>gst_pad_get_negotiated_caps()</code>,  are the Caps of the decoded media.</p>\n<p>The helper functions <code>gst_video_format_parse_caps()</code> and\n<code>gst_video_parse_caps_pixel_aspect_ratio()</code> turn the Caps into\nmanageable integers, which we pass to Java through\nits <code>onMediaSizeChanged()</code> callback.</p>\n<h3 id=\"refreshing-the-seek-bar1\">Refreshing the Seek Bar</h3>\n<p>To keep the UI updated, a GLib timer is installed in the\n<code>app_function()</code> that fires 4 times per second (or every 250ms), right\nbefore entering the main loop:</p>\n<pre><code class=\"language-c\">timeout_source = g_timeout_source_new (250);\ng_source_set_callback (timeout_source, (GSourceFunc)refresh_ui, data, NULL);\ng_source_attach (timeout_source, data-&gt;context);\ng_source_unref (timeout_source);\n</code></pre>\n<p>Then, in the refresh_ui method:</p>\n<pre><code class=\"language-c\">static gboolean refresh_ui (CustomData *data) {\n  GstFormat fmt = GST_FORMAT_TIME;\n  gint64 current = -1;\n  gint64 position;\n\n  /* We do not want to update anything unless we have a working pipeline in the PAUSED or PLAYING state */\n  if (!data || !data-&gt;pipeline || data-&gt;state &lt; GST_STATE_PAUSED)\n    return TRUE;\n\n  /* If we didn't know it yet, query the stream duration */\n  if (!GST_CLOCK_TIME_IS_VALID (data-&gt;duration)) {\n    if (!gst_element_query_duration (data-&gt;pipeline, &amp;fmt, &amp;data-&gt;duration)) {\n      GST_WARNING (\"Could not query current duration\");\n    }\n  }\n\n  if (gst_element_query_position (data-&gt;pipeline, &amp;fmt, &amp;position)) {\n    /* Java expects these values in milliseconds, and GStreamer provides nanoseconds */\n    set_current_ui_position (position / GST_MSECOND, data-&gt;duration / GST_MSECOND, data);\n  }\n  return TRUE;\n}\n</code></pre>\n<p>If it is unknown, the clip duration is retrieved, as explained in\n<a href=\"../basic/time-management.html\">Basic tutorial 4: Time management</a>. The current position is\nretrieved next, and the UI is informed of both through its\n<code>setCurrentPosition()</code> callback.</p>\n<p>Bear in mind that all time-related measures returned by GStreamer are in\nnanoseconds, whereas, for simplicity, we decided to make the UI code\nwork in milliseconds.</p>\n<h3 id=\"seeking-with-the-seek-bar1\">Seeking with the Seek Bar</h3>\n<p>The Java UI code already takes care of most of the complexity of seeking\nby dragging the thumb of the Seek Bar. From C code, we just need to\nhonor the calls to <code>nativeSetPosition()</code> and instruct the pipeline to\njump to the indicated position.</p>\n<p>There are, though, a couple of caveats. Firstly, seeks are only possible\nwhen the pipeline is in the PAUSED or PLAYING state, and we might\nreceive seek requests before that happens. Secondly, dragging the Seek\nBar can generate a very high number of seek requests in a short period\nof time, which is visually useless and will impair responsiveness. Let\u2019s\nsee how to overcome these problems.</p>\n<h4 id=\"delayed-seeks\">Delayed seeks</h4>\n<p>In\n<code>gst_native_set_position()</code>:</p>\n<pre><code class=\"language-c\">void gst_native_set_position (JNIEnv* env, jobject thiz, int milliseconds) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  gint64 desired_position = (gint64)(milliseconds * GST_MSECOND);\n  if (data-&gt;state &gt;= GST_STATE_PAUSED) {\n    execute_seek(desired_position, data);\n  } else {\n    GST_DEBUG (\"Scheduling seek to %\" GST_TIME_FORMAT \" for later\", GST_TIME_ARGS (desired_position));\n    data-&gt;desired_position = desired_position;\n  }\n}\n</code></pre>\n<p>If we are already in the correct state for seeking, execute it right\naway; otherwise, store the desired position in the\n<code>desired_position</code> variable. Then, in the\n<code>state_changed_cb()</code> callback:</p>\n<pre><code class=\"language-c\">if (old_state == GST_STATE_READY &amp;&amp; new_state == GST_STATE_PAUSED) {\n  /* By now the sink already knows the media size */\n  check_media_size(data);\n\n  /* If there was a scheduled seek, perform it now that we have moved to the Paused state */\n  if (GST_CLOCK_TIME_IS_VALID (data-&gt;desired_position))\n    execute_seek (data-&gt;desired_position, data);\n }\n}\n</code></pre>\n<p>Once the pipeline moves from the READY to the PAUSED state, we check if\nthere is a pending seek operation and execute it. The\n<code>desired_position</code> variable is reset inside <code>execute_seek()</code>.</p>\n<h4 id=\"seek-throttling\">Seek throttling</h4>\n<p>A seek is potentially a lengthy operation. The demuxer (the element\ntypically in charge of seeking) needs to estimate the appropriate byte\noffset inside the media file that corresponds to the time position to\njump to. Then, it needs to start decoding from that point until the\ndesired position is reached. If the initial estimate is accurate, this\nwill not take long, but, on some container formats, or when indexing\ninformation is missing, it can take up to several seconds.</p>\n<p>If a demuxer is in the process of performing a seek and receives a\nsecond one, it is up to it to finish the first one, start the second one\nor abort both, which is a bad thing. A simple method to avoid this issue\nis <em>throttling</em>, which means that we will only allow one seek every half\na second (for example): after performing a seek, only the last seek\nrequest received during the next 500ms is stored, and will be honored\nonce this period elapses.</p>\n<p>To achieve this, all seek requests are routed through the\n<code>execute_seek()</code> method:</p>\n<pre><code class=\"language-c\">static void execute_seek (gint64 desired_position, CustomData *data) {\n  gint64 diff;\n\n  if (desired_position == GST_CLOCK_TIME_NONE)\n    return;\n\n  diff = gst_util_get_timestamp () - data-&gt;last_seek_time;\n\n  if (GST_CLOCK_TIME_IS_VALID (data-&gt;last_seek_time) &amp;&amp; diff &lt; SEEK_MIN_DELAY) {\n    /* The previous seek was too close, delay this one */\n    GSource *timeout_source;\n\n    if (data-&gt;desired_position == GST_CLOCK_TIME_NONE) {\n      /* There was no previous seek scheduled. Setup a timer for some time in the future */\n      timeout_source = g_timeout_source_new ((SEEK_MIN_DELAY - diff) / GST_MSECOND);\n      g_source_set_callback (timeout_source, (GSourceFunc)delayed_seek_cb, data, NULL);\n      g_source_attach (timeout_source, data-&gt;context);\n      g_source_unref (timeout_source);\n    }\n    /* Update the desired seek position. If multiple requests are received before it is time\n     * to perform a seek, only the last one is remembered. */\n    data-&gt;desired_position = desired_position;\n    GST_DEBUG (\"Throttling seek to %\" GST_TIME_FORMAT \", will be in %\" GST_TIME_FORMAT,\n        GST_TIME_ARGS (desired_position), GST_TIME_ARGS (SEEK_MIN_DELAY - diff));\n  } else {\n    /* Perform the seek now */\n    GST_DEBUG (\"Seeking to %\" GST_TIME_FORMAT, GST_TIME_ARGS (desired_position));\n    data-&gt;last_seek_time = gst_util_get_timestamp ();\n    gst_element_seek_simple (data-&gt;pipeline, GST_FORMAT_TIME, GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_KEY_UNIT, desired_position);\n    data-&gt;desired_position = GST_CLOCK_TIME_NONE;\n  }\n}\n</code></pre>\n<p>The time at which the last seek was performed is stored in the\n<code>last_seek_time</code> variable. This is wall clock time, not to be confused\nwith the stream time carried in the media time stamps, and is obtained\nwith <code>gst_util_get_timestamp()</code>.</p>\n<p>If enough time has passed since the last seek operation, the new one is\ndirectly executed and <code>last_seek_time</code> is updated. Otherwise, the new\nseek is scheduled for later. If there is no previously scheduled seek, a\none-shot timer is setup to trigger 500ms after the last seek operation.\nIf another seek was already scheduled, its desired position is simply\nupdated with the new one.</p>\n<p>The one-shot timer calls <code>delayed_seek_cb()</code>, which simply calls\n<code>execute_seek()</code> again.</p>\n<blockquote>\n<p><img src=\"images/icons/emoticons/information.png\" alt=\"information\" id=\"information\">\nIdeally, <code>execute_seek()</code> will now find that enough time has indeed passed since the last seek and the scheduled one will proceed. It might happen, though, that after 500ms of the previous seek, and before the timer wakes up, yet another seek comes through and is executed. <code>delayed_seek_cb()</code> needs to check for this condition to avoid performing two very close seeks, and therefore calls <code>execute_seek()</code> instead of performing it itself.</p>\n<p>This is not a complete solution: the scheduled seek will still be executed, even though a more-recent seek has already been executed that should have cancelled it. However, it is a good tradeoff between functionality and simplicity.</p>\n</blockquote>\n<h3 id=\"network-resilience\">Network resilience</h3>\n<p><a href=\"../basic/streaming.html\">Basic tutorial 12: Streaming</a> has already\nshown how to adapt to the variable nature of the network bandwidth by\nusing buffering. The same procedure is used here, by listening to the\nbuffering\nmessages:</p>\n<pre><code class=\"language-c\">g_signal_connect (G_OBJECT (bus), \"message::buffering\", (GCallback)buffering_cb, data);\n</code></pre>\n<p>And pausing the pipeline until buffering is complete (unless this is a\nlive\nsource):</p>\n<pre><code class=\"language-c\">static void buffering_cb (GstBus *bus, GstMessage *msg, CustomData *data) {\n  gint percent;\n\n  if (data-&gt;is_live)\n    return;\n\n  gst_message_parse_buffering (msg, &amp;percent);\n  if (percent &lt; 100 &amp;&amp; data-&gt;target_state &gt;= GST_STATE_PAUSED) {\n    gchar * message_string = g_strdup_printf (\"Buffering %d%%\", percent);\n    gst_element_set_state (data-&gt;pipeline, GST_STATE_PAUSED);\n    set_ui_message (message_string, data);\n    g_free (message_string);\n  } else if (data-&gt;target_state &gt;= GST_STATE_PLAYING) {\n    gst_element_set_state (data-&gt;pipeline, GST_STATE_PLAYING);\n  } else if (data-&gt;target_state &gt;= GST_STATE_PAUSED) {\n    set_ui_message (\"Buffering complete\", data);\n  }\n}\n</code></pre>\n<p><code>target_state</code> is the state in which we have been instructed to set the\npipeline, which might be different to the current state, because\nbuffering forces us to go to PAUSED. Once buffering is complete we set\nthe pipeline to the <code>target_state</code>.</p>\n<h2 id=\"a-basic-media-player-androidmk\">A basic media player [Android.mk]</h2>\n<p>The only line worth mentioning in the makefile\nis <code>GSTREAMER_PLUGINS</code>:</p>\n<p><strong>jni/Android.mk</strong></p>\n<pre><code>GSTREAMER_PLUGINS         := $(GSTREAMER_PLUGINS_CORE) $(GSTREAMER_PLUGINS_PLAYBACK) $(GSTREAMER_PLUGINS_CODECS) $(GSTREAMER_PLUGINS_NET) $(GSTREAMER_PLUGINS_SYS)\n</code></pre>\n<p>In which all plugins required for playback are loaded, because it is not\nknown at build time what would be needed for an unspecified URI (again,\nin this tutorial the URI does not change, but it will in the next one).</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>This tutorial has shown how to embed a <code>playbin</code> pipeline into an\nAndroid application. This, effectively, turns such application into a\nbasic media player, capable of streaming and decoding all the formats\nGStreamer understands. More particularly, it has shown:</p>\n<ul>\n<li>How to keep the User Interface regularly updated by using a timer,\nquerying the pipeline position and calling a UI code method.</li>\n<li>How to implement a Seek Bar which follows the current position and\ntransforms thumb motion into reliable seek events.</li>\n<li>How to report the media size to adapt the display surface, by\nreading the sink Caps at the appropriate moment and telling the UI\nabout it.</li>\n</ul>\n<p>The next tutorial adds the missing bits to turn the application built\nhere into an acceptable Android media player.</p>\n<p>As usual, it has been a pleasure having you here, and see you soon!</p>\n\n        \n\n    </div>\n\n\n        "});