fragment_downloaded_cb({"url": "tutorials/android/video.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"video.md\">\n<h1 id=\"android-tutorial-3-video\">Android tutorial 3: Video</h1>\n<h3 id=\"goal\">Goal</h3>\n<p><img src=\"images/tutorials/android-video-screenshot.png\" alt=\"screenshot\" id=\"screenshot\"></p>\n<p>Except for <a href=\"../basic/toolkit-integration.html\">Basic tutorial 5: GUI toolkit integration</a>,\nwhich embedded a video window on a GTK application, all tutorials so far\nrelied on GStreamer video sinks to create a window to display their\ncontents. The video sink on Android is not capable of creating its own\nwindow, so a drawing surface always needs to be provided. This tutorial\nshows:</p>\n<ul>\n<li>How to allocate a drawing surface on the Android layout and pass it\nto GStreamer</li>\n<li>How to keep GStreamer posted on changes to the surface</li>\n</ul>\n<h3 id=\"introduction\">Introduction</h3>\n<p>Since Android does not provide a windowing system, a GStreamer video\nsink cannot create pop-up windows as it would do on a Desktop platform.\nFortunately, the <code>VideoOverlay</code> interface allows providing video sinks with\nan already created window onto which they can draw, as we have seen in\n<a href=\"../basic/toolkit-integration.html\">Basic tutorial 5: GUI toolkit integration</a>.</p>\n<p>In this tutorial, a\n<a href=\"http://developer.android.com/reference/android/view/SurfaceView.html\">SurfaceView</a>\nwidget (actually, a subclass of it) is placed on the main layout. When\nAndroid informs the application that a surface has been created for this\nwidget, we pass it to the C code which stores it. The\n<code>check_initialization_complete()</code> method explained in the previous\ntutorial is extended so that GStreamer is not considered initialized\nuntil a main loop is running and a drawing surface has been received.</p>\n<h3 id=\"a-video-surface-on-android-java-code\">A video surface on Android [Java code]</h3>\n<p><strong>src/org/freedesktop/gstreamer/tutorials/tutorial_3/Tutorial3.java</strong></p>\n<pre><code class=\"language-java\">package org.freedesktop.gstreamer.tutorials.tutorial_3;\n\nimport android.app.Activity;\nimport android.os.Bundle;\nimport android.util.Log;\nimport android.view.SurfaceHolder;\nimport android.view.SurfaceView;\nimport android.view.View;\nimport android.view.View.OnClickListener;\nimport android.widget.ImageButton;\nimport android.widget.TextView;\nimport android.widget.Toast;\n\nimport org.freedesktop.gstreamer.GStreamer;\n\npublic class Tutorial3 extends Activity implements SurfaceHolder.Callback {\n    private native void nativeInit();     // Initialize native code, build pipeline, etc\n    private native void nativeFinalize(); // Destroy pipeline and shutdown native code\n    private native void nativePlay();     // Set pipeline to PLAYING\n    private native void nativePause();    // Set pipeline to PAUSED\n    private static native boolean nativeClassInit(); // Initialize native class: cache Method IDs for callbacks\n    private native void nativeSurfaceInit(Object surface);\n    private native void nativeSurfaceFinalize();\n    private long native_custom_data;      // Native code will use this to keep private data\n\n    private boolean is_playing_desired;   // Whether the user asked to go to PLAYING\n\n    // Called when the activity is first created.\n    @Override\n    public void onCreate(Bundle savedInstanceState)\n    {\n        super.onCreate(savedInstanceState);\n\n        // Initialize GStreamer and warn if it fails\n        try {\n            GStreamer.init(this);\n        } catch (Exception e) {\n            Toast.makeText(this, e.getMessage(), Toast.LENGTH_LONG).show();\n            finish();\n            return;\n        }\n\n        setContentView(R.layout.main);\n\n        ImageButton play = (ImageButton) this.findViewById(R.id.button_play);\n        play.setOnClickListener(new OnClickListener() {\n            public void onClick(View v) {\n                is_playing_desired = true;\n                nativePlay();\n            }\n        });\n\n        ImageButton pause = (ImageButton) this.findViewById(R.id.button_stop);\n        pause.setOnClickListener(new OnClickListener() {\n            public void onClick(View v) {\n                is_playing_desired = false;\n                nativePause();\n            }\n        });\n\n        SurfaceView sv = (SurfaceView) this.findViewById(R.id.surface_video);\n        SurfaceHolder sh = sv.getHolder();\n        sh.addCallback(this);\n\n        if (savedInstanceState != null) {\n            is_playing_desired = savedInstanceState.getBoolean(\"playing\");\n            Log.i (\"GStreamer\", \"Activity created. Saved state is playing:\" + is_playing_desired);\n        } else {\n            is_playing_desired = false;\n            Log.i (\"GStreamer\", \"Activity created. There is no saved state, playing: false\");\n        }\n\n        // Start with disabled buttons, until native code is initialized\n        this.findViewById(R.id.button_play).setEnabled(false);\n        this.findViewById(R.id.button_stop).setEnabled(false);\n\n        nativeInit();\n    }\n\n    protected void onSaveInstanceState (Bundle outState) {\n        Log.d (\"GStreamer\", \"Saving state, playing:\" + is_playing_desired);\n        outState.putBoolean(\"playing\", is_playing_desired);\n    }\n\n    protected void onDestroy() {\n        nativeFinalize();\n        super.onDestroy();\n    }\n\n    // Called from native code. This sets the content of the TextView from the UI thread.\n    private void setMessage(final String message) {\n        final TextView tv = (TextView) this.findViewById(R.id.textview_message);\n        runOnUiThread (new Runnable() {\n          public void run() {\n            tv.setText(message);\n          }\n        });\n    }\n\n    // Called from native code. Native code calls this once it has created its pipeline and\n    // the main loop is running, so it is ready to accept commands.\n    private void onGStreamerInitialized () {\n        Log.i (\"GStreamer\", \"Gst initialized. Restoring state, playing:\" + is_playing_desired);\n        // Restore previous playing state\n        if (is_playing_desired) {\n            nativePlay();\n        } else {\n            nativePause();\n        }\n\n        // Re-enable buttons, now that GStreamer is initialized\n        final Activity activity = this;\n        runOnUiThread(new Runnable() {\n            public void run() {\n                activity.findViewById(R.id.button_play).setEnabled(true);\n                activity.findViewById(R.id.button_stop).setEnabled(true);\n            }\n        });\n    }\n\n    static {\n        System.loadLibrary(\"gstreamer_android\");\n        System.loadLibrary(\"tutorial-3\");\n        nativeClassInit();\n    }\n\n    public void surfaceChanged(SurfaceHolder holder, int format, int width,\n            int height) {\n        Log.d(\"GStreamer\", \"Surface changed to format \" + format + \" width \"\n                + width + \" height \" + height);\n        nativeSurfaceInit (holder.getSurface());\n    }\n\n    public void surfaceCreated(SurfaceHolder holder) {\n        Log.d(\"GStreamer\", \"Surface created: \" + holder.getSurface());\n    }\n\n    public void surfaceDestroyed(SurfaceHolder holder) {\n        Log.d(\"GStreamer\", \"Surface destroyed\");\n        nativeSurfaceFinalize ();\n    }\n\n}\n</code></pre>\n<p>This tutorial continues where the previous one left, adding a video\nsurface to the layout and changing the GStreamer pipeline to produce\nvideo instead of audio. Only the parts of the code that are new will be\ndiscussed.</p>\n<pre><code class=\"language-java\">private native void nativeSurfaceInit(Object surface);\nprivate native void nativeSurfaceFinalize();\n</code></pre>\n<p>Two new entry points to the C code are defined,\n<code>nativeSurfaceInit()</code> and <code>nativeSurfaceFinalize()</code>, which we will call\nwhen the video surface becomes available and when it is about to be\ndestroyed, respectively.</p>\n<pre><code class=\"language-java\">SurfaceView sv = (SurfaceView) this.findViewById(R.id.surface_video);\nSurfaceHolder sh = sv.getHolder();\nsh.addCallback(this);\n</code></pre>\n<p>In <code>onCreate()</code>, we retrieve the\n<a href=\"http://developer.android.com/reference/android/view/SurfaceView.html\">SurfaceView</a>,\nand then register ourselves to receive notifications about the surface\nstate through the\n<a href=\"http://developer.android.com/reference/android/view/SurfaceHolder.html\">SurfaceHolder</a>\ninterface. This is why we declared this Activity as implementing the\n<a href=\"http://developer.android.com/reference/android/view/SurfaceHolder.Callback.html\">SurfaceHolder.Callback</a>\ninterface in line 16.</p>\n<pre><code class=\"language-java\">public void surfaceChanged(SurfaceHolder holder, int format, int width,\n        int height) {\n    Log.d(\"GStreamer\", \"Surface changed to format \" + format + \" width \"\n            + width + \" height \" + height);\n    nativeSurfaceInit (holder.getSurface());\n}\n\npublic void surfaceCreated(SurfaceHolder holder) {\n    Log.d(\"GStreamer\", \"Surface created: \" + holder.getSurface());\n}\n\npublic void surfaceDestroyed(SurfaceHolder holder) {\n    Log.d(\"GStreamer\", \"Surface destroyed\");\n    nativeSurfaceFinalize ();\n}\n</code></pre>\n<p>This interface is composed of the three methods above, which get called\nwhen the geometry of the surface changes, when the surface is created\nand when it is about to be destroyed. <code>surfaceChanged()</code> always gets\ncalled at least once, right after <code>surfaceCreated()</code>, so we will use it\nto notify GStreamer about the new surface. We use\n<code>surfaceDestroyed()</code> to tell GStreamer to stop using this surface.</p>\n<p>Let\u2019s review the C code to see what these functions do.</p>\n<h3 id=\"a-video-surface-on-android-c-code\">A video surface on Android [C code]</h3>\n<p><strong>jni/tutorial-3.c</strong></p>\n<pre><code class=\"language-c\">#include &lt;string.h&gt;\n#include &lt;stdint.h&gt;\n#include &lt;jni.h&gt;\n#include &lt;android/log.h&gt;\n#include &lt;android/native_window.h&gt;\n#include &lt;android/native_window_jni.h&gt;\n#include &lt;gst/gst.h&gt;\n#include &lt;gst/video/video.h&gt;\n#include &lt;pthread.h&gt;\n\nGST_DEBUG_CATEGORY_STATIC (debug_category);\n#define GST_CAT_DEFAULT debug_category\n\n/*\n * These macros provide a way to store the native pointer to CustomData, which might be 32 or 64 bits, into\n * a jlong, which is always 64 bits, without warnings.\n */\n#if GLIB_SIZEOF_VOID_P == 8\n## define GET_CUSTOM_DATA(env, thiz, fieldID) (CustomData *)(*env)-&gt;GetLongField (env, thiz, fieldID)\n## define SET_CUSTOM_DATA(env, thiz, fieldID, data) (*env)-&gt;SetLongField (env, thiz, fieldID, (jlong)data)\n#else\n## define GET_CUSTOM_DATA(env, thiz, fieldID) (CustomData *)(jint)(*env)-&gt;GetLongField (env, thiz, fieldID)\n## define SET_CUSTOM_DATA(env, thiz, fieldID, data) (*env)-&gt;SetLongField (env, thiz, fieldID, (jlong)(jint)data)\n#endif\n\n/* Structure to contain all our information, so we can pass it to callbacks */\ntypedef struct _CustomData {\n  jobject app;            /* Application instance, used to call its methods. A global reference is kept. */\n  GstElement *pipeline;   /* The running pipeline */\n  GMainContext *context;  /* GLib context used to run the main loop */\n  GMainLoop *main_loop;   /* GLib main loop */\n  gboolean initialized;   /* To avoid informing the UI multiple times about the initialization */\n  GstElement *video_sink; /* The video sink element which receives VideoOverlay commands */\n  ANativeWindow *native_window; /* The Android native window where video will be rendered */\n} CustomData;\n\n/* These global variables cache values which are not changing during execution */\nstatic pthread_t gst_app_thread;\nstatic pthread_key_t current_jni_env;\nstatic JavaVM *java_vm;\nstatic jfieldID custom_data_field_id;\nstatic jmethodID set_message_method_id;\nstatic jmethodID on_gstreamer_initialized_method_id;\n\n/*\n * Private methods\n */\n\n/* Register this thread with the VM */\nstatic JNIEnv *attach_current_thread (void) {\n  JNIEnv *env;\n  JavaVMAttachArgs args;\n\n  GST_DEBUG (\"Attaching thread %p\", g_thread_self ());\n  args.version = JNI_VERSION_1_4;\n  args.name = NULL;\n  args.group = NULL;\n\n  if ((*java_vm)-&gt;AttachCurrentThread (java_vm, &amp;env, &amp;args) &lt; 0) {\n    GST_ERROR (\"Failed to attach current thread\");\n    return NULL;\n  }\n\n  return env;\n}\n\n/* Unregister this thread from the VM */\nstatic void detach_current_thread (void *env) {\n  GST_DEBUG (\"Detaching thread %p\", g_thread_self ());\n  (*java_vm)-&gt;DetachCurrentThread (java_vm);\n}\n\n/* Retrieve the JNI environment for this thread */\nstatic JNIEnv *get_jni_env (void) {\n  JNIEnv *env;\n\n  if ((env = pthread_getspecific (current_jni_env)) == NULL) {\n    env = attach_current_thread ();\n    pthread_setspecific (current_jni_env, env);\n  }\n\n  return env;\n}\n\n/* Change the content of the UI's TextView */\nstatic void set_ui_message (const gchar *message, CustomData *data) {\n  JNIEnv *env = get_jni_env ();\n  GST_DEBUG (\"Setting message to: %s\", message);\n  jstring jmessage = (*env)-&gt;NewStringUTF(env, message);\n  (*env)-&gt;CallVoidMethod (env, data-&gt;app, set_message_method_id, jmessage);\n  if ((*env)-&gt;ExceptionCheck (env)) {\n    GST_ERROR (\"Failed to call Java method\");\n    (*env)-&gt;ExceptionClear (env);\n  }\n  (*env)-&gt;DeleteLocalRef (env, jmessage);\n}\n\n/* Retrieve errors from the bus and show them on the UI */\nstatic void error_cb (GstBus *bus, GstMessage *msg, CustomData *data) {\n  GError *err;\n  gchar *debug_info;\n  gchar *message_string;\n\n  gst_message_parse_error (msg, &amp;err, &amp;debug_info);\n  message_string = g_strdup_printf (\"Error received from element %s: %s\", GST_OBJECT_NAME (msg-&gt;src), err-&gt;message);\n  g_clear_error (&amp;err);\n  g_free (debug_info);\n  set_ui_message (message_string, data);\n  g_free (message_string);\n  gst_element_set_state (data-&gt;pipeline, GST_STATE_NULL);\n}\n\n/* Notify UI about pipeline state changes */\nstatic void state_changed_cb (GstBus *bus, GstMessage *msg, CustomData *data) {\n  GstState old_state, new_state, pending_state;\n  gst_message_parse_state_changed (msg, &amp;old_state, &amp;new_state, &amp;pending_state);\n  /* Only pay attention to messages coming from the pipeline, not its children */\n  if (GST_MESSAGE_SRC (msg) == GST_OBJECT (data-&gt;pipeline)) {\n    gchar *message = g_strdup_printf(\"State changed to %s\", gst_element_state_get_name(new_state));\n    set_ui_message(message, data);\n    g_free (message);\n  }\n}\n\n/* Check if all conditions are met to report GStreamer as initialized.\n * These conditions will change depending on the application */\nstatic void check_initialization_complete (CustomData *data) {\n  JNIEnv *env = get_jni_env ();\n  if (!data-&gt;initialized &amp;&amp; data-&gt;native_window &amp;&amp; data-&gt;main_loop) {\n    GST_DEBUG (\"Initialization complete, notifying application. native_window:%p main_loop:%p\", data-&gt;native_window, data-&gt;main_loop);\n\n    /* The main loop is running and we received a native window, inform the sink about it */\n    gst_video_overlay_set_window_handle (GST_VIDEO_OVERLAY (data-&gt;video_sink), (guintptr)data-&gt;native_window);\n\n    (*env)-&gt;CallVoidMethod (env, data-&gt;app, on_gstreamer_initialized_method_id);\n    if ((*env)-&gt;ExceptionCheck (env)) {\n      GST_ERROR (\"Failed to call Java method\");\n      (*env)-&gt;ExceptionClear (env);\n    }\n    data-&gt;initialized = TRUE;\n  }\n}\n\n/* Main method for the native code. This is executed on its own thread. */\nstatic void *app_function (void *userdata) {\n  JavaVMAttachArgs args;\n  GstBus *bus;\n  CustomData *data = (CustomData *)userdata;\n  GSource *bus_source;\n  GError *error = NULL;\n\n  GST_DEBUG (\"Creating pipeline in CustomData at %p\", data);\n\n  /* Create our own GLib Main Context and make it the default one */\n  data-&gt;context = g_main_context_new ();\n  g_main_context_push_thread_default(data-&gt;context);\n\n  /* Build pipeline */\n  data-&gt;pipeline = gst_parse_launch(\"videotestsrc ! warptv ! videoconvert ! autovideosink\", &amp;error);\n  if (error) {\n    gchar *message = g_strdup_printf(\"Unable to build pipeline: %s\", error-&gt;message);\n    g_clear_error (&amp;error);\n    set_ui_message(message, data);\n    g_free (message);\n    return NULL;\n  }\n\n  /* Set the pipeline to READY, so it can already accept a window handle, if we have one */\n  gst_element_set_state(data-&gt;pipeline, GST_STATE_READY);\n\n  data-&gt;video_sink = gst_bin_get_by_interface(GST_BIN(data-&gt;pipeline), GST_TYPE_VIDEO_OVERLAY);\n  if (!data-&gt;video_sink) {\n    GST_ERROR (\"Could not retrieve video sink\");\n    return NULL;\n  }\n\n  /* Instruct the bus to emit signals for each received message, and connect to the interesting signals */\n  bus = gst_element_get_bus (data-&gt;pipeline);\n  bus_source = gst_bus_create_watch (bus);\n  g_source_set_callback (bus_source, (GSourceFunc) gst_bus_async_signal_func, NULL, NULL);\n  g_source_attach (bus_source, data-&gt;context);\n  g_source_unref (bus_source);\n  g_signal_connect (G_OBJECT (bus), \"message::error\", (GCallback)error_cb, data);\n  g_signal_connect (G_OBJECT (bus), \"message::state-changed\", (GCallback)state_changed_cb, data);\n  gst_object_unref (bus);\n\n  /* Create a GLib Main Loop and set it to run */\n  GST_DEBUG (\"Entering main loop... (CustomData:%p)\", data);\n  data-&gt;main_loop = g_main_loop_new (data-&gt;context, FALSE);\n  check_initialization_complete (data);\n  g_main_loop_run (data-&gt;main_loop);\n  GST_DEBUG (\"Exited main loop\");\n  g_main_loop_unref (data-&gt;main_loop);\n  data-&gt;main_loop = NULL;\n\n  /* Free resources */\n  g_main_context_pop_thread_default(data-&gt;context);\n  g_main_context_unref (data-&gt;context);\n  gst_element_set_state (data-&gt;pipeline, GST_STATE_NULL);\n  gst_object_unref (data-&gt;video_sink);\n  gst_object_unref (data-&gt;pipeline);\n\n  return NULL;\n}\n\n/*\n * Java Bindings\n */\n\n/* Instruct the native code to create its internal data structure, pipeline and thread */\nstatic void gst_native_init (JNIEnv* env, jobject thiz) {\n  CustomData *data = g_new0 (CustomData, 1);\n  SET_CUSTOM_DATA (env, thiz, custom_data_field_id, data);\n  GST_DEBUG_CATEGORY_INIT (debug_category, \"tutorial-3\", 0, \"Android tutorial 3\");\n  gst_debug_set_threshold_for_name(\"tutorial-3\", GST_LEVEL_DEBUG);\n  GST_DEBUG (\"Created CustomData at %p\", data);\n  data-&gt;app = (*env)-&gt;NewGlobalRef (env, thiz);\n  GST_DEBUG (\"Created GlobalRef for app object at %p\", data-&gt;app);\n  pthread_create (&amp;gst_app_thread, NULL, &amp;app_function, data);\n}\n\n/* Quit the main loop, remove the native thread and free resources */\nstatic void gst_native_finalize (JNIEnv* env, jobject thiz) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  GST_DEBUG (\"Quitting main loop...\");\n  g_main_loop_quit (data-&gt;main_loop);\n  GST_DEBUG (\"Waiting for thread to finish...\");\n  pthread_join (gst_app_thread, NULL);\n  GST_DEBUG (\"Deleting GlobalRef for app object at %p\", data-&gt;app);\n  (*env)-&gt;DeleteGlobalRef (env, data-&gt;app);\n  GST_DEBUG (\"Freeing CustomData at %p\", data);\n  g_free (data);\n  SET_CUSTOM_DATA (env, thiz, custom_data_field_id, NULL);\n  GST_DEBUG (\"Done finalizing\");\n}\n\n/* Set pipeline to PLAYING state */\nstatic void gst_native_play (JNIEnv* env, jobject thiz) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  GST_DEBUG (\"Setting state to PLAYING\");\n  gst_element_set_state (data-&gt;pipeline, GST_STATE_PLAYING);\n}\n\n/* Set pipeline to PAUSED state */\nstatic void gst_native_pause (JNIEnv* env, jobject thiz) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  GST_DEBUG (\"Setting state to PAUSED\");\n  gst_element_set_state (data-&gt;pipeline, GST_STATE_PAUSED);\n}\n\n/* Static class initializer: retrieve method and field IDs */\nstatic jboolean gst_native_class_init (JNIEnv* env, jclass klass) {\n  custom_data_field_id = (*env)-&gt;GetFieldID (env, klass, \"native_custom_data\", \"J\");\n  set_message_method_id = (*env)-&gt;GetMethodID (env, klass, \"setMessage\", \"(Ljava/lang/String;)V\");\n  on_gstreamer_initialized_method_id = (*env)-&gt;GetMethodID (env, klass, \"onGStreamerInitialized\", \"()V\");\n\n  if (!custom_data_field_id || !set_message_method_id || !on_gstreamer_initialized_method_id) {\n    /* We emit this message through the Android log instead of the GStreamer log because the later\n     * has not been initialized yet.\n     */\n    __android_log_print (ANDROID_LOG_ERROR, \"tutorial-3\", \"The calling class does not implement all necessary interface methods\");\n    return JNI_FALSE;\n  }\n  return JNI_TRUE;\n}\n\nstatic void gst_native_surface_init (JNIEnv *env, jobject thiz, jobject surface) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  ANativeWindow *new_native_window = ANativeWindow_fromSurface(env, surface);\n  GST_DEBUG (\"Received surface %p (native window %p)\", surface, new_native_window);\n\n  if (data-&gt;native_window) {\n    ANativeWindow_release (data-&gt;native_window);\n    if (data-&gt;native_window == new_native_window) {\n      GST_DEBUG (\"New native window is the same as the previous one\", data-&gt;native_window);\n      if (data-&gt;video_sink) {\n        gst_video_overlay_expose(GST_VIDEO_OVERLAY (data-&gt;video_sink));\n        gst_video_overlay_expose(GST_VIDEO_OVERLAY (data-&gt;video_sink));\n      }\n      return;\n    } else {\n      GST_DEBUG (\"Released previous native window %p\", data-&gt;native_window);\n      data-&gt;initialized = FALSE;\n    }\n  }\n  data-&gt;native_window = new_native_window;\n\n  check_initialization_complete (data);\n}\n\nstatic void gst_native_surface_finalize (JNIEnv *env, jobject thiz) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  GST_DEBUG (\"Releasing Native Window %p\", data-&gt;native_window);\n\n  if (data-&gt;video_sink) {\n    gst_video_overlay_set_window_handle (GST_VIDEO_OVERLAY (data-&gt;video_sink), (guintptr)NULL);\n    gst_element_set_state (data-&gt;pipeline, GST_STATE_READY);\n  }\n\n  ANativeWindow_release (data-&gt;native_window);\n  data-&gt;native_window = NULL;\n  data-&gt;initialized = FALSE;\n}\n\n/* List of implemented native methods */\nstatic JNINativeMethod native_methods[] = {\n  { \"nativeInit\", \"()V\", (void *) gst_native_init},\n  { \"nativeFinalize\", \"()V\", (void *) gst_native_finalize},\n  { \"nativePlay\", \"()V\", (void *) gst_native_play},\n  { \"nativePause\", \"()V\", (void *) gst_native_pause},\n  { \"nativeSurfaceInit\", \"(Ljava/lang/Object;)V\", (void *) gst_native_surface_init},\n  { \"nativeSurfaceFinalize\", \"()V\", (void *) gst_native_surface_finalize},\n  { \"nativeClassInit\", \"()Z\", (void *) gst_native_class_init}\n};\n\n/* Library initializer */\njint JNI_OnLoad(JavaVM *vm, void *reserved) {\n  JNIEnv *env = NULL;\n\n  java_vm = vm;\n\n  if ((*vm)-&gt;GetEnv(vm, (void**) &amp;env, JNI_VERSION_1_4) != JNI_OK) {\n    __android_log_print (ANDROID_LOG_ERROR, \"tutorial-3\", \"Could not retrieve JNIEnv\");\n    return 0;\n  }\n  jclass klass = (*env)-&gt;FindClass (env, \"org/freedesktop/gstreamer/tutorials/tutorial_3/Tutorial3\");\n  (*env)-&gt;RegisterNatives (env, klass, native_methods, G_N_ELEMENTS(native_methods));\n\n  pthread_key_create (&amp;current_jni_env, detach_current_thread);\n\n  return JNI_VERSION_1_4;\n}\n</code></pre>\n<p>First, our <code>CustomData</code> structure is augmented to keep a pointer to the\nvideo sink element and the native window\nhandle:</p>\n<pre><code class=\"language-c\">GstElement *video_sink; /* The video sink element which receives VideoOverlay commands */\nANativeWindow *native_window; /* The Android native window where video will be rendered */\n</code></pre>\n<p>The <code>check_initialization_complete()</code> method is also augmented so that\nit requires a native window before considering GStreamer to be\ninitialized:</p>\n<pre><code class=\"language-c\">static void check_initialization_complete (CustomData *data) {\n  JNIEnv *env = get_jni_env ();\n  if (!data-&gt;initialized &amp;&amp; data-&gt;native_window &amp;&amp; data-&gt;main_loop) {\n    GST_DEBUG (\"Initialization complete, notifying application. native_window:%p main_loop:%p\", data-&gt;native_window, data-&gt;main_loop);\n\n    /* The main loop is running and we received a native window, inform the sink about it */\n    gst_video_overlay_set_window_handle (GST_VIDEO_OVERLAY (data-&gt;video_sink), (guintptr)data-&gt;native_window);\n\n    (*env)-&gt;CallVoidMethod (env, data-&gt;app, on_gstreamer_initialized_method_id);\n    if ((*env)-&gt;ExceptionCheck (env)) {\n      GST_ERROR (\"Failed to call Java method\");\n      (*env)-&gt;ExceptionClear (env);\n    }\n    data-&gt;initialized = TRUE;\n  }\n}\n</code></pre>\n<p>Also, once the pipeline has been built and a native window has been\nreceived, we inform the video sink of the window handle to use via the\n<code>gst_video_overlay_set_window_handle()</code> method.</p>\n<p>The GStreamer pipeline for this tutorial involves a <code>videotestsrc</code>, a\n<code>warptv</code> psychedelic distorter effect (check out other cool video\neffects in the <code>GSTREAMER_PLUGINS_EFFECTS</code> package), and an\n<code>autovideosink</code> which will instantiate the adequate video sink for the\nplatform:</p>\n<pre><code class=\"language-c\">data-&gt;pipeline = gst_parse_launch(\"videotestsrc ! warptv ! videoconvert ! autovideosink \", &amp;error);\n</code></pre>\n<p>Here things start to get more\ninteresting:</p>\n<pre><code class=\"language-c\">/* Set the pipeline to READY, so it can already accept a window handle, if we have one */\ngst_element_set_state(data-&gt;pipeline, GST_STATE_READY);\n\ndata-&gt;video_sink = gst_bin_get_by_interface(GST_BIN(data-&gt;pipeline), GST_TYPE_VIDEO_OVERLAY);\nif (!data-&gt;video_sink) {\n  GST_ERROR (\"Could not retrieve video sink\");\n  return NULL;\n}\n</code></pre>\n<p>We start by setting the pipeline to the READY state. No data flow occurs\nyet, but the <code>autovideosink</code> will instantiate the actual sink so we can\nask for it immediately.</p>\n<p>The <code>gst_bin_get_by_interface()</code> method will examine the whole pipeline\nand return a pointer to an element which supports the requested\ninterface. We are asking for the <code>VideoOverlay</code> interface, explained in\n<a href=\"../basic/toolkit-integration.html\">Basic tutorial 5: GUI toolkit integration</a>,\nwhich controls how to perform rendering into foreign (non-GStreamer)\nwindows. The internal video sink instantiated by <code>autovideosink</code> is the\nonly element in this pipeline implementing it, so it will be returned.</p>\n<p>Now we will implement the two native functions called by the Java code\nwhen the drawing surface becomes available or is about to be\ndestroyed:</p>\n<pre><code class=\"language-c\">static void gst_native_surface_init (JNIEnv *env, jobject thiz, jobject surface) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  ANativeWindow *new_native_window = ANativeWindow_fromSurface(env, surface);\n  GST_DEBUG (\"Received surface %p (native window %p)\", surface, new_native_window);\n\n  if (data-&gt;native_window) {\n    ANativeWindow_release (data-&gt;native_window);\n    if (data-&gt;native_window == new_native_window) {\n      GST_DEBUG (\"New native window is the same as the previous one\", data-&gt;native_window);\n      if (data-&gt;video_sink) {\n        gst_video_overlay_expose(GST_VIDEO_OVERLAY (data-&gt;video_sink));\n        gst_video_overlay_expose(GST_VIDEO_OVERLAY (data-&gt;video_sink));\n      }\n      return;\n    } else {\n      GST_DEBUG (\"Released previous native window %p\", data-&gt;native_window);\n      data-&gt;initialized = FALSE;\n    }\n  }\n  data-&gt;native_window = new_native_window;\n\n  check_initialization_complete (data);\n}\n</code></pre>\n<p>This method is responsible for providing the video sink with the window\nhandle coming from the Java code. We are passed a\n<a href=\"http://developer.android.com/reference/android/view/Surface.html\">Surface</a>\nobject, and we use <code>ANativeWindow_fromSurface()</code> to obtain the\nunderlying native window pointer. There is no official online\ndocumentation for the NDK, but fortunately the header files are well\ncommented. Native window management functions can be found in\n<code>$(ANDROID_NDK_ROOT)\\platforms\\android-9\\arch-arm\\usr\\include\\android\\native_window.h</code> and <code>native_window_jni.h</code></p>\n<p>If we had already stored a native window, the one we just received can\neither be a new one, or just an update of the one we have. If the\npointers are the same, we assume the geometry of the surface has\nchanged, and simply instruct the video sink to redraw itself, via the\n<code>gst_video_overlay_expose()</code> method. The video sink will recover the new\nsize from the surface itself, so we do not need to bother about it\nhere. We need to call <code>gst_video_overlay_expose()</code> twice because of the way\nthe surface changes propagate down the OpenGL ES / EGL pipeline (The\nonly video sink available for Android in GStreamer uses OpenGL\nES). By the time we call the first expose, the surface that the sink\nwill pick up still contains the old size.</p>\n<p>On the other hand, if the pointers are different, we mark GStreamer as\nnot being initialized. Next time we call\n<code>check_initialization_complete()</code>, the video sink will be informed of\nthe new window handle.</p>\n<p>We finally store the new window handle and call\n<code>check_initialization_complete()</code> to inform the Java code that\neverything is set up, if that is the case.</p>\n<pre><code class=\"language-c\">static void gst_native_surface_finalize (JNIEnv *env, jobject thiz) {\n  CustomData *data = GET_CUSTOM_DATA (env, thiz, custom_data_field_id);\n  if (!data) return;\n  GST_DEBUG (\"Releasing Native Window %p\", data-&gt;native_window);\n\n  if (data-&gt;video_sink) {\n    gst_video_overlay_set_window_handle (GST_VIDEO_OVERLAY (data-&gt;video_sink), (guintptr)NULL);\n    gst_element_set_state (data-&gt;pipeline, GST_STATE_READY);\n  }\n\n  ANativeWindow_release (data-&gt;native_window);\n  data-&gt;native_window = NULL;\n  data-&gt;initialized = FALSE;\n}\n</code></pre>\n<p>The complementary function, <code>gst_native_surface_finalize()</code> is called\nwhen a surface is about to be destroyed and should not be used anymore.\nHere, we simply instruct the video sink to stop using the window handle\nand set the pipeline to READY so no rendering occurs. We release the\nwindow pointer we had stored with <code>ANativeWindow_release()</code>, and mark\nGStreamer as not being initialized anymore.</p>\n<p>And this is all there is to it, regarding the main code. Only a couple\nof details remain, the subclass we made for SurfaceView and the\n<code>Android.mk</code> file.</p>\n<h3 id=\"gstreamersurfaceview-a-convenient-surfaceview-wrapper-java-code\">GStreamerSurfaceView, a convenient SurfaceView wrapper [Java code]</h3>\n<p>By default,\n<a href=\"http://developer.android.com/reference/android/view/SurfaceView.html\">SurfaceView</a> does\nnot have any particular size, so it expands to use all the space the\nlayout can give it. While this might be convenient sometimes, it does\nnot allow a great deal of control. In particular, when the surface does\nnot have the same aspect ratio as the media, the sink will add black\nborders (the known \u201cletterbox\u201d or \u201cpillarbox\u201d effect), which is an\nunnecessary work (and a waste of battery).</p>\n<p>The subclass of\n<a href=\"http://developer.android.com/reference/android/view/SurfaceView.html\">SurfaceView</a> presented\nhere overrides the\n<a href=\"http://developer.android.com/reference/android/view/SurfaceView.html#onMeasure(int,%20int)\">onMeasure()</a> method\nto report the actual media size, so the surface can adapt to any layout\nwhile preserving the media aspect ratio.</p>\n<p>Since in this tutorial the media size is known beforehand, it is\nhardcoded in the GStreamerSurfaceView class for simplicity. The next\ntutorial shows how it can be recovered at runtime and passed onto the\nsurface.</p>\n<p><strong>src/org/freedesktop/gstreamer/tutorials/tutorial_3/GStreamerSurfaceView.java</strong></p>\n<pre><code class=\"language-java\">package org.freedesktop.gstreamer.tutorials.tutorial_3;\n\nimport android.content.Context;\nimport android.util.AttributeSet;\nimport android.util.Log;\nimport android.view.SurfaceView;\nimport android.view.View;\n\n// A simple SurfaceView whose width and height can be set from the outside\npublic class GStreamerSurfaceView extends SurfaceView {\n    public int media_width = 320;\n    public int media_height = 240;\n\n    // Mandatory constructors, they do not do much\n    public GStreamerSurfaceView(Context context, AttributeSet attrs,\n            int defStyle) {\n        super(context, attrs, defStyle);\n    }\n\n    public GStreamerSurfaceView(Context context, AttributeSet attrs) {\n        super(context, attrs);\n    }\n\n    public GStreamerSurfaceView (Context context) {\n        super(context);\n    }\n\n    // Called by the layout manager to find out our size and give us some rules.\n    // We will try to maximize our size, and preserve the media's aspect ratio if\n    // we are given the freedom to do so.\n    @Override\n    protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) {\n        int width = 0, height = 0;\n        int wmode = View.MeasureSpec.getMode(widthMeasureSpec);\n        int hmode = View.MeasureSpec.getMode(heightMeasureSpec);\n        int wsize = View.MeasureSpec.getSize(widthMeasureSpec);\n        int hsize = View.MeasureSpec.getSize(heightMeasureSpec);\n\n        Log.i (\"GStreamer\", \"onMeasure called with \" + media_width + \"x\" + media_height);\n        // Obey width rules\n        switch (wmode) {\n        case View.MeasureSpec.AT_MOST:\n            if (hmode == View.MeasureSpec.EXACTLY) {\n                width = Math.min(hsize * media_width / media_height, wsize);\n                break;\n            }\n        case View.MeasureSpec.EXACTLY:\n            width = wsize;\n            break;\n        case View.MeasureSpec.UNSPECIFIED:\n            width = media_width;\n        }\n\n        // Obey height rules\n        switch (hmode) {\n        case View.MeasureSpec.AT_MOST:\n            if (wmode == View.MeasureSpec.EXACTLY) {\n                height = Math.min(wsize * media_height / media_width, hsize);\n                break;\n            }\n        case View.MeasureSpec.EXACTLY:\n            height = hsize;\n            break;\n        case View.MeasureSpec.UNSPECIFIED:\n            height = media_height;\n        }\n\n        // Finally, calculate best size when both axis are free\n        if (hmode == View.MeasureSpec.AT_MOST &amp;&amp; wmode == View.MeasureSpec.AT_MOST) {\n            int correct_height = width * media_height / media_width;\n            int correct_width = height * media_width / media_height;\n\n            if (correct_height &lt; height)\n                height = correct_height;\n            else\n                width = correct_width;\n        }\n\n        // Obey minimum size\n        width = Math.max (getSuggestedMinimumWidth(), width);\n        height = Math.max (getSuggestedMinimumHeight(), height);\n        setMeasuredDimension(width, height);\n    }\n\n}\n</code></pre>\n<h3 id=\"a-video-surface-on-android-androidmk\">A video surface on Android [Android.mk]</h3>\n<p><strong>/jni/Android.mk</strong></p>\n<pre><code class=\"language-ruby\">LOCAL_PATH := $(call my-dir)\n\ninclude $(CLEAR_VARS)\n\nLOCAL_MODULE    := tutorial-3\nLOCAL_SRC_FILES := tutorial-3.c\nLOCAL_SHARED_LIBRARIES := gstreamer_android\nLOCAL_LDLIBS := -llog -landroid\ninclude $(BUILD_SHARED_LIBRARY)\n\nifndef GSTREAMER_ROOT\nifndef GSTREAMER_ROOT_ANDROID\n$(error GSTREAMER_ROOT_ANDROID is not defined!)\nendif\nGSTREAMER_ROOT        := $(GSTREAMER_ROOT_ANDROID)\nendif\nGSTREAMER_NDK_BUILD_PATH  := $(GSTREAMER_ROOT)/share/gst-android/ndk-build/\ninclude $(GSTREAMER_NDK_BUILD_PATH)/plugins.mk\nGSTREAMER_PLUGINS         := $(GSTREAMER_PLUGINS_CORE) $(GSTREAMER_PLUGINS_SYS) $(GSTREAMER_PLUGINS_EFFECTS)\nGSTREAMER_EXTRA_DEPS      := gstreamer-video-1.0\ninclude $(GSTREAMER_NDK_BUILD_PATH)/gstreamer.mk\n</code></pre>\n<p>Worth mentioning is the <code>-landroid</code> library being used to allow\ninteraction with the native windows, and the different plugin\npackages: <code>GSTREAMER_PLUGINS_SYS</code> for the system-dependent video sink\nand <code>GSTREAMER_PLUGINS_EFFECTS</code> for the <code>warptv</code> element. This tutorial\nrequires the <code>gstreamer-video</code> library to use the\n<code>VideoOverlay</code> interface and the video helper methods.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>This tutorial has shown:</p>\n<ul>\n<li>How to display video on Android using a\n<a href=\"http://developer.android.com/reference/android/view/SurfaceView.html\">SurfaceView</a> and\nthe <code>VideoOverlay</code> interface.</li>\n<li>How to be aware of changes in the surface\u2019s size using\n<a href=\"http://developer.android.com/reference/android/view/SurfaceView.html\">SurfaceView</a>\u2019s\ncallbacks.</li>\n<li>How to report the media size to the Android layout engine.</li>\n</ul>\n<p>The following tutorial plays an actual clip and adds a few more controls\nto this tutorial in order to build a simple media player.</p>\n<p>It has been a pleasure having you here, and see you soon!</p>\n\n</div>\n\n\n        "});