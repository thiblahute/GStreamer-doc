fragment_downloaded_cb({"url": "gst-plugins-base-video-1.0/javascript/video-info.html#page-description", "fragment": "Adjust the offset and stride fields in info so that the padding and stride alignment in align is respected. \nExtra padding will be added to the right side when stride alignment padding is required and align will be updated with the new padding values. \nConverts among various Gst.Format types. This function handles GST_FORMAT_BYTES GST_FORMAT_TIME and GST_FORMAT_DEFAULT. For raw video GST_FORMAT_DEFAULT corresponds to video frames. This function can be used to handle pad queries of the type GST_QUERY_CONVERT. \nCopy a GstVideoInfo structure. \nFree a GstVideoInfo structure previously allocated with GstVideo.VideoInfo.prototype.new or GstVideo.VideoInfo.prototype.copy. \nParse caps and update info. \nInitialize info with default values. \nCompares two GstVideo.VideoInfo and returns whether they are equal or not \nSet the default info for a video frame of format and width and height. \nNote This initializes info first no values are preserved. This function does not set the offsets correctly for interlaced vertically subsampled formats. \nConvert the values of info into a Gst.Caps. \nConvert order to a GstVideo.VideoFieldOrder \nConvert order to its string representation. \nConvert mode to a GstVideo.VideoInterlaceMode \nConvert mode to its string representation. \ntop field is first \nGstVideo.VideoFieldOrder.prototype.bottom_field_first \nbottom field is first \nEach color has been scaled by the alpha value. \nThe possible values of the GstVideo.VideoInterlaceMode describing the interlace mode of the stream. \nall frames are progressive \nGstVideo.VideoInterlaceMode.prototype.interleaved \nfields are interleaved in one video frame. Extra buffer flags describe the field order. \nGstVideo.VideoInterlaceMode.prototype.mixed \nframes contains both interlaced and progressive video the buffer flags describe the frame and fields. \nGstVideo.VideoInterlaceMode.prototype.fields \nfields are stored in one buffer use the frame ID to get access to the required field. For multiview the views property the fields of view N can be found at frame ID N and N Each field has only half the amount of lines as noted in the height property. This mode requires multiple GstVideoMeta metadata to describe the fields. \nGstVideoMultiviewFlags are used to indicate extra properties of a stereo multiview stream beyond the frame layout and buffer mapping that is conveyed in the GstMultiviewMode. \nNo flags \nGstVideo.VideoMultiviewFlags.prototype.right_view_first \nFor stereo streams the normal arrangement of left and right views is reversed. \nGstVideo.VideoMultiviewFlags.prototype.left_flipped \nThe left view is vertically mirrored. \nGstVideo.VideoMultiviewFlags.prototype.left_flopped \nThe left view is horizontally mirrored. \nGstVideo.VideoMultiviewFlags.prototype.right_flipped \nThe right view is vertically mirrored. \nGstVideo.VideoMultiviewFlags.prototype.right_flopped \nThe right view is horizontally mirrored. \nGstVideo.VideoMultiviewFlags.prototype.half_aspect \nFor frame packed multiview modes indicates that the individual views have been encoded with half the true width or height and should be scaled back up for display. This flag is used for overriding input layout interpretation by adjusting pixel aspect ratio. For side by side column interleaved or checkerboard packings the pixel width will be doubled. For row interleaved and top bottom encodings pixel height will be doubled. \nGstVideo.VideoMultiviewFlags.prototype.mixed_mono \nThe video stream contains both mono and multiview portions signalled on each buffer by the absence or presence of the GST_VIDEO_BUFFER_FLAG_MULTIPLE_VIEW buffer flag. \nGstVideo.VideoMultiviewFramePacking represents the subset of GstVideo.VideoMultiviewMode values that can be applied to any video frame without needing extra metadata. It can be used by elements that provide a property to override the multiview interpretation of a video stream when the video doesn t contain any markers. \nThis enum is used for example on playbin to re interpret a played video stream as a stereoscopic video. The individual enum values are equivalent to and have the same value as the matching GstVideo.VideoMultiviewMode. \nA special value indicating no frame packing info. \nGstVideo.VideoMultiviewFramePacking.prototype.mono \nAll frames are monoscopic. \nGstVideo.VideoMultiviewFramePacking.prototype.left \nAll frames represent a left eye view. \nGstVideo.VideoMultiviewFramePacking.prototype.right \nAll frames represent a right eye view. \nGstVideo.VideoMultiviewFramePacking.prototype.side_by_side \nLeft and right eye views are provided in the left and right half of the frame respectively. \nGstVideo.VideoMultiviewFramePacking.prototype.side_by_side_quincunx \nLeft and right eye views are provided in the left and right half of the frame but have been sampled using quincunx method with half pixel offset between the views. \nGstVideo.VideoMultiviewFramePacking.prototype.column_interleaved \nAlternating vertical columns of pixels represent the left and right eye view respectively. \nGstVideo.VideoMultiviewFramePacking.prototype.row_interleaved \nAlternating horizontal rows of pixels represent the left and right eye view respectively. \nGstVideo.VideoMultiviewFramePacking.prototype.top_bottom \nThe top half of the frame contains the left eye and the bottom half the right eye. \nGstVideo.VideoMultiviewFramePacking.prototype.checkerboard \nPixels are arranged with alternating pixels representing left and right eye views in a checkerboard fashion. \nAll possible stereoscopic D and multiview representations. In conjunction with GstVideo.VideoMultiviewFlags describes how multiview content is being transported in the stream. \nAll frames represent a right eye view. \nGstVideo.VideoMultiviewMode.prototype.side_by_side \nLeft and right eye views are provided in the left and right half of the frame respectively. \nGstVideo.VideoMultiviewMode.prototype.side_by_side_quincunx \nLeft and right eye views are provided in the left and right half of the frame but have been sampled using quincunx method with half pixel offset between the views. \nGstVideo.VideoMultiviewMode.prototype.column_interleaved \nAlternating vertical columns of pixels represent the left and right eye view respectively. \nGstVideo.VideoMultiviewMode.prototype.row_interleaved \nAlternating horizontal rows of pixels represent the left and right eye view respectively. \nGstVideo.VideoMultiviewMode.prototype.top_bottom \nThe top half of the frame contains the left eye and the bottom half the right eye. \nGstVideo.VideoMultiviewMode.prototype.checkerboard \nPixels are arranged with alternating pixels representing left and right eye views in a checkerboard fashion. \nGstVideo.VideoMultiviewMode.prototype.frame_by_frame \nLeft and right eye views are provided in separate frames alternately. \nGstVideo.VideoMultiviewMode.prototype.multiview_frame_by_frame \nMultiple independent views are provided in separate frames in sequence. This method only applies to raw video buffers at the moment. Specific view identification is via the GstVideoMultiviewMeta and GstVideo.VideoMeta s on raw video buffers. \nGstVideo.VideoMultiviewMode.prototype.separated \nMultiple views are provided as separate Gst.Memory framebuffers attached to each Gst.Buffer described by the GstVideoMultiviewMeta and GstVideo.VideoMeta s \n"});