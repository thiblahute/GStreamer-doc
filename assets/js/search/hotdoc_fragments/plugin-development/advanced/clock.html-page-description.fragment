fragment_downloaded_cb({"url": "plugin-development/advanced/clock.html#page-description", "fragment": "<div id=\"page-description\" data-hotdoc-source=\"clock.md\">\n<h1 id=\"clocking\">Clocking</h1>\n<p>When playing complex media, each sound and video sample must be played\nin a specific order at a specific time. For this purpose, GStreamer\nprovides a synchronization mechanism.</p>\n<h2 id=\"clocks\">Clocks</h2>\n<p>Time in GStreamer is defined as the value returned from a particular\n<code>GstClock</code> object from the method <code>gst_clock_get_time ()</code>.</p>\n<p>In a typical computer, there are many sources that can be used as a time\nsource, e.g., the system time, soundcards, CPU performance counters, ...\nFor this reason, there are many <code>GstClock</code> implementations available in\nGStreamer. The clock time doesn't always start from 0 or from some known\nvalue. Some clocks start counting from some known start date, other\nclocks start counting since last reboot, etc...</p>\n<p>As clocks return an absolute measure of time, they are not usually used\ndirectly. Instead, differences between two clock times are used to\nmeasure elapsed time according to a clock.</p>\n<h2 id=\"clock-runningtime\">Clock running-time</h2>\n<p>A clock returns the <strong>absolute-time</strong> according to that clock with\n<code>gst_clock_get_time ()</code>. From the absolute-time is a <strong>running-time</strong>\ncalculated, which is simply the difference between a previous snapshot\nof the absolute-time called the <strong>base-time</strong>. So:</p>\n<p>running-time = absolute-time - base-time</p>\n<p>A GStreamer <code>GstPipeline</code> object maintains a <code>GstClock</code> object and a\nbase-time when it goes to the PLAYING state. The pipeline gives a handle\nto the selected <code>GstClock</code> to each element in the pipeline along with\nselected base-time. The pipeline will select a base-time in such a way\nthat the running-time reflects the total time spent in the PLAYING\nstate. As a result, when the pipeline is PAUSED, the running-time stands\nstill.</p>\n<p>Because all objects in the pipeline have the same clock and base-time,\nthey can thus all calculate the running-time according to the pipeline\nclock.</p>\n<h2 id=\"buffer-runningtime\">Buffer running-time</h2>\n<p>To calculate a buffer running-time, we need a buffer timestamp and the\nSEGMENT event that preceded the buffer. First we can convert the SEGMENT\nevent into a <code>GstSegment</code> object and then we can use the\n<code>gst_segment_to_running_time ()</code> function to perform the calculation of\nthe buffer running-time.</p>\n<p>Synchronization is now a matter of making sure that a buffer with a\ncertain running-time is played when the clock reaches the same\nrunning-time. Usually this task is done by sink elements. Sink also have\nto take into account the latency configured in the pipeline and add this\nto the buffer running-time before synchronizing to the pipeline clock.</p>\n<h2 id=\"obligations-of-each-element\">Obligations of each element.</h2>\n<p>Let us clarify the contract between GStreamer and each element in the\npipeline.</p>\n<h3 id=\"nonlive-source-elements\">Non-live source elements</h3>\n<p>Non-live source elements must place a timestamp in each buffer that they\ndeliver when this is possible. They must choose the timestamps and the\nvalues of the SEGMENT event in such a way that the running-time of the\nbuffer starts from 0.</p>\n<p>Some sources, such as filesrc, is not able to generate timestamps on all\nbuffers. It can and must however create a timestamp on the first buffer\n(with a running-time of 0).</p>\n<p>The source then pushes out the SEGMENT event followed by the timestamped\nbuffers.</p>\n<h3 id=\"live-source-elements\">Live source elements</h3>\n<p>Live source elements must place a timestamp in each buffer that they\ndeliver. They must choose the timestamps and the values of the SEGMENT\nevent in such a way that the running-time of the buffer matches exactly\nthe running-time of the pipeline clock when the first byte in the buffer\nwas captured.</p>\n<h3 id=\"parserdecoderencoder-elements\">Parser/Decoder/Encoder elements</h3>\n<p>Parser/Decoder elements must use the incoming timestamps and transfer\nthose to the resulting output buffers. They are allowed to interpolate\nor reconstruct timestamps on missing input buffers when they can.</p>\n<h3 id=\"demuxer-elements\">Demuxer elements</h3>\n<p>Demuxer elements can usually set the timestamps stored inside the media\nfile onto the outgoing buffers. They need to make sure that outgoing\nbuffers that are to be played at the same time have the same\nrunning-time. Demuxers also need to take into account the incoming\ntimestamps on buffers and use that to calculate an offset on the\noutgoing buffer timestamps.</p>\n<h3 id=\"muxer-elements\">Muxer elements</h3>\n<p>Muxer elements should use the incoming buffer running-time to mux the\ndifferent streams together. They should copy the incoming running-time\nto the outgoing buffers.</p>\n<h3 id=\"sink-elements\">Sink elements</h3>\n<p>If the element is intended to emit samples at a specific time (real time\nplaying), the element should require a clock, and thus implement the\nmethod <code>set_clock</code>.</p>\n<p>The sink should then make sure that the sample with running-time is\nplayed exactly when the pipeline clock reaches that running-time +\nlatency. Some elements might use the clock API such as\n<code>gst_clock_id_wait()</code> to perform this action. Other sinks might need to\nuse other means of scheduling timely playback of the data.</p>\n\n</div>\n\n\n\t"});